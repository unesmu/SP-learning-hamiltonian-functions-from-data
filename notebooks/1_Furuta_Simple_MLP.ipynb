{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code in this notebook has been adapted from the work of Zhongy et al. and Greydanus et al. and from the report and code of Jonas Perolini.\n",
    "\n",
    "Their code is available in the following repositories :[\n",
    "Symplectic-ODENet](https://github.com/Physics-aware-AI/Symplectic-ODENet) and [hamiltonian-nn](https://github.com/greydanus/hamiltonian-nn)\n",
    "\n",
    "Structure inspired from https://github.com/Physics-aware-AI/Symplectic-ODENet/blob/master/experiment-single-force/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Setting up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..') \n",
    "import os\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    PATH = './' # './drive/MyDrive/1_SP_Ham_func/'\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    %pip install torchdiffeq\n",
    "\n",
    "    %cd /content/drive/MyDrive/1_SP_Ham_func/src/furuta\n",
    "    !wget --no-cache --backups=1 https://raw.githubusercontent.com/unesmu/SP_Learn_Ham_func/main/src/furuta/data.py \n",
    "    !wget --no-cache --backups=1 https://raw.githubusercontent.com/unesmu/SP_Learn_Ham_func/main/src/furuta/dynamics.py \n",
    "    !wget --no-cache --backups=1 https://raw.githubusercontent.com/unesmu/SP_Learn_Ham_func/main/src/furuta/models.py \n",
    "    !wget --no-cache --backups=1 https://raw.githubusercontent.com/unesmu/SP_Learn_Ham_func/main/src/furuta/train.py \n",
    "    !wget --no-cache --backups=1 https://raw.githubusercontent.com/unesmu/SP_Learn_Ham_func/main/src/furuta/plots.py \n",
    "    !wget --no-cache --backups=1 https://raw.githubusercontent.com/unesmu/SP_Learn_Ham_func/main/src/furuta/trajectories.py \n",
    "    !wget --no-cache --backups=1 https://raw.githubusercontent.com/unesmu/SP_Learn_Ham_func/main/src/furuta/utils.py \n",
    "\n",
    "    %cd ..\n",
    "    %cd ..\n",
    "    \n",
    "    from src.furuta.data import *\n",
    "    from src.furuta.dynamics import *\n",
    "    from src.furuta.models import *\n",
    "    from src.furuta.train import *\n",
    "    from src.furuta.plots import *\n",
    "    from src.furuta.trajectories import *\n",
    "    from src.furuta.utils import *\n",
    "    # !pip install torchdiffeq\n",
    "    #   # Clone the entire repo to access the files.\n",
    "    #   !git clone -l -s https://github.com/....... repo\n",
    "    # Mount your google drive \n",
    "else:\n",
    "    from src.furuta.data import *\n",
    "    from src.furuta.dynamics import *\n",
    "    from src.furuta.models import *\n",
    "    from src.furuta.train import *\n",
    "    from src.furuta.plots import *\n",
    "    from src.furuta.trajectories import *\n",
    "    from src.furuta.utils import *\n",
    "    PATH = '../'\n",
    "\n",
    "# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.furuta.data import *\n",
    "from src.furuta.dynamics import *\n",
    "from src.furuta.models import *\n",
    "from src.furuta.train import *\n",
    "from src.furuta.plots import *\n",
    "from src.furuta.trajectories import *\n",
    "from src.furuta.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate, load and save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = set_device()\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = 'fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_func(t, utype):  \n",
    "  ''' time dependent input '''\n",
    "  if utype == 'tanh':\n",
    "      u = (-torch.tanh((t-0.75)*4)+1)/100\n",
    "  elif utype == 'CHIRP':\n",
    "      u = chirp_fun(t,T=1.5,f0=1,f1=10)\n",
    "  elif utype == 'multisine':\n",
    "      u = multi_sine(t)\n",
    "  elif utype == 'step':\n",
    "      u = step_fun(t, t1=0.05)\n",
    "  u.requires_grad=False\n",
    "  return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "utype=None\n",
    "gtype=None\n",
    "u_func=None\n",
    "g_func=None\n",
    "init_method = 'random_closetopi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, stds = load_data_device(device, utype=utype, gtype=gtype, init_method=init_method, \n",
    "                                                   u_func=u_func, g_func=g_func, time_steps=5, \n",
    "                                                   shuffle = False, \n",
    "                                                   num_trajectories=125, \n",
    "                                                   coord_type='hamiltonian', \n",
    "                                                   proportion=0.8, batch_size=100, \n",
    "                                                   Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
    "                                                   g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = 'Ts_{:.3f}_Jr_{:.2f}_Lr_{:.2f}_Mp_{:.2f}__Lp_{:.2f}'.format(Ts, Jr, Lr, Mp, Lp)\n",
    "suffix = suffix + '_'+ utype+ '_'\n",
    "print(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "# os.makedirs('../data/experiment_1/', exist_ok=True)\n",
    "# filename = '../data/experiment_1/1/simulation_{}.{}'\n",
    "# filename.format(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_path = PATH + 'data/datasets/train_loader_' + suffix + '.pt'\n",
    "test_loader_path = PATH + 'data/datasets/test_loader_' + suffix + '.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path)\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.load(train_loader_path)\n",
    "test_loader = torch.load(test_loader_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_nes_hdnn(device,utype=utype, u_func=u_func, hidden_dim=90, nb_hidden_layers=4) # load_model(hidden_dim=90, nb_hidden_layers=4)\n",
    "num_params = count_parameters(model)\n",
    "print(num_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1.0, 1.0, 10.0, 10.0] # [1.0, 5.0, 10.0, 15.0]\n",
    "\n",
    "weights_title = ' | weights = ' + str(weights)\n",
    "print('weights',weights)\n",
    "horizon_list = [20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,\n",
    "                200,210,220,230,240,250,260,270,280,290,300]\n",
    "                #list(range(20,301,10))\n",
    "\n",
    "switch_steps = [300,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,\n",
    "                100,100,100,100,50,50,50,50,50,50,50,50,100]\n",
    "#[100]*len(horizon_list) # [150,150,150,150,150,150,150,150,150,150,150,150,150,150]\n",
    "\n",
    "print(len(horizon_list))\n",
    "print(len(switch_steps))\n",
    "epoch_number = sum(switch_steps)\n",
    "print(epoch_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prefix = '{:d}e_w_{:05.1f}_{:05.1f}_{:05.1f}_{:05.1f}_p{:d}k_ts_{:1.3f}__'.format(epoch_number,weights[0],weights[1],weights[2],weights[3],int((num_params-num_params%1000)/1000),Ts)\n",
    "save_prefix = save_prefix+ '_'+ utype+ '_'\n",
    "print(save_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = train(model, \n",
    "              Ts, \n",
    "              train_loader, \n",
    "              test_loader, \n",
    "              w=torch.tensor(weights, device=device),\n",
    "              epoch_number = epoch_number,\n",
    "              horizon = False, \n",
    "              horizon_type = 'auto', \n",
    "              horizon_list = horizon_list, \n",
    "              switch_steps = switch_steps, \n",
    "              epochs = 3, \n",
    "              loss_type = 'L2weighted2') # L2normalizedfixed3 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = train_alternating(model, \n",
    "              Ts, \n",
    "              train_loader, \n",
    "              test_loader, \n",
    "              w=torch.tensor(weights, device=device), \n",
    "              epoch_number=epoch_number,\n",
    "              horizon = False, \n",
    "              horizon_type = 'auto', \n",
    "              horizon_list = horizon_list, \n",
    "              switch_steps = switch_steps, \n",
    "              epochs = epoch_number, \n",
    "              loss_type = 'L2weighted2') # L2normalizedfixed3 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tSZNGbFzsxTO",
   "metadata": {
    "id": "tSZNGbFzsxTO"
   },
   "outputs": [],
   "source": [
    "stats_path = PATH+'data/stats/'+save_prefix+'stats.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the stats\n",
    "save_stats(PATH, stats, stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the stats \n",
    "stats = read_dict(PATH, stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'models/'+save_prefix+'model_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "model_name = 'data/models/'+save_prefix+'model_test'\n",
    "torch.save(model.state_dict(), PATH+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "model = load_model_nes_hdnn(device,utype=utype, u_func=u_func, hidden_dim=90, nb_hidden_layers=4) # load_model(hidden_dim=90, nb_hidden_layers=4)\n",
    "#load_model(device, hidden_dim=90, nb_hidden_layers=4)\n",
    "model.load_state_dict(torch.load(PATH+model_name))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.C2_dissip)\n",
    "print(model.C1_dissip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_steps = []\n",
    "horizon_steps.append(0)\n",
    "for i, number in enumerate(switch_steps) :\n",
    "  horizon_steps.append(horizon_steps[i] +number) \n",
    "horizon_steps = horizon_steps[1:-1]\n",
    "# horizon_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bpcjbU2h_bk-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "bpcjbU2h_bk-",
    "outputId": "2791ccd1-5a00-405b-dd73-70e9b546f608"
   },
   "outputs": [],
   "source": [
    "loss_train = stats['train_loss']\n",
    "loss_test = stats['test_loss']\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(loss_train, loss_test, epochs, file_path=PATH+'data/img/'+save_prefix+'LOSS_train_test_1.png', \n",
    "                     title='train and test loss per epoch'+ weights_title, horizons= False )\n",
    "\n",
    "train_test_loss_plot(loss_train, loss_test, epochs, file_path=PATH+'data/img/'+save_prefix+'LOSS_train_test_2.png', \n",
    "                     title='train and test loss per epoch'+ weights_title, horizons= horizon_list[:-1], horizon_steps = horizon_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71072h6uvdVo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "71072h6uvdVo",
    "outputId": "7c8a1498-02f0-4a4c-c51d-a1dc4a541eb4"
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "plot_furuta_hat_nom(model, u_func, g_func, utype, gtype, data_loader_t=train_loader, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
    "                     title = 'Train set trajectories'+ weights_title, file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_train_set'+str(n)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ThwazVRemVEe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "ThwazVRemVEe",
    "outputId": "516fec60-e29c-44a6-a7c9-ba2b81f50b9f"
   },
   "outputs": [],
   "source": [
    "n=20\n",
    "plot_furuta_hat_nom(model, u_func, g_func, utype, gtype, data_loader_t=train_loader, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
    "                     title = 'Train set trajectories'+ weights_title, file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_train_set'+str(n)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J2mcTyfewM8t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "J2mcTyfewM8t",
    "outputId": "34ad2f9b-ebc7-4c99-9c6b-23db21c77bfa"
   },
   "outputs": [],
   "source": [
    "n = 10 \n",
    "\n",
    "plot_furuta_hat_nom(model, u_func, g_func, utype, gtype, data_loader_t=test_loader, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
    "                     title = 'Test set trajectories'+ weights_title, file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_test_set'+str(n)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mvjltX8DwPMT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "mvjltX8DwPMT",
    "outputId": "c7ebe605-c297-46a1-b241-13a43ab3bc3b"
   },
   "outputs": [],
   "source": [
    "n = 7\n",
    "plot_furuta_hat_nom(model, u_func, g_func, utype, gtype, data_loader_t=test_loader, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
    "                     title = 'Test set trajectories'+ weights_title, file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_test_set'+str(n)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "woKs_NcAwPsm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "woKs_NcAwPsm",
    "outputId": "7b239a00-021c-48ed-fc44-cf6b0fdc8fbd"
   },
   "outputs": [],
   "source": [
    "n = 12\n",
    "plot_furuta_hat_nom(model, u_func, g_func, utype, gtype, data_loader_t=test_loader, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
    "                     title = 'Test set trajectories'+ weights_title, file_path=None)#PATH+'data/img/'+save_prefix+'TRAJECTORIES_test_set'+str(n)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CNNSWhuZEQzf",
   "metadata": {
    "id": "CNNSWhuZEQzf"
   },
   "outputs": [],
   "source": [
    "test_loader_3, _ , _ = load_data_device(device, utype, gtype, init_method=init_method,u_func=u_func, g_func=g_func, time_steps=100, num_trajectories=2,  coord_type='hamiltonian', proportion=0.0, batch_size=1,\n",
    "                                        noise_std=noise_std, Ts=Ts,C_q1= C_q1, C_q2= C_q2, g= g, Jr= Jr, Lr= Lr, Mp= Mp, Lp= Lp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JuBXNKdTGaZm",
   "metadata": {
    "id": "JuBXNKdTGaZm"
   },
   "outputs": [],
   "source": [
    "test_loader_path_3 = PATH + 'data/datasets/test_loader_longer_3' + suffix + '.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8jmOTa7-uHYX",
   "metadata": {
    "id": "8jmOTa7-uHYX"
   },
   "outputs": [],
   "source": [
    "torch.save(test_loader_3, test_loader_path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vda2P6EuuuGL",
   "metadata": {
    "id": "vda2P6EuuuGL"
   },
   "outputs": [],
   "source": [
    "test_loader_3 = torch.load(test_loader_path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pNZ2RVBcwVYM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "pNZ2RVBcwVYM",
    "outputId": "9364a00a-1f6c-4af4-b0a2-8e5a57efd430"
   },
   "outputs": [],
   "source": [
    "plot_longer_horizon_furuta(model, u_func, g_func, utype, gtype, test_loader=test_loader_3,t1=0,t2=2000, C_q1= C_q1, C_q2= C_q2, g= g, Jr= Jr, Lr= Lr, Mp= Mp, Lp= Lp, title = 'Trajectory after longer horizon'+ weights_title,\n",
    "                           file_path=PATH+'img/'+save_prefix+'TRAJ_longer_horizon1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uiLkHlnpERoL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "uiLkHlnpERoL",
    "outputId": "87a3a189-6f25-4aab-93de-2d5d74d941cc"
   },
   "outputs": [],
   "source": [
    "plot_longer_horizon_furuta(model, u_func, g_func, utype, gtype, test_loader=test_loader_3,t1=2000,t2=10000, C_q1= C_q1, C_q2= C_q2, g= g, Jr= Jr, Lr= Lr, Mp= Mp, Lp= Lp, title = 'Trajectory after longer horizon'+ weights_title,\n",
    "                           file_path=PATH+'img/'+save_prefix+'TRAJ_longer_horizon2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mjzUpuyhpevc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "mjzUpuyhpevc",
    "outputId": "c4170e53-cf3d-4c9d-a4f4-b236867dafef"
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "plot_furuta_hat_nom(model, u_func, g_func, utype, gtype, data_loader_t=test_loader_3, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
    "                     title = 'Test set trajectories'+ weights_title, file_path=PATH+'img/'+save_prefix+'TRAJECTORIES_test_set_longer'+str(n)+'.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52b0f3b5fff4e2d99607e23e4ce3f8b9e3a664acf6541783ed53f1bd22095b69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
