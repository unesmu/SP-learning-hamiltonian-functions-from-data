{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy0mWdPersbg"
   },
   "source": [
    "Some code in this notebook has been adapted from the work of Zhongy et al. and Greydanus et al. and from the report and code of Jonas Perolini.\n",
    "\n",
    "Their code is available in the following repositories :[\n",
    "Symplectic-ODENet](https://github.com/Physics-aware-AI/Symplectic-ODENet) and [hamiltonian-nn](https://github.com/greydanus/hamiltonian-nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd6pGmU-rsbk"
   },
   "source": [
    "# Imports & Setting up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ioF4QRA1FEF",
    "outputId": "98dd7e30-bd38-4c5a-b1bc-f139b400d050"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    PATH = \"./\"  # './drive/MyDrive/1_SP_Ham_func/'\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    %cd /content/drive/MyDrive/1_SP_Ham_func/furuta_pendulum/\n",
    "    %pip install torchdiffeq\n",
    "    from src.data import *\n",
    "    from src.dynamics import *\n",
    "    from src.models import *\n",
    "    from src.train import *\n",
    "    from src.plots import *\n",
    "    from src.trajectories import *\n",
    "    from src.utils import *\n",
    "else:\n",
    "    import sys\n",
    "\n",
    "    sys.path.insert(0, \"..\")\n",
    "    import os\n",
    "\n",
    "    PATH = \"../\"\n",
    "    from src.data import *\n",
    "    from src.dynamics import *\n",
    "    from src.models import *\n",
    "    from src.train import *\n",
    "    from src.plots import *\n",
    "    from src.trajectories import *\n",
    "    from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6F69c4UZ_3U_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "from torchdiffeq import odeint_adjoint as odeint_adjoint\n",
    "\n",
    "# func must be a nn.Module when using the adjoint method\n",
    "from torchdiffeq import odeint as odeint\n",
    "\n",
    "import time as time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MqUrZjjnu8Xh"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK-tFX-vrsbt"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WBPS5kWJycC"
   },
   "source": [
    "#### simple_HNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up2e73c_u8Xk"
   },
   "source": [
    "##### 10k parameters - w horizon - with std rescaling (and loss) no clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SebIxog3JycC",
    "outputId": "ca5a3e04-a0b2-4228-a563-2a15855eece5"
   },
   "outputs": [],
   "source": [
    "device = set_device()  # set it to gpu if it is available\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "furuta_type = \"real\"  # 'real' or 'fake'\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
    "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
    "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
    "gtype = None  # 'simple' or None\n",
    "# instantiate the input function G(q,p) (here it is constant)\n",
    "g_func = G_FUNC(gtype=gtype)\n",
    "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
    "time_steps = 800  # length of a trajectory\n",
    "num_trajectories = 125  # number of trajectories in total\n",
    "proportion = 0.8  # train test proportion\n",
    "batch_size = 100  # batch size used by dataloader\n",
    "w_rescale = [1, 1000, 1, 10000]  # [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
    "shuffle = False  # shuffle sample in the batches between epochs\n",
    "# 'hamiltonian' or 'newtonian', newtonian if you want [q1,q1_dot,q2,q2_dot]\n",
    "coord_type = \"hamiltonian\"\n",
    "min_max_rescale = False  # rescale the training trajectories\n",
    "# which dimensions to rescale if using min_max_rescale, so that nothing is divided by zero\n",
    "rescale_dims = [1, 1, 1, 0]\n",
    "\n",
    "# Parameters for the training procedure\n",
    "resnet_config = None\n",
    "alternating = False  # for Input_HNN, if G is a neural network, train\n",
    "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
    "horizon = False  # if horizon_type == 'constant', use this horizon\n",
    "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
    "collect_grads = False  # collect gradients in all layers at every epoch\n",
    "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
    "rescale_loss = True\n",
    "grad_clip = False  # activate gradient clipping\n",
    "lr_schedule = False  # activate lr schedule\n",
    "begin_decay = 600  # epoch at which lr starts decaying\n",
    "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
    "\n",
    "horizon_list = [50, 100, 150, 200, 250, 300]\n",
    "switch_steps = [200, 100, 100, 100, 100, 100]\n",
    "epoch_number = sum(switch_steps)  # total number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMsE0Gdpu8Xn"
   },
   "outputs": [],
   "source": [
    "# generate train and test dataloader objects containing the trajectories\n",
    "train_loader, test_loader = load_data_device(\n",
    "    device,\n",
    "    init_method,\n",
    "    w_rescale,\n",
    "    u_func,\n",
    "    g_func,\n",
    "    time_steps,\n",
    "    shuffle=shuffle,\n",
    "    num_trajectories=num_trajectories,\n",
    "    coord_type=coord_type,\n",
    "    proportion=proportion,\n",
    "    batch_size=batch_size,\n",
    "    Ts=Ts,\n",
    "    noise_std=noise_std,\n",
    "    C_q1=C_q1,\n",
    "    C_q2=C_q2,\n",
    "    g=g,\n",
    "    Jr=Jr,\n",
    "    Lr=Lr,\n",
    "    Mp=Mp,\n",
    "    Lp=Lp,\n",
    "    min_max_rescale=min_max_rescale,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFeWFdOtJycC",
    "outputId": "3b9c0197-f736-46ae-93f3-53b6007e4470"
   },
   "outputs": [],
   "source": [
    "# initialise the model that will be trianed\n",
    "model_name = \"simple_HNN\"\n",
    "H_net = MLP(input_dim=4, hidden_dim=70, nb_hidden_layers=2, output_dim=1, activation=\"x+sin(x)^2\")  # load H model\n",
    "model = simple_HNN(input_dim=4, H_net=H_net, device=device)  # load neural ODE model\n",
    "model.to(device)  # send model to devie ( cpu or gpu )\n",
    "\n",
    "# create file name from parameters\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "save_prefix = name_from_params(\n",
    "    Ts,\n",
    "    rescale_loss,\n",
    "    weights,\n",
    "    epoch_number,\n",
    "    num_params,\n",
    "    utype,\n",
    "    model_name,\n",
    "    num_trajectories,\n",
    "    furuta_type,\n",
    "    noise_std,\n",
    "    grad_clip,\n",
    "    lr_schedule,\n",
    "    C_q1,\n",
    "    C_q2,\n",
    "    horizon,\n",
    "    min_max_rescale,\n",
    ")\n",
    "\n",
    "# print some information on the training and file name\n",
    "print(\"Total number of epochs:\", epoch_number)\n",
    "print(\"H_net number of parameters :\", num_params)\n",
    "print(\"Save file prefix : \", save_prefix)\n",
    "\n",
    "# Sanity check\n",
    "is_same_size(horizon_list, switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0p7VJblfYUws",
    "outputId": "2900b1db-eb56-44cf-8d70-e3d0f837c9bd"
   },
   "outputs": [],
   "source": [
    "stats = train(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    Ts=Ts,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    w=torch.tensor(weights, device=device),\n",
    "    grad_clip=grad_clip,\n",
    "    lr_schedule=lr_schedule,\n",
    "    begin_decay=begin_decay,\n",
    "    resnet_config=resnet_config,\n",
    "    epoch_number=epoch_number,\n",
    "    alternating=alternating,\n",
    "    horizon=horizon,\n",
    "    horizon_type=horizon_type,\n",
    "    horizon_list=horizon_list,\n",
    "    switch_steps=switch_steps,\n",
    "    epochs=epoch_number,\n",
    "    loss_type=loss_type,\n",
    "    collect_grads=collect_grads,\n",
    "    rescale_loss=rescale_loss,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_2n7AXcu8Xr"
   },
   "outputs": [],
   "source": [
    "if collect_grads:\n",
    "    plot_grads(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msB_a2sou8Xs"
   },
   "outputs": [],
   "source": [
    "# set all paths and create folders :\n",
    "model_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "stats_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "plot_path = PATH + \"data/\" + save_prefix + \"/img/\"\n",
    "train_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "test_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(stats_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "os.makedirs(train_loader_path, exist_ok=True)\n",
    "os.makedirs(test_loader_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArMCgWh9u8Xt"
   },
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path + \"train_loader.pt\")\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path + \"test_loader.pt\")\n",
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), model_path + \"model\")\n",
    "\n",
    "# save the stats\n",
    "save_stats(stats, stats_path + \"stats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgnTeT9-u8Xt"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.load(train_loader_path)\n",
    "# test_loader = torch.load(test_loader_path)\n",
    "# # loads the stats\n",
    "# stats = read_dict(PATH, stats_path)\n",
    "# # load the model from disk\n",
    "# model.load_state_dict(torch.load(PATH+model_path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "bpcjbU2h_bk-",
    "outputId": "bdaca955-7ad5-41b1-b32f-34946055ca55"
   },
   "outputs": [],
   "source": [
    "loss_train = stats[\"train_loss\"]\n",
    "loss_test = stats[\"test_loss\"]\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=False,\n",
    "    switch_steps=switch_steps,\n",
    ")\n",
    "\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test_warrows.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=horizon_list[:-1],\n",
    "    switch_steps=switch_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3WcR1iZg4ha5",
    "outputId": "f46a19fe-7763-4bfe-f2a0-a3fb61a8a751"
   },
   "outputs": [],
   "source": [
    "# show train and prediction\n",
    "for n in [0, 5, 10, 19]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=time_steps,\n",
    "        show_pred=True,\n",
    "        H_or_Input=\"input\",\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "71072h6uvdVo",
    "outputId": "fe2b9800-52b9-4e80-95fb-17f215dc91d2"
   },
   "outputs": [],
   "source": [
    "# show only training portion\n",
    "for n in [0, 50, 70]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=horizon_list[-1],\n",
    "        show_pred=False,\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \"nopred.png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LzQNWQiu8Xv"
   },
   "source": [
    "##### 10k parameters - w horizon - with rescaling - with grad clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zjCUj9Xu8Xw",
    "outputId": "5dc6e18f-bab3-4ca1-c3be-799a2210dcd2"
   },
   "outputs": [],
   "source": [
    "device = set_device()  # set it to gpu if it is available\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "furuta_type = \"real\"  # 'real' or 'fake'\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
    "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
    "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
    "gtype = None  # 'simple' or None\n",
    "# instantiate the input function G(q,p) (here it is constant)\n",
    "g_func = G_FUNC(gtype=gtype)\n",
    "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
    "time_steps = 800\n",
    "num_trajectories = 125\n",
    "proportion = 0.8\n",
    "batch_size = 100\n",
    "w_rescale = [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
    "shuffle = False\n",
    "coord_type = \"hamiltonian\"\n",
    "rescale_dims = [1, 1, 1, 0]\n",
    "min_max_rescale = True\n",
    "\n",
    "# Parameters for the training procedure\n",
    "resnet_config = None\n",
    "alternating = False  # for Input_HNN, if G is a neural network, train\n",
    "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
    "horizon = False  # if horizon_type == 'constant', use this horizon\n",
    "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
    "collect_grads = False  # collect gradients in all layers at every epoch\n",
    "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
    "rescale_loss = True\n",
    "grad_clip = True  # activate gradient clipping\n",
    "lr_schedule = False  # activate lr schedule\n",
    "begin_decay = 600  # epoch at which lr starts decaying\n",
    "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
    "\n",
    "horizon_list = [50, 100, 150, 200, 250, 300]\n",
    "switch_steps = [200, 100, 100, 100, 100, 100]\n",
    "epoch_number = sum(switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogyero35u8Xx"
   },
   "outputs": [],
   "source": [
    "# generate train and test dataloader objects containing the trajectories\n",
    "train_loader, test_loader = load_data_device(\n",
    "    device,\n",
    "    init_method,\n",
    "    w_rescale,\n",
    "    u_func,\n",
    "    g_func,\n",
    "    time_steps,\n",
    "    shuffle=shuffle,\n",
    "    num_trajectories=num_trajectories,\n",
    "    coord_type=coord_type,\n",
    "    proportion=proportion,\n",
    "    batch_size=batch_size,\n",
    "    Ts=Ts,\n",
    "    noise_std=noise_std,\n",
    "    C_q1=C_q1,\n",
    "    C_q2=C_q2,\n",
    "    g=g,\n",
    "    Jr=Jr,\n",
    "    Lr=Lr,\n",
    "    Mp=Mp,\n",
    "    Lp=Lp,\n",
    "    min_max_rescale=min_max_rescale,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjK2r65gu8Xx",
    "outputId": "e15188cc-1cc6-48fd-e5b5-8983d9e6843e"
   },
   "outputs": [],
   "source": [
    "# initialise the model that will be trianed\n",
    "model_name = \"simple_HNN\"\n",
    "H_net = MLP(input_dim=4, hidden_dim=70, nb_hidden_layers=2, output_dim=1, activation=\"x+sin(x)^2\")  # load H model\n",
    "model = simple_HNN(input_dim=4, H_net=H_net, device=device)  # load neural ODE model\n",
    "model.to(device)  # send model to devie ( cpu or gpu )\n",
    "\n",
    "# create file name from parameters\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "save_prefix = name_from_params(\n",
    "    Ts,\n",
    "    rescale_loss,\n",
    "    weights,\n",
    "    epoch_number,\n",
    "    num_params,\n",
    "    utype,\n",
    "    model_name,\n",
    "    num_trajectories,\n",
    "    furuta_type,\n",
    "    noise_std,\n",
    "    grad_clip,\n",
    "    lr_schedule,\n",
    "    C_q1,\n",
    "    C_q2,\n",
    "    horizon,\n",
    "    min_max_rescale,\n",
    ")\n",
    "\n",
    "# print some information on the training and file name\n",
    "print(\"Total number of epochs:\", epoch_number)\n",
    "print(\"H_net number of parameters :\", num_params)\n",
    "print(\"Save file prefix : \", save_prefix)\n",
    "\n",
    "# Sanity check\n",
    "is_same_size(horizon_list, switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "36Wsu6GMu8Xy",
    "outputId": "e818efb3-e631-4e7c-edf1-847da4297173"
   },
   "outputs": [],
   "source": [
    "stats = train(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    Ts=Ts,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    w=torch.tensor(weights, device=device),\n",
    "    grad_clip=grad_clip,\n",
    "    lr_schedule=lr_schedule,\n",
    "    begin_decay=begin_decay,\n",
    "    resnet_config=resnet_config,\n",
    "    epoch_number=epoch_number,\n",
    "    alternating=alternating,\n",
    "    horizon=horizon,\n",
    "    horizon_type=horizon_type,\n",
    "    horizon_list=horizon_list,\n",
    "    switch_steps=switch_steps,\n",
    "    epochs=epoch_number,\n",
    "    loss_type=loss_type,\n",
    "    collect_grads=collect_grads,\n",
    "    rescale_loss=rescale_loss,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbwEI430u8Xz"
   },
   "outputs": [],
   "source": [
    "if collect_grads:\n",
    "    plot_grads(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hF_lg4aPu8Xz"
   },
   "outputs": [],
   "source": [
    "# set all paths and create folders :\n",
    "model_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "stats_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "plot_path = PATH + \"data/\" + save_prefix + \"/img/\"\n",
    "train_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "test_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(stats_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "os.makedirs(train_loader_path, exist_ok=True)\n",
    "os.makedirs(test_loader_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiAFmGHQu8X0"
   },
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path + \"train_loader.pt\")\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path + \"test_loader.pt\")\n",
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), model_path + \"model\")\n",
    "\n",
    "# save the stats\n",
    "save_stats(stats, stats_path + \"stats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4mAMTihu8X0"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.load(train_loader_path)\n",
    "# test_loader = torch.load(test_loader_path)\n",
    "# # loads the stats\n",
    "# stats = read_dict(PATH, stats_path)\n",
    "# # load the model from disk\n",
    "# model.load_state_dict(torch.load(PATH+model_path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "n-bULZrGu8X0",
    "outputId": "915873a9-3fe6-4def-dfed-5aba8229faf5"
   },
   "outputs": [],
   "source": [
    "loss_train = stats[\"train_loss\"]\n",
    "loss_test = stats[\"test_loss\"]\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=False,\n",
    "    switch_steps=switch_steps,\n",
    ")\n",
    "\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test_warrows.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=horizon_list[:-1],\n",
    "    switch_steps=switch_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "prAmoFXmu8X1",
    "outputId": "083a98b3-b69e-469e-89a7-55ab184b6c29"
   },
   "outputs": [],
   "source": [
    "# show train and prediction\n",
    "for n in [0, 5, 10, 19]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=time_steps,\n",
    "        show_pred=True,\n",
    "        H_or_Input=\"input\",\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "J8ibmijwu8X1",
    "outputId": "591fb9f9-71b4-4185-ca2f-611d322885f6"
   },
   "outputs": [],
   "source": [
    "# show only training portion\n",
    "for n in [0, 50, 70]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=horizon_list[-1],\n",
    "        show_pred=False,\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \"nopred.png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arUTmhM0u8X1"
   },
   "source": [
    "##### 30k parameters - w horizon no rescaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvMQU3tm4OBo",
    "outputId": "48527a90-bd53-4c00-d67b-91ee96f8f3e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = set_device()  # set it to gpu if it is available\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "furuta_type = \"real\"  # 'real' or 'fake'\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
    "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
    "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
    "gtype = None  # 'simple' or None\n",
    "# instantiate the input function G(q,p) (here it is constant)\n",
    "g_func = G_FUNC(gtype=gtype)\n",
    "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
    "time_steps = 800  # length of a trajectory\n",
    "num_trajectories = 125  # number of trajectories in total\n",
    "proportion = 0.8  # train test proportion\n",
    "batch_size = 100  # batch size used by dataloader\n",
    "w_rescale = [1, 1, 1, 1]  # [1, 1000, 1, 10000]  # [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
    "shuffle = False  # shuffle sample in the batches between epochs\n",
    "# 'hamiltonian' or 'newtonian', newtonian if you want [q1,q1_dot,q2,q2_dot]\n",
    "coord_type = \"hamiltonian\"\n",
    "min_max_rescale = False  # rescale the training trajectories\n",
    "# which dimensions to rescale if using min_max_rescale, so that nothing is divided by zero\n",
    "rescale_dims = [1, 1, 1, 0]\n",
    "\n",
    "# Parameters for the training procedure\n",
    "resnet_config = None\n",
    "alternating = False  # for Input_HNN, if G is a neural network, train\n",
    "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
    "horizon = False  # if horizon_type == 'constant', use this horizon\n",
    "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
    "collect_grads = False  # collect gradients in all layers at every epoch\n",
    "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
    "rescale_loss = False\n",
    "grad_clip = False  # activate gradient clipping\n",
    "lr_schedule = False  # activate lr schedule\n",
    "begin_decay = 600  # epoch at which lr starts decaying\n",
    "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
    "\n",
    "horizon_list = [50, 100, 150, 200, 250, 300]\n",
    "switch_steps = [200, 100, 100, 100, 100, 100]\n",
    "epoch_number = sum(switch_steps)  # total number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4xw7Rnk94OBp"
   },
   "outputs": [],
   "source": [
    "# generate train and test dataloader objects containing the trajectories\n",
    "train_loader, test_loader = load_data_device(\n",
    "    device,\n",
    "    init_method,\n",
    "    w_rescale,\n",
    "    u_func,\n",
    "    g_func,\n",
    "    time_steps,\n",
    "    shuffle=shuffle,\n",
    "    num_trajectories=num_trajectories,\n",
    "    coord_type=coord_type,\n",
    "    proportion=proportion,\n",
    "    batch_size=batch_size,\n",
    "    Ts=Ts,\n",
    "    noise_std=noise_std,\n",
    "    C_q1=C_q1,\n",
    "    C_q2=C_q2,\n",
    "    g=g,\n",
    "    Jr=Jr,\n",
    "    Lr=Lr,\n",
    "    Mp=Mp,\n",
    "    Lp=Lp,\n",
    "    min_max_rescale=min_max_rescale,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEZu1UpB4OBq",
    "outputId": "c3719c91-1241-49ca-98e2-72647f4f5257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of epochs: 700\n",
      "H_net number of parameters : 33303\n",
      "Save file prefix :  simple_HNN_noinput_125traj_real_noise0.0_700e_p33k_Ts0.005_nodissip_\n",
      "horizon_list and switch_steps have the same size\n"
     ]
    }
   ],
   "source": [
    "# initialise the model that will be trianed\n",
    "model_name = \"simple_HNN\"\n",
    "H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4, output_dim=1, activation=\"x+sin(x)^2\")  # load H model\n",
    "model = simple_HNN(input_dim=4, H_net=H_net, device=device)  # load neural ODE model\n",
    "model.to(device)  # send model to devie ( cpu or gpu )\n",
    "\n",
    "# create file name from parameters\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "save_prefix = name_from_params(\n",
    "    Ts,\n",
    "    rescale_loss,\n",
    "    weights,\n",
    "    epoch_number,\n",
    "    num_params,\n",
    "    utype,\n",
    "    model_name,\n",
    "    num_trajectories,\n",
    "    furuta_type,\n",
    "    noise_std,\n",
    "    grad_clip,\n",
    "    lr_schedule,\n",
    "    C_q1,\n",
    "    C_q2,\n",
    "    horizon,\n",
    "    min_max_rescale,\n",
    ")\n",
    "\n",
    "# print some information on the training and file name\n",
    "print(\"Total number of epochs:\", epoch_number)\n",
    "print(\"H_net number of parameters :\", num_params)\n",
    "print(\"Save file prefix : \", save_prefix)\n",
    "\n",
    "# Sanity check\n",
    "is_same_size(horizon_list, switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sRqgFiFM4OBq",
    "outputId": "d4e85df3-57c6-4256-d36c-60b2ce16d2c7"
   },
   "outputs": [],
   "source": [
    "stats = train(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    Ts=Ts,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    w=torch.tensor(weights, device=device),\n",
    "    grad_clip=grad_clip,\n",
    "    lr_schedule=lr_schedule,\n",
    "    begin_decay=begin_decay,\n",
    "    resnet_config=resnet_config,\n",
    "    epoch_number=epoch_number,\n",
    "    alternating=alternating,\n",
    "    horizon=horizon,\n",
    "    horizon_type=horizon_type,\n",
    "    horizon_list=horizon_list,\n",
    "    switch_steps=switch_steps,\n",
    "    epochs=epoch_number,\n",
    "    loss_type=loss_type,\n",
    "    collect_grads=collect_grads,\n",
    "    rescale_loss=rescale_loss,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sVwwqZwN4OBr"
   },
   "outputs": [],
   "source": [
    "if collect_grads:\n",
    "    plot_grads(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j1MqVDSt4OBr"
   },
   "outputs": [],
   "source": [
    "# set all paths and create folders :\n",
    "model_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "stats_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "plot_path = PATH + \"data/\" + save_prefix + \"/img/\"\n",
    "train_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "test_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(stats_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "os.makedirs(train_loader_path, exist_ok=True)\n",
    "os.makedirs(test_loader_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcL1ejfm4OBs"
   },
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path + \"train_loader.pt\")\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path + \"test_loader.pt\")\n",
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), model_path + \"model\")\n",
    "\n",
    "# save the stats\n",
    "save_stats(stats, stats_path + \"stats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mqSba-6n4OBs"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/simple_HNN_noinput_125traj_real_noise0.0_700e_p33k_Ts0.005_nodissip_/model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Younes\\Documents\\GitHub\\SP-learning-hamiltonian-functions-from-data\\furuta_pendulum\\notebooks\\furuta_pendulum_simpleHNN copy.ipynb Cell 40'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Younes/Documents/GitHub/SP-learning-hamiltonian-functions-from-data/furuta_pendulum/notebooks/furuta_pendulum_simpleHNN%20copy.ipynb#ch0000039?line=3'>4</a>\u001b[0m stats \u001b[39m=\u001b[39m read_dict(stats_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstats.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Younes/Documents/GitHub/SP-learning-hamiltonian-functions-from-data/furuta_pendulum/notebooks/furuta_pendulum_simpleHNN%20copy.ipynb#ch0000039?line=4'>5</a>\u001b[0m \u001b[39m# load the model from disk\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Younes/Documents/GitHub/SP-learning-hamiltonian-functions-from-data/furuta_pendulum/notebooks/furuta_pendulum_simpleHNN%20copy.ipynb#ch0000039?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(model_path\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Younes/Documents/GitHub/SP-learning-hamiltonian-functions-from-data/furuta_pendulum/notebooks/furuta_pendulum_simpleHNN%20copy.ipynb#ch0000039?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    592\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 594\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    595\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    596\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    598\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/simple_HNN_noinput_125traj_real_noise0.0_700e_p33k_Ts0.005_nodissip_/model'"
     ]
    }
   ],
   "source": [
    "train_loader = torch.load(train_loader_path + \"train_loader.pt\")\n",
    "test_loader = torch.load(test_loader_path + \"test_loader.pt\")\n",
    "# loads the stats\n",
    "stats = read_dict(stats_path + \"stats.txt\")\n",
    "# load the model from disk\n",
    "model.load_state_dict(torch.load(model_path + \"model\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "0Nd3rdvq4OBs",
    "outputId": "182fd65a-98bc-4909-f2cc-f3b022e2283e"
   },
   "outputs": [],
   "source": [
    "loss_train = stats[\"train_loss\"]\n",
    "loss_test = stats[\"test_loss\"]\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=False,\n",
    "    switch_steps=switch_steps,\n",
    ")\n",
    "\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test_warrows.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=horizon_list[:-1],\n",
    "    switch_steps=switch_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qM2uEEPB4OBt",
    "outputId": "30f645c5-b394-4201-a6c7-8f3b1d20159e"
   },
   "outputs": [],
   "source": [
    "# show train and prediction\n",
    "for n in [0, 5, 10, 19]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=time_steps,\n",
    "        show_pred=True,\n",
    "        H_or_Input=\"input\",\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "j3_PNgLF4OBt",
    "outputId": "f71e5809-817c-4422-d080-15d641af457e"
   },
   "outputs": [],
   "source": [
    "# show only training portion\n",
    "for n in [0, 50, 70]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=horizon_list[-1],\n",
    "        show_pred=False,\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \"nopred.png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AltpEqt8UqNk"
   },
   "source": [
    "##### 30k parameters - w horizon only loss rescaling no clipping (didnt work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11R1TxMOUrkI",
    "outputId": "b46df9c5-90af-4482-fddf-3c2614275d42"
   },
   "outputs": [],
   "source": [
    "device = set_device()  # set it to gpu if it is available\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "furuta_type = \"real\"  # 'real' or 'fake'\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
    "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
    "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
    "gtype = None  # 'simple' or None\n",
    "# instantiate the input function G(q,p) (here it is constant)\n",
    "g_func = G_FUNC(gtype=gtype)\n",
    "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
    "time_steps = 800  # length of a trajectory\n",
    "num_trajectories = 125  # number of trajectories in total\n",
    "proportion = 0.8  # train test proportion\n",
    "batch_size = 100  # batch size used by dataloader\n",
    "w_rescale = [1, 1, 1, 1]  # [1, 1000, 1, 10000]  # [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
    "shuffle = False  # shuffle sample in the batches between epochs\n",
    "# 'hamiltonian' or 'newtonian', newtonian if you want [q1,q1_dot,q2,q2_dot]\n",
    "coord_type = \"hamiltonian\"\n",
    "min_max_rescale = False  # rescale the training trajectories\n",
    "# which dimensions to rescale if using min_max_rescale, so that nothing is divided by zero\n",
    "rescale_dims = [1, 1, 1, 0]\n",
    "\n",
    "# Parameters for the training procedure\n",
    "resnet_config = None\n",
    "alternating = False  # for Input_HNN, if G is a neural network, train\n",
    "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
    "horizon = False  # if horizon_type == 'constant', use this horizon\n",
    "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
    "collect_grads = False  # collect gradients in all layers at every epoch\n",
    "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
    "rescale_loss = True\n",
    "grad_clip = False  # activate gradient clipping\n",
    "lr_schedule = False  # activate lr schedule\n",
    "begin_decay = 600  # epoch at which lr starts decaying\n",
    "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
    "\n",
    "horizon_list = [50, 100, 150, 200, 250, 300]\n",
    "switch_steps = [200, 100, 100, 100, 100, 100]\n",
    "epoch_number = sum(switch_steps)  # total number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwlq1XgfUrkJ"
   },
   "outputs": [],
   "source": [
    "# generate train and test dataloader objects containing the trajectories\n",
    "train_loader, test_loader = load_data_device(\n",
    "    device,\n",
    "    init_method,\n",
    "    w_rescale,\n",
    "    u_func,\n",
    "    g_func,\n",
    "    time_steps,\n",
    "    shuffle=shuffle,\n",
    "    num_trajectories=num_trajectories,\n",
    "    coord_type=coord_type,\n",
    "    proportion=proportion,\n",
    "    batch_size=batch_size,\n",
    "    Ts=Ts,\n",
    "    noise_std=noise_std,\n",
    "    C_q1=C_q1,\n",
    "    C_q2=C_q2,\n",
    "    g=g,\n",
    "    Jr=Jr,\n",
    "    Lr=Lr,\n",
    "    Mp=Mp,\n",
    "    Lp=Lp,\n",
    "    min_max_rescale=min_max_rescale,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPiYSgKRUrkK",
    "outputId": "4def4413-80c8-4391-a993-7b79c215c6e4"
   },
   "outputs": [],
   "source": [
    "# initialise the model that will be trianed\n",
    "model_name = \"simple_HNN\"\n",
    "H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4, output_dim=1, activation=\"x+sin(x)^2\")  # load H model\n",
    "model = simple_HNN(input_dim=4, H_net=H_net, device=device)  # load neural ODE model\n",
    "model.to(device)  # send model to devie ( cpu or gpu )\n",
    "\n",
    "# create file name from parameters\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "save_prefix = name_from_params(\n",
    "    Ts,\n",
    "    rescale_loss,\n",
    "    weights,\n",
    "    epoch_number,\n",
    "    num_params,\n",
    "    utype,\n",
    "    model_name,\n",
    "    num_trajectories,\n",
    "    furuta_type,\n",
    "    noise_std,\n",
    "    grad_clip,\n",
    "    lr_schedule,\n",
    "    C_q1,\n",
    "    C_q2,\n",
    "    horizon,\n",
    "    min_max_rescale,\n",
    ")\n",
    "\n",
    "# print some information on the training and file name\n",
    "print(\"Total number of epochs:\", epoch_number)\n",
    "print(\"H_net number of parameters :\", num_params)\n",
    "print(\"Save file prefix : \", save_prefix)\n",
    "\n",
    "# Sanity check\n",
    "is_same_size(horizon_list, switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDByT64RVFGA"
   },
   "outputs": [],
   "source": [
    "save_prefix = save_prefix + \"nostdrescale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AbSLebwNUrkK",
    "outputId": "92355e09-5d58-45c8-f907-c289a201b1f8"
   },
   "outputs": [],
   "source": [
    "stats = train(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    Ts=Ts,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    w=torch.tensor(weights, device=device),\n",
    "    grad_clip=grad_clip,\n",
    "    lr_schedule=lr_schedule,\n",
    "    begin_decay=begin_decay,\n",
    "    resnet_config=resnet_config,\n",
    "    epoch_number=epoch_number,\n",
    "    alternating=alternating,\n",
    "    horizon=horizon,\n",
    "    horizon_type=horizon_type,\n",
    "    horizon_list=horizon_list,\n",
    "    switch_steps=switch_steps,\n",
    "    epochs=epoch_number,\n",
    "    loss_type=loss_type,\n",
    "    collect_grads=collect_grads,\n",
    "    rescale_loss=rescale_loss,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OK_G5L_hUrkL"
   },
   "outputs": [],
   "source": [
    "if collect_grads:\n",
    "    plot_grads(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUP3e4OVUrkM"
   },
   "outputs": [],
   "source": [
    "# set all paths and create folders :\n",
    "model_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "stats_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "plot_path = PATH + \"data/\" + save_prefix + \"/img/\"\n",
    "train_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "test_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(stats_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "os.makedirs(train_loader_path, exist_ok=True)\n",
    "os.makedirs(test_loader_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAamkQ6nUrkM"
   },
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path + \"train_loader.pt\")\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path + \"test_loader.pt\")\n",
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), model_path + \"model\")\n",
    "\n",
    "# save the stats\n",
    "save_stats(stats, stats_path + \"stats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytuaHFbVUrkR"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.load(train_loader_path)\n",
    "# test_loader = torch.load(test_loader_path)\n",
    "# # loads the stats\n",
    "# stats = read_dict(PATH, stats_path)\n",
    "# # load the model from disk\n",
    "# model.load_state_dict(torch.load(PATH+model_path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrjPXUYcUrkR"
   },
   "outputs": [],
   "source": [
    "loss_train = stats[\"train_loss\"]\n",
    "loss_test = stats[\"test_loss\"]\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=False,\n",
    "    switch_steps=switch_steps,\n",
    ")\n",
    "\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test_warrows.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=horizon_list[:-1],\n",
    "    switch_steps=switch_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wruomJavUrkS"
   },
   "outputs": [],
   "source": [
    "# show train and prediction\n",
    "for n in [0, 5, 10, 19]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=time_steps,\n",
    "        show_pred=True,\n",
    "        H_or_Input=\"input\",\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ncjl1G_4UrkS"
   },
   "outputs": [],
   "source": [
    "# show only training portion\n",
    "for n in [0, 50, 70]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=horizon_list[-1],\n",
    "        show_pred=False,\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \"nopred.png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3F0sJ8GMaP-"
   },
   "source": [
    "##### 30k parameters - w horizon - std rescaling (and loss) no clipping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hSRooW4MjlJ",
    "outputId": "f5e586d3-fbfa-4f98-c644-802b5ab54f98"
   },
   "outputs": [],
   "source": [
    "device = set_device()  # set it to gpu if it is available\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "furuta_type = \"real\"  # 'real' or 'fake'\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
    "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
    "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
    "gtype = None  # 'simple' or None\n",
    "# instantiate the input function G(q,p) (here it is constant)\n",
    "g_func = G_FUNC(gtype=gtype)\n",
    "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
    "time_steps = 800  # length of a trajectory\n",
    "num_trajectories = 125  # number of trajectories in total\n",
    "proportion = 0.8  # train test proportion\n",
    "batch_size = 100  # batch size used by dataloader\n",
    "w_rescale = [1, 1000, 1, 10000]  # [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
    "shuffle = False  # shuffle sample in the batches between epochs\n",
    "# 'hamiltonian' or 'newtonian', newtonian if you want [q1,q1_dot,q2,q2_dot]\n",
    "coord_type = \"hamiltonian\"\n",
    "min_max_rescale = False  # rescale the training trajectories\n",
    "# which dimensions to rescale if using min_max_rescale, so that nothing is divided by zero\n",
    "rescale_dims = [1, 1, 1, 0]\n",
    "\n",
    "# Parameters for the training procedure\n",
    "resnet_config = None\n",
    "alternating = False  # for Input_HNN, if G is a neural network, train\n",
    "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
    "horizon = False  # if horizon_type == 'constant', use this horizon\n",
    "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
    "collect_grads = False  # collect gradients in all layers at every epoch\n",
    "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
    "rescale_loss = True\n",
    "grad_clip = False  # activate gradient clipping\n",
    "lr_schedule = False  # activate lr schedule\n",
    "begin_decay = 600  # epoch at which lr starts decaying\n",
    "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
    "\n",
    "horizon_list = [50, 100, 150, 200, 250, 300]\n",
    "switch_steps = [200, 100, 100, 100, 100, 100]\n",
    "epoch_number = sum(switch_steps)  # total number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvUcCKF1MjlK"
   },
   "outputs": [],
   "source": [
    "# generate train and test dataloader objects containing the trajectories\n",
    "train_loader, test_loader = load_data_device(\n",
    "    device,\n",
    "    init_method,\n",
    "    w_rescale,\n",
    "    u_func,\n",
    "    g_func,\n",
    "    time_steps,\n",
    "    shuffle=shuffle,\n",
    "    num_trajectories=num_trajectories,\n",
    "    coord_type=coord_type,\n",
    "    proportion=proportion,\n",
    "    batch_size=batch_size,\n",
    "    Ts=Ts,\n",
    "    noise_std=noise_std,\n",
    "    C_q1=C_q1,\n",
    "    C_q2=C_q2,\n",
    "    g=g,\n",
    "    Jr=Jr,\n",
    "    Lr=Lr,\n",
    "    Mp=Mp,\n",
    "    Lp=Lp,\n",
    "    min_max_rescale=min_max_rescale,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gmyuq1NIMjlL",
    "outputId": "63e8d5dd-aef8-4aed-d291-6462a897d045"
   },
   "outputs": [],
   "source": [
    "# initialise the model that will be trianed\n",
    "model_name = \"simple_HNN\"\n",
    "H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4, output_dim=1, activation=\"x+sin(x)^2\")  # load H model\n",
    "model = simple_HNN(input_dim=4, H_net=H_net, device=device)  # load neural ODE model\n",
    "model.to(device)  # send model to devie ( cpu or gpu )\n",
    "\n",
    "# create file name from parameters\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "save_prefix = name_from_params(\n",
    "    Ts,\n",
    "    rescale_loss,\n",
    "    weights,\n",
    "    epoch_number,\n",
    "    num_params,\n",
    "    utype,\n",
    "    model_name,\n",
    "    num_trajectories,\n",
    "    furuta_type,\n",
    "    noise_std,\n",
    "    grad_clip,\n",
    "    lr_schedule,\n",
    "    C_q1,\n",
    "    C_q2,\n",
    "    horizon,\n",
    "    min_max_rescale,\n",
    ")\n",
    "\n",
    "# print some information on the training and file name\n",
    "print(\"Total number of epochs:\", epoch_number)\n",
    "print(\"H_net number of parameters :\", num_params)\n",
    "print(\"Save file prefix : \", save_prefix)\n",
    "\n",
    "# Sanity check\n",
    "is_same_size(horizon_list, switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LGjVmKteMjlL",
    "outputId": "f693ad58-68f0-4a24-959c-2d8e3188f50f"
   },
   "outputs": [],
   "source": [
    "stats = train(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    Ts=Ts,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    w=torch.tensor(weights, device=device),\n",
    "    grad_clip=grad_clip,\n",
    "    lr_schedule=lr_schedule,\n",
    "    begin_decay=begin_decay,\n",
    "    resnet_config=resnet_config,\n",
    "    epoch_number=epoch_number,\n",
    "    alternating=alternating,\n",
    "    horizon=horizon,\n",
    "    horizon_type=horizon_type,\n",
    "    horizon_list=horizon_list,\n",
    "    switch_steps=switch_steps,\n",
    "    epochs=epoch_number,\n",
    "    loss_type=loss_type,\n",
    "    collect_grads=collect_grads,\n",
    "    rescale_loss=rescale_loss,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDW_j_uQMjlL"
   },
   "outputs": [],
   "source": [
    "if collect_grads:\n",
    "    plot_grads(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvEA2JpLMjlM"
   },
   "outputs": [],
   "source": [
    "# set all paths and create folders :\n",
    "model_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "stats_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "plot_path = PATH + \"data/\" + save_prefix + \"/img/\"\n",
    "train_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "test_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(stats_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "os.makedirs(train_loader_path, exist_ok=True)\n",
    "os.makedirs(test_loader_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0s6CwzQWMjlM"
   },
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path + \"train_loader.pt\")\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path + \"test_loader.pt\")\n",
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), model_path + \"model\")\n",
    "\n",
    "# save the stats\n",
    "save_stats(stats, stats_path + \"stats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q83Z_xGSMjlM"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.load(train_loader_path)\n",
    "# test_loader = torch.load(test_loader_path)\n",
    "# # loads the stats\n",
    "# stats = read_dict(PATH, stats_path)\n",
    "# # load the model from disk\n",
    "# model.load_state_dict(torch.load(PATH+model_path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "8m1nNYC3MjlM",
    "outputId": "57a83aab-2bef-48bf-b690-cd8a0a476b4a"
   },
   "outputs": [],
   "source": [
    "loss_train = stats[\"train_loss\"]\n",
    "loss_test = stats[\"test_loss\"]\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=False,\n",
    "    switch_steps=switch_steps,\n",
    ")\n",
    "\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test_warrows.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=horizon_list[:-1],\n",
    "    switch_steps=switch_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Qrt_VM-MjlM",
    "outputId": "480db77a-b88e-4df1-b663-967334826707"
   },
   "outputs": [],
   "source": [
    "# show train and prediction\n",
    "for n in [0, 5, 10, 19]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=time_steps,\n",
    "        show_pred=True,\n",
    "        H_or_Input=\"input\",\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "BL9rc096MjlN",
    "outputId": "18c59313-5d01-48f1-de1b-ffaa9d1c7c9b"
   },
   "outputs": [],
   "source": [
    "# show only training portion\n",
    "for n in [0, 50, 70]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=horizon_list[-1],\n",
    "        show_pred=False,\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \"nopred.png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2NHFts9u8X1"
   },
   "source": [
    "##### 30k parameters - w horizon - with all rescaling no clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bm31D-rY-iVS",
    "outputId": "d6bba048-fa84-457e-fd03-b24811e3cb7b"
   },
   "outputs": [],
   "source": [
    "device = set_device()  # set it to gpu if it is available\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "furuta_type = \"real\"  # 'real' or 'fake'\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
    "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
    "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
    "gtype = None  # 'simple' or None\n",
    "# instantiate the input function G(q,p) (here it is constant)\n",
    "g_func = G_FUNC(gtype=gtype)\n",
    "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
    "time_steps = 800  # length of a trajectory\n",
    "num_trajectories = 125  # number of trajectories in total\n",
    "proportion = 0.8  # train test proportion\n",
    "batch_size = 100  # batch size used by dataloader\n",
    "w_rescale = [1, 1, 1, 1]  # [1, 1000, 1, 10000]  # [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
    "shuffle = False  # shuffle sample in the batches between epochs\n",
    "# 'hamiltonian' or 'newtonian', newtonian if you want [q1,q1_dot,q2,q2_dot]\n",
    "coord_type = \"hamiltonian\"\n",
    "min_max_rescale = True  # rescale the training trajectories\n",
    "# which dimensions to rescale if using min_max_rescale, so that nothing is divided by zero\n",
    "rescale_dims = [1, 1, 1, 0]\n",
    "\n",
    "# Parameters for the training procedure\n",
    "resnet_config = None\n",
    "alternating = False  # for Input_HNN, if G is a neural network, train\n",
    "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
    "horizon = False  # if horizon_type == 'constant', use this horizon\n",
    "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
    "collect_grads = False  # collect gradients in all layers at every epoch\n",
    "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
    "rescale_loss = True\n",
    "grad_clip = False  # activate gradient clipping\n",
    "lr_schedule = False  # activate lr schedule\n",
    "begin_decay = 600  # epoch at which lr starts decaying\n",
    "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
    "\n",
    "horizon_list = [50, 100, 150, 200, 250, 300]\n",
    "switch_steps = [200, 100, 100, 100, 100, 100]\n",
    "epoch_number = sum(switch_steps)  # total number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRPqpaeo-iVT"
   },
   "outputs": [],
   "source": [
    "# generate train and test dataloader objects containing the trajectories\n",
    "train_loader, test_loader = load_data_device(\n",
    "    device,\n",
    "    init_method,\n",
    "    w_rescale,\n",
    "    u_func,\n",
    "    g_func,\n",
    "    time_steps,\n",
    "    shuffle=shuffle,\n",
    "    num_trajectories=num_trajectories,\n",
    "    coord_type=coord_type,\n",
    "    proportion=proportion,\n",
    "    batch_size=batch_size,\n",
    "    Ts=Ts,\n",
    "    noise_std=noise_std,\n",
    "    C_q1=C_q1,\n",
    "    C_q2=C_q2,\n",
    "    g=g,\n",
    "    Jr=Jr,\n",
    "    Lr=Lr,\n",
    "    Mp=Mp,\n",
    "    Lp=Lp,\n",
    "    min_max_rescale=min_max_rescale,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsunSHPt-iVT",
    "outputId": "4d2556bf-e1d1-443b-c160-33d02b5b099e"
   },
   "outputs": [],
   "source": [
    "# initialise the model that will be trianed\n",
    "model_name = \"simple_HNN\"\n",
    "H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4, output_dim=1, activation=\"x+sin(x)^2\")  # load H model\n",
    "model = simple_HNN(input_dim=4, H_net=H_net, device=device)  # load neural ODE model\n",
    "model.to(device)  # send model to devie ( cpu or gpu )\n",
    "\n",
    "# create file name from parameters\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "save_prefix = name_from_params(\n",
    "    Ts,\n",
    "    rescale_loss,\n",
    "    weights,\n",
    "    epoch_number,\n",
    "    num_params,\n",
    "    utype,\n",
    "    model_name,\n",
    "    num_trajectories,\n",
    "    furuta_type,\n",
    "    noise_std,\n",
    "    grad_clip,\n",
    "    lr_schedule,\n",
    "    C_q1,\n",
    "    C_q2,\n",
    "    horizon,\n",
    "    min_max_rescale,\n",
    ")\n",
    "\n",
    "# print some information on the training and file name\n",
    "print(\"Total number of epochs:\", epoch_number)\n",
    "print(\"H_net number of parameters :\", num_params)\n",
    "print(\"Save file prefix : \", save_prefix)\n",
    "\n",
    "# Sanity check\n",
    "is_same_size(horizon_list, switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QH_J9jWL-iVU",
    "outputId": "78014674-98a4-4818-f072-7abad74633a8"
   },
   "outputs": [],
   "source": [
    "stats = train(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    Ts=Ts,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    w=torch.tensor(weights, device=device),\n",
    "    grad_clip=grad_clip,\n",
    "    lr_schedule=lr_schedule,\n",
    "    begin_decay=begin_decay,\n",
    "    resnet_config=resnet_config,\n",
    "    epoch_number=epoch_number,\n",
    "    alternating=alternating,\n",
    "    horizon=horizon,\n",
    "    horizon_type=horizon_type,\n",
    "    horizon_list=horizon_list,\n",
    "    switch_steps=switch_steps,\n",
    "    epochs=epoch_number,\n",
    "    loss_type=loss_type,\n",
    "    collect_grads=collect_grads,\n",
    "    rescale_loss=rescale_loss,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dqns6M7o-iVU"
   },
   "outputs": [],
   "source": [
    "if collect_grads:\n",
    "    plot_grads(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lN_8wzL1-iVV"
   },
   "outputs": [],
   "source": [
    "# set all paths and create folders :\n",
    "model_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "stats_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "plot_path = PATH + \"data/\" + save_prefix + \"/img/\"\n",
    "train_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "test_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(stats_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "os.makedirs(train_loader_path, exist_ok=True)\n",
    "os.makedirs(test_loader_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35gWCuK1-iVV"
   },
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path + \"train_loader.pt\")\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path + \"test_loader.pt\")\n",
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), model_path + \"model\")\n",
    "\n",
    "# save the stats\n",
    "save_stats(stats, stats_path + \"stats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDtwYwTn-iVW"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.load(train_loader_path)\n",
    "# test_loader = torch.load(test_loader_path)\n",
    "# # loads the stats\n",
    "# stats = read_dict(PATH, stats_path)\n",
    "# # load the model from disk\n",
    "# model.load_state_dict(torch.load(PATH+model_path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "ABzCnQNa-iVW",
    "outputId": "88b7d2a8-67fd-460a-aa54-6c7aa3d7c555"
   },
   "outputs": [],
   "source": [
    "loss_train = stats[\"train_loss\"]\n",
    "loss_test = stats[\"test_loss\"]\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=False,\n",
    "    switch_steps=switch_steps,\n",
    ")\n",
    "\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test_warrows.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=horizon_list[:-1],\n",
    "    switch_steps=switch_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xJzv_1eR-iVW",
    "outputId": "8556f82b-a600-4530-9fb5-72ed19468d35"
   },
   "outputs": [],
   "source": [
    "# show train and prediction\n",
    "for n in [0, 5, 10, 19]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=time_steps,\n",
    "        show_pred=True,\n",
    "        H_or_Input=\"input\",\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "BwtO2s_3-iVX",
    "outputId": "d64ceca2-1e3d-4d6c-9fd6-17d70a9620c4"
   },
   "outputs": [],
   "source": [
    "# show only training portion\n",
    "for n in [0, 50, 70]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=horizon_list[-1],\n",
    "        show_pred=False,\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \"nopred.png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6piNvOwu8X2"
   },
   "source": [
    "##### 30k parameters - w horizon - with rescaling - with grad clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOmaMQ28Cczz",
    "outputId": "3ef93931-5aa2-4321-ef04-97e4e90d30d8"
   },
   "outputs": [],
   "source": [
    "device = set_device()  # set it to gpu if it is available\n",
    "\n",
    "# Parameters to generate the dataset\n",
    "furuta_type = \"real\"  # 'real' or 'fake'\n",
    "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
    "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
    "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
    "gtype = None  # 'simple' or None\n",
    "# instantiate the input function G(q,p) (here it is constant)\n",
    "g_func = G_FUNC(gtype=gtype)\n",
    "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
    "time_steps = 800  # length of a trajectory\n",
    "num_trajectories = 125  # number of trajectories in total\n",
    "proportion = 0.8  # train test proportion\n",
    "batch_size = 100  # batch size used by dataloader\n",
    "w_rescale = [1, 1, 1, 1]  # [1, 1000, 1, 10000]  # [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
    "shuffle = False  # shuffle sample in the batches between epochs\n",
    "# 'hamiltonian' or 'newtonian', newtonian if you want [q1,q1_dot,q2,q2_dot]\n",
    "coord_type = \"hamiltonian\"\n",
    "min_max_rescale = True  # rescale the training trajectories\n",
    "# which dimensions to rescale if using min_max_rescale, so that nothing is divided by zero\n",
    "rescale_dims = [1, 1, 1, 0]\n",
    "\n",
    "# Parameters for the training procedure\n",
    "resnet_config = None\n",
    "alternating = False  # for Input_HNN, if G is a neural network, train\n",
    "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
    "horizon = False  # if horizon_type == 'constant', use this horizon\n",
    "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
    "collect_grads = False  # collect gradients in all layers at every epoch\n",
    "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
    "rescale_loss = True\n",
    "grad_clip = True  # activate gradient clipping\n",
    "lr_schedule = False  # activate lr schedule\n",
    "begin_decay = 600  # epoch at which lr starts decaying\n",
    "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
    "\n",
    "horizon_list = [50, 100, 150, 200, 250, 300]\n",
    "switch_steps = [200, 100, 100, 100, 100, 100]\n",
    "epoch_number = sum(switch_steps)  # total number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VgOgbS_Cc0T"
   },
   "outputs": [],
   "source": [
    "# generate train and test dataloader objects containing the trajectories\n",
    "train_loader, test_loader = load_data_device(\n",
    "    device,\n",
    "    init_method,\n",
    "    w_rescale,\n",
    "    u_func,\n",
    "    g_func,\n",
    "    time_steps,\n",
    "    shuffle=shuffle,\n",
    "    num_trajectories=num_trajectories,\n",
    "    coord_type=coord_type,\n",
    "    proportion=proportion,\n",
    "    batch_size=batch_size,\n",
    "    Ts=Ts,\n",
    "    noise_std=noise_std,\n",
    "    C_q1=C_q1,\n",
    "    C_q2=C_q2,\n",
    "    g=g,\n",
    "    Jr=Jr,\n",
    "    Lr=Lr,\n",
    "    Mp=Mp,\n",
    "    Lp=Lp,\n",
    "    min_max_rescale=min_max_rescale,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3HyINQyCc0U",
    "outputId": "b4048d53-606d-40f7-a01d-174bf2b97978"
   },
   "outputs": [],
   "source": [
    "# initialise the model that will be trianed\n",
    "model_name = \"simple_HNN\"\n",
    "H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4, output_dim=1, activation=\"x+sin(x)^2\")  # load H model\n",
    "model = simple_HNN(input_dim=4, H_net=H_net, device=device)  # load neural ODE model\n",
    "model.to(device)  # send model to devie ( cpu or gpu )\n",
    "\n",
    "# create file name from parameters\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "save_prefix = name_from_params(\n",
    "    Ts,\n",
    "    rescale_loss,\n",
    "    weights,\n",
    "    epoch_number,\n",
    "    num_params,\n",
    "    utype,\n",
    "    model_name,\n",
    "    num_trajectories,\n",
    "    furuta_type,\n",
    "    noise_std,\n",
    "    grad_clip,\n",
    "    lr_schedule,\n",
    "    C_q1,\n",
    "    C_q2,\n",
    "    horizon,\n",
    "    min_max_rescale,\n",
    ")\n",
    "\n",
    "# print some information on the training and file name\n",
    "print(\"Total number of epochs:\", epoch_number)\n",
    "print(\"H_net number of parameters :\", num_params)\n",
    "print(\"Save file prefix : \", save_prefix)\n",
    "\n",
    "# Sanity check\n",
    "is_same_size(horizon_list, switch_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kNWhxamnCc0U",
    "outputId": "d05cb4d4-505b-42af-c97f-ff4a0eb7e61e"
   },
   "outputs": [],
   "source": [
    "stats = train(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    Ts=Ts,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    w=torch.tensor(weights, device=device),\n",
    "    grad_clip=grad_clip,\n",
    "    lr_schedule=lr_schedule,\n",
    "    begin_decay=begin_decay,\n",
    "    resnet_config=resnet_config,\n",
    "    epoch_number=epoch_number,\n",
    "    alternating=alternating,\n",
    "    horizon=horizon,\n",
    "    horizon_type=horizon_type,\n",
    "    horizon_list=horizon_list,\n",
    "    switch_steps=switch_steps,\n",
    "    epochs=epoch_number,\n",
    "    loss_type=loss_type,\n",
    "    collect_grads=collect_grads,\n",
    "    rescale_loss=rescale_loss,\n",
    "    rescale_dims=rescale_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38opHVq2Cc0V"
   },
   "outputs": [],
   "source": [
    "if collect_grads:\n",
    "    plot_grads(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPxjhso4Cc0V"
   },
   "outputs": [],
   "source": [
    "# set all paths and create folders :\n",
    "model_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "stats_path = PATH + \"data/\" + save_prefix + \"/\"\n",
    "plot_path = PATH + \"data/\" + save_prefix + \"/img/\"\n",
    "train_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "test_loader_path = PATH + \"data/\" + save_prefix + \"/datasets/\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(stats_path, exist_ok=True)\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "os.makedirs(train_loader_path, exist_ok=True)\n",
    "os.makedirs(test_loader_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHu5CdZlCc0V"
   },
   "outputs": [],
   "source": [
    "torch.save(train_loader, train_loader_path + \"train_loader.pt\")\n",
    "if test_loader is not None:\n",
    "    torch.save(test_loader, test_loader_path + \"test_loader.pt\")\n",
    "\n",
    "# save model to disk\n",
    "torch.save(model.state_dict(), model_path + \"model\")\n",
    "\n",
    "# save the stats\n",
    "save_stats(stats, stats_path + \"stats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LogFLihtCc0W"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.load(train_loader_path)\n",
    "# test_loader = torch.load(test_loader_path)\n",
    "# # loads the stats\n",
    "# stats = read_dict(PATH, stats_path)\n",
    "# # load the model from disk\n",
    "# model.load_state_dict(torch.load(PATH+model_path))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "NrSHBNwvCc0W",
    "outputId": "8953cab8-51be-4aa5-a0ec-24a8cc0636f8"
   },
   "outputs": [],
   "source": [
    "loss_train = stats[\"train_loss\"]\n",
    "loss_test = stats[\"test_loss\"]\n",
    "epochs = np.arange(len(loss_train))\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=False,\n",
    "    switch_steps=switch_steps,\n",
    ")\n",
    "\n",
    "train_test_loss_plot(\n",
    "    loss_train,\n",
    "    loss_test,\n",
    "    epochs,\n",
    "    file_path=plot_path + \"/LOSS_train_test_warrows.png\",\n",
    "    title=\"train and test loss per epoch\",\n",
    "    horizons=horizon_list[:-1],\n",
    "    switch_steps=switch_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SIZix06YCc0W",
    "outputId": "96c31349-ca4d-4081-c25d-45d1f131f401"
   },
   "outputs": [],
   "source": [
    "# show train and prediction\n",
    "for n in [0, 5, 10, 19]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=time_steps,\n",
    "        show_pred=True,\n",
    "        H_or_Input=\"input\",\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "AlVaj6o4Cc0X",
    "outputId": "40e0fc45-f9c2-43fe-e913-49b0429de6b0"
   },
   "outputs": [],
   "source": [
    "# show only training portion\n",
    "for n in [0, 50, 70]:\n",
    "    plot_furuta_hat_nom(\n",
    "        device,\n",
    "        model,\n",
    "        u_func,\n",
    "        g_func,\n",
    "        utype,\n",
    "        gtype,\n",
    "        data_loader_t=train_loader,\n",
    "        t_max=horizon_list[-1],\n",
    "        n=n,\n",
    "        C_q1=C_q1,\n",
    "        C_q2=C_q2,\n",
    "        g=g,\n",
    "        Jr=Jr,\n",
    "        Lr=Lr,\n",
    "        Mp=Mp,\n",
    "        Lp=Lp,\n",
    "        t_plot=horizon_list[-1],\n",
    "        show_pred=False,\n",
    "        title=\"Train set trajectories\",\n",
    "        file_path=plot_path + \"/TRAJECTORIES_train_set\" + str(n) + \".png\",\n",
    "        w_rescale=w_rescale,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "AltpEqt8UqNk",
    "Y3F0sJ8GMaP-",
    "xeWufKhKrZJF",
    "jvH00uYvxr-7",
    "v_FTm0Slrsby"
   ],
   "name": "furuta_pendulum_simpleHNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "52b0f3b5fff4e2d99607e23e4ce3f8b9e3a664acf6541783ed53f1bd22095b69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
