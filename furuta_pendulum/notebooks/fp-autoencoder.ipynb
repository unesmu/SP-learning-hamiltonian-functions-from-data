{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "OJsZuo6FXokO",
      "metadata": {
        "id": "OJsZuo6FXokO"
      },
      "source": [
        "Some code in this notebook has been adapted from the work of Zhongy et al. and Greydanus et al. and from the report and code of Jonas Perolini.\n",
        "\n",
        "Their code is available in the following repositories :[\n",
        "Symplectic-ODENet](https://github.com/Physics-aware-AI/Symplectic-ODENet) and [hamiltonian-nn](https://github.com/greydanus/hamiltonian-nn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "651a123d",
      "metadata": {},
      "source": [
        "# Imports & Setting up directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329d7221",
      "metadata": {
        "id": "329d7221"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    PATH = \"./\"  # './drive/MyDrive/1_SP_Ham_func/'\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    %cd /content/drive/MyDrive/1_SP_Ham_func/furuta_pendulum/\n",
        "    %pip install torchdiffeq\n",
        "    from src.data import *\n",
        "    from src.dynamics import *\n",
        "    from src.models import *\n",
        "    from src.train import *\n",
        "    from src.plots import *\n",
        "    from src.trajectories import *\n",
        "    from src.utils import *\n",
        "    from src.autoencoder_train import *\n",
        "    from src.autoencoder_plots import *\n",
        "else:\n",
        "    import sys\n",
        "\n",
        "    sys.path.insert(0, \"..\")\n",
        "    import os\n",
        "\n",
        "    PATH = \"../\"\n",
        "    from src.data import *\n",
        "    from src.dynamics import *\n",
        "    from src.models import *\n",
        "    from src.train import *\n",
        "    from src.plots import *\n",
        "    from src.trajectories import *\n",
        "    from src.utils import *\n",
        "    from src.autoencoder_train import *\n",
        "    from src.autoencoder_plots import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dnOJ60QMy2ZQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnOJ60QMy2ZQ",
        "outputId": "f983d1b3-3596-452a-9b70-7225f87e3334"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch\n",
        "\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "\n",
        "from torchdiffeq import odeint_adjoint as odeint_adjoint\n",
        "\n",
        "# func must be a nn.Module when using the adjoint method\n",
        "from torchdiffeq import odeint as odeint\n",
        "\n",
        "import time as time\n",
        "import json\n",
        "import os\n",
        "\n",
        "# setting seeds\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faac0224",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1y8C45De-exi",
      "metadata": {
        "id": "1y8C45De-exi"
      },
      "source": [
        "#### AE alone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb495bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "set_all_seeds(manualSeed=123, new_results=False)\n",
        "device = set_device()  # set it to gpu if it is available\n",
        "\n",
        "# Parameters to generate the dataset\n",
        "furuta_type = \"fake\"  # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which=furuta_type)\n",
        "utype = None  # 'chirp' or 'sine' or 'tanh' or 'multisine' or 'step' or None\n",
        "u_func = U_FUNC(utype=utype)  # instantiate the input function u(t)\n",
        "u_func.params[\"T\"] = 1.5\n",
        "u_func.params[\"f0\"] = 0\n",
        "u_func.params[\"f1\"] = 2  # 4 # 1.4\n",
        "u_func.params[\"scale\"] = 0.0001  # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = None  # 'simple' or None\n",
        "# instantiate the input function G(q,p) (here it is constant)\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = \"random_nozero\"  # 'random_nozero' # 'random_closetopi'\n",
        "time_steps = 800  # length of a trajectory\n",
        "num_trajectories = 125  # number of trajectories in total\n",
        "proportion = 0.8  # train test proportion\n",
        "batch_size = 100  # batch size used by dataloader\n",
        "w_rescale = [1, 1000, 1, 10000]  # [1, 1000, 1, 10000]  # [1, 9000, 1, 10000]\n",
        "shuffle = False  # shuffle sample in the batches between epochs\n",
        "# 'hamiltonian' or 'newtonian', newtonian if you want [q1,q1_dot,q2,q2_dot]\n",
        "coord_type = \"newtonian\"\n",
        "min_max_rescale = False  # rescale the training trajectories\n",
        "# which dimensions to rescale if using min_max_rescale, so that nothing is divided by zero\n",
        "rescale_dims = [1, 1, 1, 1]\n",
        "\n",
        "# Parameters for the training procedure\n",
        "resnet_config = None\n",
        "alternating = False  # for Input_HNN, if G is a neural network, train\n",
        "horizon_type = \"auto\"  # 'auto' or 'constant'\n",
        "horizon = False  # if horizon_type == 'constant', use this horizon\n",
        "loss_type = \"L2\"  # 'L2' or 'L2weighted'\n",
        "collect_grads = False  # collect gradients in all layers at every epoch\n",
        "# rescale the difference between nominal and train by the min max of train trajectory in loss function\n",
        "rescale_loss = False\n",
        "grad_clip = True  # activate gradient clipping\n",
        "lr_schedule = False  # activate lr schedule\n",
        "begin_decay = 600  # epoch at which lr starts decaying\n",
        "weights = [1.0, 1.0, 1.0, 1.0]  # weights for the loss functions\n",
        "\n",
        "horizon_list = [300]\n",
        "switch_steps = [500]\n",
        "epoch_number = sum(switch_steps)  # total number of training epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d2cc0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader, test_loader = load_data_device(\n",
        "    device,\n",
        "    init_method,\n",
        "    w_rescale,\n",
        "    u_func,\n",
        "    g_func,\n",
        "    time_steps,\n",
        "    shuffle=shuffle,\n",
        "    num_trajectories=num_trajectories,\n",
        "    coord_type=coord_type,\n",
        "    proportion=proportion,\n",
        "    batch_size=batch_size,\n",
        "    Ts=Ts,\n",
        "    noise_std=noise_std,\n",
        "    C_q1=C_q1,\n",
        "    C_q2=C_q2,\n",
        "    g=g,\n",
        "    Jr=Jr,\n",
        "    Lr=Lr,\n",
        "    Mp=Mp,\n",
        "    Lp=Lp,\n",
        "    min_max_rescale=min_max_rescale,\n",
        "    rescale_dims=rescale_dims,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4IN3FfZk97Mj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IN3FfZk97Mj",
        "outputId": "94fe1d1e-6608-4e42-d3ba-27e94b8bb6ad"
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder(nb_hidden_layers=1,  hidden_dim=90, activation='tanh', config = 'latent') # 'x+sin(x)^2'\n",
        "autoencoder.to(device)\n",
        "count_parameters(autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4naDNg4T5-ds",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4naDNg4T5-ds",
        "outputId": "d0a2cf59-9bd4-4b86-82bb-c79dee1b98e1"
      },
      "outputs": [],
      "source": [
        "H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4, output_dim=1, activation=\"x+sin(x)^2\")\n",
        "model = simple_HNN(input_dim=4, H_net=H_net, device=None)\n",
        "model.to(device)\n",
        "\n",
        "num_params = count_parameters(model)\n",
        "print(num_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TqM0EsJw97tg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TqM0EsJw97tg",
        "outputId": "196da4a4-3f0c-425e-da8a-e9c9182fb29d"
      },
      "outputs": [],
      "source": [
        "stats_2 = train_only_ae(autoencoder, \n",
        "                        model, \n",
        "                        device,\n",
        "                        train_loader, \n",
        "                        test_loader, \n",
        "                        epochs= 1000, # 3000\n",
        "                        horizon=300, \n",
        "                        lr = 1e-3,\n",
        "                        w = torch.tensor([10.0,  1.0, 100.0, 1.0],device=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f1c329",
      "metadata": {},
      "source": [
        "### plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a94b9eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_distribution(train_loader, save=False, path=PATH+'data/ae_distributions.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yGi7Aeya-toW",
      "metadata": {
        "id": "yGi7Aeya-toW"
      },
      "source": [
        "#### AE and Latent_ODE_HNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-OASXIn_97nV",
      "metadata": {
        "id": "-OASXIn_97nV"
      },
      "outputs": [],
      "source": [
        "# model = load_model()\n",
        "# count_parameters(model)\n",
        "\n",
        "# autoencoder = Autoencoder(nb_hidden_layers=1,  hidden_dim=64, activation='tanh', config = 'encoded') # 'x+sin(x)^2'\n",
        "# autoencoder.to(device)\n",
        "# count_parameters(autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "enbFbeQSDgd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enbFbeQSDgd0",
        "outputId": "6b5a99a4-d95c-4eda-cdcc-bc547e0c527d"
      },
      "outputs": [],
      "source": [
        "horizon_list = [20,50,70,90,110,130,150,170,190,210,230,250,270,290,300]\n",
        "switch_steps = [200,500,500,200,200,200,200,300,300,200,200,200,200,200,200]\n",
        "epoch_number = sum(switch_steps)\n",
        "print(epoch_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C9508kgupb14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C9508kgupb14",
        "outputId": "d386b343-2ddd-4a46-d053-8f47c8710a45"
      },
      "outputs": [],
      "source": [
        "stats =  train_ae(model,\n",
        "                  device,\n",
        "                  autoencoder, \n",
        "                  train_loader, \n",
        "                  test_loader, \n",
        "                  Ts, \n",
        "                  horizon = False, \n",
        "                  horizon_type = 'auto',\n",
        "                  horizon_list = horizon_list, \n",
        "                  switch_steps = switch_steps,\n",
        "                  steps_ae = 0,\n",
        "                  epoch_number = epoch_number,\n",
        "                  w=torch.tensor([10.0,  1.0, 100.0, 1.0], device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gFhe8N5gsuUr",
      "metadata": {
        "id": "gFhe8N5gsuUr"
      },
      "outputs": [],
      "source": [
        "## saving stats to txt file\n",
        "import json\n",
        "\n",
        "PATH = './drive/MyDrive/1_SP_Ham_func/'\n",
        "stats_path = PATH+'stats/'+save_prefix+'stats.txt'\n",
        "\n",
        "def save_stats(PATH, stats, stats_path):\n",
        "    with open(stats_path, 'w') as file:\n",
        "        file.write(json.dumps(stats)) # use `json.loads` to do the reverse  \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BIGVlEaABtCQ",
      "metadata": {
        "id": "BIGVlEaABtCQ"
      },
      "outputs": [],
      "source": [
        "# save model to disk\n",
        "\n",
        "save_prefix = 'UODEHNN_usedwithae'\n",
        "model_name = 'models/'+save_prefix+'model_test'\n",
        "torch.save(model.state_dict(), PATH+model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O5vF_1YsO1U3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5vF_1YsO1U3",
        "outputId": "5b3f0e7a-3d8f-4e68-c26c-31b4eee2af12"
      },
      "outputs": [],
      "source": [
        "\n",
        "save_prefix = 'UODEHNN_usedwithae'\n",
        "model_name = 'models/'+save_prefix+'model_test'\n",
        "model = load_model(hidden_dim=90, nb_hidden_layers=4)\n",
        "model.load_state_dict(torch.load(PATH+model_name))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ahCPuiftswPP",
      "metadata": {
        "id": "ahCPuiftswPP"
      },
      "outputs": [],
      "source": [
        "# save AE model to disk\n",
        "\n",
        "save_prefix = 'AE'\n",
        "model_name = 'models/'+save_prefix+'model_test'\n",
        "torch.save(autoencoder.state_dict(), PATH+model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fNugCUfOz_0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fNugCUfOz_0",
        "outputId": "4065ce28-30fa-45ba-90f7-5ebed43b52cc"
      },
      "outputs": [],
      "source": [
        "save_prefix = 'AE'\n",
        "model_name = 'models/'+save_prefix+'model_test'\n",
        "autoencoder = Autoencoder(nb_hidden_layers=1,  hidden_dim=90, activation='tanh', config = 'latent') # 'x+sin(x)^2'\n",
        "autoencoder.to(device)\n",
        "\n",
        "autoencoder.load_state_dict(torch.load(PATH+model_name))\n",
        "autoencoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PHWhxeeItB-7",
      "metadata": {
        "id": "PHWhxeeItB-7"
      },
      "outputs": [],
      "source": [
        "save_stats(PATH+'aeonly', stats_2, stats_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zvUsHMpKsqwA",
      "metadata": {
        "id": "zvUsHMpKsqwA"
      },
      "outputs": [],
      "source": [
        "save_stats(PATH+'aeandHNNstats', stats, stats_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OeyiXulHsvM4",
      "metadata": {
        "id": "OeyiXulHsvM4"
      },
      "outputs": [],
      "source": [
        "torch.save(train_loader, PATH + 'train_loader.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2IsC9aPa3R5P",
      "metadata": {
        "id": "2IsC9aPa3R5P"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.load(PATH + 'train_loader.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbpztujcAcpb",
      "metadata": {
        "id": "bbpztujcAcpb"
      },
      "source": [
        "##### plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7NKGrnAaP6Ig",
      "metadata": {
        "id": "7NKGrnAaP6Ig"
      },
      "outputs": [],
      "source": [
        "train_steps=290\n",
        "n=70\n",
        "max_timestep= 800\n",
        "save_prefix = 'AUTOENCODER_MODEL_nozoom_n70_twoplots'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ft_SrlF4P6rE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "Ft_SrlF4P6rE",
        "outputId": "ecc27f77-a66e-4f67-bdd8-aa15504bf982"
      },
      "outputs": [],
      "source": [
        "plot_furuta_ae_twoplots(model, \n",
        "                        autoencoder, \n",
        "                        train_loader,\n",
        "                        max_timestep,\n",
        "                        n,\n",
        "                        train_steps, time_steps, device,\n",
        "                        Ts, C_q1, C_q2, g, Jr, Lr, Mp, Lp,\n",
        "                        title = 'Trajectory of the generalized coordinates', \n",
        "                        file_path = PATH+'data/'+save_prefix+'TRAJECTORIES_test_set')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Mk0nLvy7By6y"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('pds')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "52b0f3b5fff4e2d99607e23e4ce3f8b9e3a664acf6541783ed53f1bd22095b69"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
