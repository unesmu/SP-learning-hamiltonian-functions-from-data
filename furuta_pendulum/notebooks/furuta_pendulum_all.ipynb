{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy0mWdPersbg"
      },
      "source": [
        "Some code in this notebook has been adapted from the work of Zhongy et al. and Greydanus et al. and from the report and code of Jonas Perolini.\n",
        "\n",
        "Their code is available in the following repositories :[\n",
        "Symplectic-ODENet](https://github.com/Physics-aware-AI/Symplectic-ODENet) and [hamiltonian-nn](https://github.com/greydanus/hamiltonian-nn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd6pGmU-rsbk"
      },
      "source": [
        "# Imports & Setting up directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ioF4QRA1FEF",
        "outputId": "1bbd65c1-d7f2-44ec-934f-a11a3f8588bb"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:  \n",
        "    PATH = './' # './drive/MyDrive/1_SP_Ham_func/'\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/MyDrive/1_SP_Ham_func/\n",
        "    %pip install torchdiffeq\n",
        "else:\n",
        "    import sys; sys.path.insert(0, '..') \n",
        "    import os\n",
        "    PATH = '../'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "id": "6F69c4UZ_3U_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch\n",
        "\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "\n",
        "from torchdiffeq import odeint_adjoint as odeint_adjoint \n",
        "# func must be a nn.Module when using the adjoint method\n",
        "from torchdiffeq import odeint as odeint\n",
        "\n",
        "import time as time\n",
        "import json\n",
        "\n",
        "# setting seeds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install nbconvert\n",
        "# # converts notebook to .py file for pipreqs\n",
        "# !jupyter nbconvert --output-dir=\"./\" --to script furuta_pendulum.ipynb \n",
        "\n",
        "# %pip install pipreqs\n",
        "# # creates the requirement file\n",
        "# !pipreqs \n",
        "# os.remove('./furuta_pendulum.py')  # deletes the .py file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPvuTkGm-CRE"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_E3dAJS-XNv"
      },
      "source": [
        "## dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {
        "id": "Pt37hOnR-7JR"
      },
      "outputs": [],
      "source": [
        "def furuta_H(q1, p1, q2, p2, g, Jr, Lr, Mp, Lp):\n",
        "    '''\n",
        "    Description:\n",
        "      Hamiltonian function for the Furuta pendulum \n",
        "    Inputs : \n",
        "      - q1,p1,q2,p2 (tensors) : Generalized coordinates \n",
        "    Outputs : \n",
        "      - H (tensor) : Hamiltonian function \n",
        "    Credits : \n",
        "      - Equations & constants are from Jonas's report\n",
        "    '''\n",
        "\n",
        "    # system constants\n",
        "    Jp = (1/12)*Mp*Lp**2\n",
        "\n",
        "    # function constants\n",
        "    C1 = Jr + Mp*Lr**2\n",
        "    C2 = (1/4)*Mp*Lp**2\n",
        "    C3 = (-1/2)*Mp*Lp*Lr\n",
        "    C4 = Jp+C2\n",
        "    C5 = (1/2)*Mp*g*Lp\n",
        "\n",
        "    # hamiltonian function\n",
        "    # print('furuta_H','C4*p2**2',(C4*p2**2).shape)\n",
        "    # print('furuta_H','C2*torch.sin(q1)**2 ',(C2*torch.sin(q1)**2 ).shape)\n",
        "    # print('furuta_H','2*p1*p2*C3*torch.cos(q1)',(2*p1*p2*C3*torch.cos(q1)).shape)\n",
        "    H = p1**2 * (C1+C2*torch.sin(q1)**2) + C4*p2**2-2*p1*p2*C3*torch.cos(q1)\n",
        "    H = (1/2) * (H)/(C1*C4+C4*C2*torch.sin(q1)\n",
        "                     ** 2 - (C3**2) * (torch.cos(q1)**2))\n",
        "    H = H + C5*(torch.cos(q1)+1)\n",
        "\n",
        "    return H\n",
        "\n",
        "\n",
        "def hamiltonian_fn_furuta(coords, g, Jr, Lr, Mp, Lp):\n",
        "    '''\n",
        "    Description:\n",
        "      Hamiltonian function for the Furuta pendulum, wraps furuta_H so that it is \n",
        "      the right format for ODEint\n",
        "\n",
        "    Inputs : \n",
        "      - coords (tensor) : vector containing generalized coordinates q1,p1,q2,p2\n",
        "\n",
        "    Outputs :\n",
        "      - H (tensor) : Scalar Hamiltonian function\n",
        "\n",
        "    Credits : \n",
        "      This function takes the same structure as the one in the SymODEN repository\n",
        "    '''\n",
        "    q1, p1, q2, p2 = torch.chunk(coords, 4, dim=-1)  # torch.split(coords,1)\n",
        "    # print('hamiltonian_fn_furuta','coords',coords.shape)\n",
        "    # print('hamiltonian_fn_furuta','q1',q1.shape)\n",
        "    H = furuta_H(q1, p1, q2, p2, g, Jr, Lr, Mp, Lp)\n",
        "    # print('hamiltonian_fn_furuta','H',H.shape)\n",
        "    return H\n",
        "\n",
        "\n",
        "def coord_derivatives_furuta(t, coords, C_q1, C_q2, g, Jr, Lr, Mp, Lp, u_func, g_func):\n",
        "    '''\n",
        "    Description:\n",
        "        Returns the derivatives of the generalized coordinates\n",
        "\n",
        "    Inputs : \n",
        "      - coords (tensor) : vector containing generalized coordinates q1,p1,q2,p2\n",
        "      - C_q1 (float) : coefficient of friction related to p1 ( and q1)\n",
        "      - C_q2 (float) : coefficient of friction related to p2 ( and q2)\n",
        "\n",
        "    Outputs :\n",
        "      - dq1dt, dp1dt, dq2dt, dp2dt (tensors) : Derivatives w.r.t coords\n",
        "    '''\n",
        "    if coords.requires_grad is not True:\n",
        "        coords.requires_grad = True\n",
        "\n",
        "    # Hamiltonian function\n",
        "    H = hamiltonian_fn_furuta(coords, g, Jr, Lr, Mp, Lp)\n",
        "    # print('coord_derivatives_furuta','H',H.shape)\n",
        "    # print('coord_derivatives_furuta','coords',coords.shape)\n",
        "    # gradient of the hamiltornian function wrt the generalized coordinates\n",
        "    # !! might need to add H.sum() if batches used here later\n",
        "    dcoords = torch.autograd.grad(H.sum(), coords, create_graph=True)\n",
        "\n",
        "    # dHdq1, dHdp1, dHdq2, dHdp2 = torch.split(dcoords[0], 1)\n",
        "    dHdq1, dHdp1, dHdq2, dHdp2 = torch.chunk(dcoords[0], 4, dim=-1)\n",
        "    # print('coord_derivatives_furuta','dHdq1',dHdq1.shape)\n",
        "    U = u_func.forward(t)\n",
        "    G = g_func.forward(coords)\n",
        "    # print('coord_derivatives_furuta','U',U.shape)\n",
        "    # print('coord_derivatives_furuta','G',G.shape)\n",
        "    # print('coord_derivatives_furuta','U * G[1]',(U * G[:,1]).shape)\n",
        "    # print('coord_derivatives_furuta','U * G[0]',(U * G[:,0]).shape)\n",
        "    # print('coord_derivatives_furuta','C_q1*dHdp1',(C_q1*dHdp1).shape)\n",
        "    # print('coord_derivatives_furuta','U * G[:,0].unsqueeze(dim=-1)',((U * G[:,0]).unsqueeze(dim=-1)).shape)\n",
        "    # print('coord_derivatives_furuta','U * G[:,0].unsqueeze(dim=1)',((U * G[:,0]).unsqueeze(dim=1)).shape)\n",
        "    dq1dt = dHdp1 + (U * G[:, 0]).unsqueeze(dim=1)\n",
        "    dp1dt = - dHdq1 - C_q1*dHdp1 + (U * G[:, 1]).unsqueeze(dim=1)\n",
        "    dq2dt = dHdp2 + (U * G[:, 2]).unsqueeze(dim=1)\n",
        "    dp2dt = - dHdq2 - C_q2*dHdp2 + (U * G[:, 3]).unsqueeze(dim=1)\n",
        "    # print('coord_derivatives_furuta','dq1dt',dq1dt.shape)\n",
        "    # print('coord_derivatives_furuta','dp1dt',dp1dt.shape)\n",
        "    return dq1dt, dp1dt, dq2dt, dp2dt\n",
        "\n",
        "\n",
        "def dynamics_fn_furuta(t, coords, C_q1, C_q2, g, Jr, Lr, Mp, Lp, u_func, g_func):\n",
        "    '''\n",
        "    Description:\n",
        "    Function that returns the gradient (in form of a function) of a Hamiltonian function\n",
        "    Inputs : \n",
        "      - t () : \n",
        "      - coords () : generalized coordinates\n",
        "      - u () : system input\n",
        "      - C () : dissipation coefficient\n",
        "\n",
        "    Outputs :\n",
        "      - S () : Symplectic gradient\n",
        "\n",
        "    Credits : \n",
        "      - This function has a similar structure as the one in the SymODEN repository\n",
        "    '''\n",
        "\n",
        "    dq1dt, dp1dt, dq2dt, dp2dt = coord_derivatives_furuta(\n",
        "        t, coords, C_q1, C_q2, g, Jr, Lr, Mp, Lp, u_func, g_func)\n",
        "\n",
        "    S = torch.hstack((dq1dt, dp1dt, dq2dt, dp2dt))\n",
        "    return S\n",
        "\n",
        "\n",
        "''' Input functions '''\n",
        "\n",
        "\n",
        "def chirp_fun(t, T=1.5, f0=1, f1=50, scale=1):\n",
        "    # https://en.wikipedia.org/wiki/Chirp\n",
        "    c = (f1-f0)/T\n",
        "    return torch.sin(2*torch.pi*(c*t**2/2 + f0*t))*scale\n",
        "\n",
        "\n",
        "def multi_sine(t, scale=0.5):\n",
        "    f = torch.tensor([2, 10, 3, 4], device=t.device).unsqueeze(dim=1)\n",
        "    A = torch.tensor([2, 0.5, 0.3, 0.8], device=t.device).unsqueeze(dim=1)\n",
        "    return (A*torch.sin(2*torch.pi*t*f)).sum(dim=0)*scale\n",
        "\n",
        "\n",
        "def sine_fun(t, scale=0.5, f=1):\n",
        "    return (scale*torch.sin(2*torch.pi*t*f))\n",
        "\n",
        "\n",
        "def step_fun(t, t1=0.05, scale=0.1):\n",
        "    f = torch.zeros_like(t)\n",
        "    f[t < t1] = 0\n",
        "    f[~(t < t1)] = scale\n",
        "    return f\n",
        "\n",
        "\n",
        "class U_FUNC():\n",
        "    def __init__(self, utype=None, params={}):\n",
        "        super(U_FUNC).__init__()\n",
        "        self.utype = utype\n",
        "        self.params = params  # dict containing parameters for the input function\n",
        "        self.params['T'] = 1.5\n",
        "        self.params['f0'] = 1\n",
        "        self.params['f1'] = 10\n",
        "        self.params['scale'] = 1\n",
        "\n",
        "    def forward(self, t):\n",
        "        ''' time dependent input '''\n",
        "        if self.utype == 'chirp':\n",
        "            u = chirp_fun(t,\n",
        "                          T=self.params['T'],\n",
        "                          f0=self.params['f0'],\n",
        "                          f1=self.params['f1'],\n",
        "                          scale=self.params['scale'])\n",
        "        elif self.utype == 'sine':\n",
        "            u = sine_fun(t, scale=self.params['scale'], f=self.params['f1'])\n",
        "        elif self.utype == 'tanh':\n",
        "            u = (-torch.tanh((t-0.75)*4)+1)/100\n",
        "        elif self.utype == 'multisine':\n",
        "            u = multi_sine(t, scale=self.params['scale'])\n",
        "        elif self.utype == 'step':\n",
        "            u = step_fun(t, t1=0.5)\n",
        "        elif self.utype is None:\n",
        "            u = torch.zeros(t.shape, device=t.device)\n",
        "        u.requires_grad = False\n",
        "        return u\n",
        "\n",
        "\n",
        "class G_FUNC():\n",
        "    def __init__(self, gtype=None, params={}):\n",
        "        super(G_FUNC).__init__()\n",
        "        self.gtype = gtype\n",
        "        self.params = params  # dict containing params on\n",
        "        self.params['q_ref'] = torch.tensor([1.0], device=device)\n",
        "\n",
        "    def forward(self, coords):\n",
        "        ''' state dependent input '''\n",
        "        q1, p1, q2, p2 = torch.split(coords, 1, dim=-1)\n",
        "        if self.gtype == 'simple':\n",
        "            if len(q1.shape) == 1:\n",
        "                dimension = 0\n",
        "            else:\n",
        "                dimension = 1\n",
        "            g = torch.stack((torch.zeros(q1.shape[0], device=q1.device),  # (q1,p1,q2,p2)\n",
        "                             torch.ones(q1.shape[0], device=q1.device),\n",
        "                             torch.zeros(q1.shape[0], device=q1.device),\n",
        "                             torch.ones(q1.shape[0], device=q1.device)), dim=dimension)\n",
        "\n",
        "        # if self.gtype=='setpoint':\n",
        "        #     if len(q.shape)==1:\n",
        "        #         dimension = 0\n",
        "        #     else:\n",
        "        #         dimension = 1\n",
        "        #     g = torch.stack((torch.zeros(q.shape[0]),torch.ones(q.shape[0])*q-self.params['q_ref']), dim=dimension)\n",
        "\n",
        "        elif self.gtype is None:\n",
        "            if len(q1.shape) == 1:\n",
        "                dimension = 0\n",
        "            else:\n",
        "                dimension = 1\n",
        "            g = torch.stack((torch.zeros(q1.shape[0], device=q1.device),  # (q1,p1,q2,p2)\n",
        "                             torch.zeros(q1.shape[0], device=q1.device),\n",
        "                             torch.zeros(q1.shape[0], device=q1.device),\n",
        "                            torch.zeros(q1.shape[0], device=q1.device)), dim=dimension)\n",
        "            # g = torch.zeros((4, q1.shape[0]), device = q1.device)\n",
        "        g.requires_grad = False\n",
        "        return g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq5yMx-F-Yuq"
      },
      "source": [
        "## trajectories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhoX0eLVADYw"
      },
      "source": [
        "### single/multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {
        "id": "agHuWM8BADH0"
      },
      "outputs": [],
      "source": [
        "'''Functions to generate the trajectories'''\n",
        "\n",
        "\n",
        "def get_trajectory_furuta(device, init_method, num_trajectories, u_func=None, g_func=None, time_steps=20, y0=None, noise_std=0.0, Ts=0.005, C_q1=0.0,\n",
        "                          C_q2=0.0, g=9.81, Jr=5.72*1e-5, Lr=0.085, Mp=0.024, Lp=0.129):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outputs:\n",
        "    '''\n",
        "\n",
        "    # sampling time\n",
        "\n",
        "    t_eval = torch.linspace(1, time_steps, time_steps,\n",
        "                            device=device) * Ts  # evaluated times vector\n",
        "    t_span = [Ts, time_steps*Ts]  # [t_start, t_end]\n",
        "\n",
        "    # get initial state\n",
        "    if y0 is None:\n",
        "        y0 = get_init_state(num_trajectories, init_method)\n",
        "        y0 = y0.to(device)\n",
        "\n",
        "    # solve the differential equation using odeint\n",
        "    q_p = odeint(func=lambda t, coords: dynamics_fn_furuta(t, coords, C_q1, C_q2, g, Jr, Lr, Mp, Lp, u_func, g_func),\n",
        "                 y0=y0, t=t_eval, method='rk4', options=dict(step_size=Ts))\n",
        "\n",
        "    q1, p1, q2, p2 = torch.chunk(q_p, 4, dim=-1)\n",
        "\n",
        "    # q1, p1, q2, p2 = torch.chunk(q_p, 4, 1)\n",
        "\n",
        "    # u = u_func.forward(t_eval)\n",
        "    # g = g_func.forward(q_p)\n",
        "\n",
        "    # add noise\n",
        "    if noise_std:\n",
        "        q1 = (q1+torch.randn(q1.shape, device=device)*noise_std)\n",
        "        p1 = (p1+torch.randn(p1.shape, device=device)*noise_std*torch.max(p1))\n",
        "        q2 = (q2+torch.randn(q2.shape, device=device)*noise_std)\n",
        "        p2 = (p2+torch.randn(p2.shape, device=device)*noise_std*torch.max(p2))\n",
        "    # print('q1',q1.shape)\n",
        "    # if not num_trajectories == 1 :\n",
        "    q1 = q1.squeeze(dim=-1).detach()\n",
        "    p1 = p1.squeeze(dim=-1).detach()\n",
        "    q2 = q2.squeeze(dim=-1).detach()\n",
        "    p2 = p2.squeeze(dim=-1).detach()\n",
        "\n",
        "    # .detach() because the pytorch computational graph is no longer needed\n",
        "    # only the value is needed\n",
        "    # .squeeze() to have a desired dimentionality\n",
        "    # *torch.max(p) otherwise noise is too big compared to the generalized momentum\n",
        "\n",
        "    # if num_trajectories == 1 :\n",
        "    #     # so that the vectors will have the correct dimensions if only 1\n",
        "    #     # trajectory is requested\n",
        "    #     q1 = q1.unsqueeze(dim=0)\n",
        "    #     p1 = p1.unsqueeze(dim=0)\n",
        "    #     q2 = q2.unsqueeze(dim=0)\n",
        "    #     p2 = p2.unsqueeze(dim=0)\n",
        "\n",
        "    q1, p1, q2, p2 = q1.permute(1, 0), p1.permute(\n",
        "        1, 0), q2.permute(1, 0), p2.permute(1, 0)\n",
        "\n",
        "    return q1, p1, q2, p2, t_eval.detach()  # u, g, q1, p1, q2, p2, t_eval.detach()\n",
        "\n",
        "def get_init_state(n, init_method):\n",
        "    '''\n",
        "      Returns initial states q1,p1,q2,p2 for the Furuta pendulum \n",
        "      The angular velocities ( /generalized momenmtums) are set to zero\n",
        "    Inputs : \n",
        "      None\n",
        "    Outputs : \n",
        "      y0(tensor) : inital condition\n",
        "\n",
        "    '''\n",
        "\n",
        "    y0 = torch.zeros(n, 4)\n",
        "\n",
        "    if init_method == 'random_nozero':\n",
        "        x = torch.ones(n)\n",
        "        mask = torch.full((n,), fill_value=0.5).bernoulli().bool()\n",
        "        x[mask] = torch.zeros(len(x[mask])).uniform_(0.3, 2)\n",
        "        x[~mask] = torch.zeros(len(x[~mask])).uniform_(-2, -0.3)\n",
        "    elif init_method == 'random_closetozero':\n",
        "        x = torch.zeros(n).uniform_(-0.3, 0.3)\n",
        "    elif init_method == 'random_closetopi':\n",
        "        x = torch.zeros(n).uniform_(torch.pi-0.3, torch.pi+0.3)\n",
        "    elif init_method == 'random_nozero_pos':\n",
        "        x = torch.zeros(y0.shape[0]).uniform_(0.3, 2)\n",
        "    elif init_method == 'random_closetopi_pos':\n",
        "        x = torch.zeros(n).uniform_(torch.positive, torch.pi+0.3)\n",
        "\n",
        "    y0[:, 0] = x\n",
        "\n",
        "    # random_uniform_two_interval() centered around pi\n",
        "    y0[:, 2] = torch.zeros(n).uniform_(torch.pi-1, torch.pi+1)\n",
        "\n",
        "    y0[:, 1] = torch.zeros(n)  # p1 = 0\n",
        "    y0[:, 3] = torch.zeros(n)  # p2 = 0\n",
        "\n",
        "    return y0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeKAyrylAGJO"
      },
      "source": [
        "### energy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {
        "id": "_tCkBsI7AFb_"
      },
      "outputs": [],
      "source": [
        "''' ENERGY functions '''\n",
        "\n",
        "def coord_derivatives_furuta_energy(t, coords, C_q1, C_q2, g, Jr, Lr, Mp, Lp, u_func, g_func):\n",
        "    '''\n",
        "    Description:\n",
        "        Returns the derivatives of the generalized coordinates\n",
        "\n",
        "    Inputs : \n",
        "      - coords (tensor) : vector containing generalized coordinates q1,p1,q2,p2\n",
        "      - C_q1 (float) : coefficient of friction related to p1 ( and q1)\n",
        "      - C_q2 (float) : coefficient of friction related to p2 ( and q2)\n",
        "\n",
        "    Outputs :\n",
        "      - dq1dt, dp1dt, dq2dt, dp2dt (tensors) : Derivatives w.r.t coords\n",
        "    '''\n",
        "    if coords.requires_grad is not True:  # coords shape: [timesteps, batchnum, (q1,p1,q2,p2)]\n",
        "        coords.requires_grad = True\n",
        "\n",
        "    # Hamiltonian function\n",
        "    H = hamiltonian_fn_furuta(coords, g, Jr, Lr, Mp, Lp)\n",
        "\n",
        "    # gradient of the hamiltornian function wrt the generalized coordinates\n",
        "    # !! might need to add H.sum() if batches used here later\n",
        "    dcoords = torch.autograd.grad(H.sum(), coords, create_graph=True)\n",
        "    # dcoords_temp[0]\n",
        "    # print('coord_derivatives_furuta','dcoords[0]',dcoords[0].shape)\n",
        "    dHdq1, dHdp1, dHdq2, dHdp2 = torch.chunk(dcoords[0], 4, dim=-1)\n",
        "\n",
        "    U = u_func.forward(t)\n",
        "    G = g_func.forward(coords)\n",
        "    if not G.shape[0] == 1:\n",
        "        G = G[0, :].unsqueeze(dim=0)\n",
        "    # print('coord_derivatives_furuta','H',H.shape)\n",
        "    # print('coord_derivatives_furuta','coords',coords.shape)\n",
        "    # print('coord_derivatives_furuta','dHdq1',dHdq1.shape)\n",
        "    # print('coord_derivatives_furuta','U',U.shape)\n",
        "    # print('coord_derivatives_furuta','G',G.shape)\n",
        "    # print('coord_derivatives_furuta','U * G[1]',(U * G[:,1]).shape)\n",
        "    # print('coord_derivatives_furuta','U * G[0]',(U * G[:,0]).shape)\n",
        "    # print('coord_derivatives_furuta','C_q1*dHdp1',(C_q1*dHdp1).shape)\n",
        "    # print('coord_derivatives_furuta','U * G[:,0].unsqueeze(dim=-1)',((U * G[:,0]).unsqueeze(dim=-1)).shape)\n",
        "    # print('coord_derivatives_furuta','U * G[:,0].unsqueeze(dim=1)',((U * G[:,0]).unsqueeze(dim=1)).shape)\n",
        "\n",
        "    # if not len(dHdp1.shape)==2: # to make broadcasting possible\n",
        "    #     dHdq1 , dHdp1, dHdq2 , dHdp2 = dHdp1.squeeze(),dHdq1.squeeze(),dHdp2.squeeze() ,dHdq2.squeeze()\n",
        "    # print('coord_derivatives_furuta','dHdq1',dHdq1.shape)\n",
        "    # print('coord_derivatives_furuta','C_q1*dHdp1',(C_q1*dHdp1).shape)\n",
        "\n",
        "    U_G = (U.unsqueeze(dim=-1) * G).unsqueeze(dim=-1)\n",
        "\n",
        "    # print('coord_derivatives_furuta','U_G',U_G.shape)\n",
        "    # print('coord_derivatives_furuta','U_G[:,0]',U_G[:,0].shape)\n",
        "\n",
        "    dq1dt = dHdp1 + (U_G[:, 0])\n",
        "    dp1dt = - dHdq1 - C_q1*dHdp1 + (U_G[:, 1])\n",
        "    dq2dt = dHdp2 + (U_G[:, 2])\n",
        "    dp2dt = - dHdq2 - C_q2*dHdp2 + (U_G[:, 3])\n",
        "\n",
        "    dq1dt, dp1dt, dq2dt, dp2dt = dq1dt.squeeze(\n",
        "        dim=-1), dp1dt.squeeze(dim=-1), dq2dt.squeeze(dim=-1), dp2dt.squeeze(dim=-1)\n",
        "    return dq1dt, dp1dt, dq2dt, dp2dt\n",
        "\n",
        "def energy_furuta(dq1dt, dq2dt, q1, g, Jr, Lr, Mp, Lp):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "    # system constants\n",
        "    Jp = (1/12)*Mp*Lp**2\n",
        "\n",
        "    # function constants\n",
        "    C1 = Jr + Mp*Lr**2\n",
        "    C2 = (1/4)*Mp*Lp**2\n",
        "    C3 = (-1/2)*Mp*Lp*Lr\n",
        "    C4 = Jp+C2\n",
        "    C5 = (1/2)*Mp*g*Lp\n",
        "\n",
        "    E = (1/2) * dq2dt**2 * (C1+C2*torch.sin(q1)**2) + \\\n",
        "        dq2dt*dq1dt*C3*torch.cos(q1)\n",
        "    # print('energy_furuta','dq2dt',dq2dt.shape)\n",
        "    # print('energy_furuta','torch.sin(q1)**2',(torch.sin(q1)**2).shape)\n",
        "    # print('energy_furuta','E',E.shape)\n",
        "    E = E + (1/2)*dq1dt**2 * C4+C5*torch.cos(q1)+C5\n",
        "    # print('energy_furuta','E',E.shape)\n",
        "    return E\n",
        "\n",
        "\n",
        "def get_energy_furuta(device, time_steps, Ts, u_func, g_func, q1, p1, q2, p2, C_q1, C_q2, g, Jr, Lr, Mp, Lp, time_=None):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "    energy = []\n",
        "    derivatives = []\n",
        "    if time_ is None:\n",
        "        time_ = torch.linspace(1, time_steps, time_steps, device=device) * Ts\n",
        "    # print('get_energy_furuta','q1',q1.shape)\n",
        "    coords = torch.stack((q1, p1, q2, p2), dim=-1)\n",
        "\n",
        "    dq1dt, dp1dt, dq2dt, dp2dt = coord_derivatives_furuta_energy(time_, coords,\n",
        "                                                                 C_q1, C_q2, g, Jr, Lr, Mp, Lp, u_func, g_func)\n",
        "    # if dq1dt.shape[1]==1:\n",
        "    #     q1 =  q1.unsqueeze(dim=-1)\n",
        "    # print('get_energy_furuta','dq1dt',dq1dt.shape)\n",
        "    # print('get_energy_furuta','q1',q1.shape)\n",
        "    energy = energy_furuta(dq1dt, dq2dt, q1, g, Jr, Lr, Mp, Lp)\n",
        "\n",
        "    derivatives = torch.stack((dq1dt, dp1dt, dq2dt, dp2dt), dim=-1)\n",
        "    return energy, derivatives\n",
        "\n",
        "\n",
        "# NOT TESTED !!!!!!!!!!!!!!!!!!!\n",
        "def get_energy_furuta_newtonian(q1, dq1dt, q2, dq2dt, C_q1, C_q2, g, Jr, Lr, Mp, Lp):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "    # energy=[]\n",
        "    # derivatives=[]\n",
        "    # for coords in torch.stack((q1, dq1dt, dq2dt),dim=1):\n",
        "\n",
        "    #   q1_n = coords[0]\n",
        "    #   dq1dt = coords[1]\n",
        "    #   dq2dt = coords[2]\n",
        "    #   energy.append(energy_furuta(dq1dt,dq2dt,q1_n, g, Jr, Lr, Mp, Lp))\n",
        "\n",
        "    # energy = torch.hstack(energy).detach()\n",
        "\n",
        "    energy = []\n",
        "    derivatives = []\n",
        "    t = torch.linspace(1, time_steps, time_steps, device=device) * Ts\n",
        "\n",
        "    energy = energy_furuta(dq1dt, dq2dt, q1, g, Jr, Lr, Mp, Lp)\n",
        "\n",
        "    # derivatives = torch.stack((dq1dt, dp1dt, dq2dt, dp2dt),dim=-1)\n",
        "\n",
        "    return energy, _\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItjgD4wyAHJ-"
      },
      "source": [
        "### multiple traj+energy wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "id": "vV3LC_Pc_xrN"
      },
      "outputs": [],
      "source": [
        "''' MULTIPLE TRAJECTORIES '''\n",
        "\n",
        "\n",
        "def multiple_trajectories_furuta(device, init_method, time_steps, num_trajectories, u_func=None, g_func=None,\n",
        "                                 y0=torch.tensor([1.0, 0.0, 1.0, 0.0]), Ts=0.005,\n",
        "                                 noise_std=0.0, C_q1=0.0, C_q2=0.0, g=9.81,\n",
        "                                 Jr=5.72*1e-5, Lr=0.085, Mp=0.024, Lp=0.129, energ_deriv=True):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "    # the first trajectory\n",
        "    q1, p1, q2, p2, t_eval = get_trajectory_furuta(device, init_method, num_trajectories, u_func, g_func, time_steps, y0, noise_std,\n",
        "                                                   Ts, C_q1, C_q2, g, Jr, Lr,\n",
        "                                                   Mp, Lp)  # u, G,\n",
        "    energy = []\n",
        "    derivatives = []\n",
        "    # # G = G.unsqueeze(dim=0)\n",
        "    if energ_deriv:\n",
        "        energy, derivatives = get_energy_furuta(\n",
        "            device, time_steps, Ts, u_func, g_func, q1, p1, q2, p2, C_q1, C_q2, g, Jr, Lr, Mp, Lp)\n",
        "    # print(q1.shape)\n",
        "    # if not len(q1.shape)==1:\n",
        "    #     # q1, p1, q2, p2, energy, derivatives = q1.permute(1,0), p1.permute(1,0), q2.permute(1,0), p2.permute(1,0), energy.permute(1,0), derivatives.permute(1,0,2)\n",
        "    #       energy, derivatives =  energy.permute(1,0), derivatives.permute(1,0,2)\n",
        "\n",
        "    # if num_trajectories == 1 :\n",
        "    #     # so that the vectors will have the correct dimensions if only 1\n",
        "    #     # trajectory is requested\n",
        "    #     # q1 = q1.unsqueeze(dim=0)\n",
        "    #     # p1 = p1.unsqueeze(dim=0)\n",
        "    #     # q2 = q2.unsqueeze(dim=0)\n",
        "    #     # p2 = p2.unsqueeze(dim=0)\n",
        "\n",
        "    #     if energ_deriv:\n",
        "    #       energy = energy.unsqueeze(dim=0)\n",
        "\n",
        "    return q1, p1, q2, p2, energy, derivatives, t_eval  # u, G,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCOtyABh-kAv"
      },
      "source": [
        "## dataset & dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "id": "lYmILMMLAQfD"
      },
      "outputs": [],
      "source": [
        "class TrajectoryDataset_furuta(Dataset):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self, q1, p1, q2, p2, t_eval,  # energy=torch.tensor(False),\n",
        "                 derivatives, coord_type='hamiltonian'):  # u, G,\n",
        "        self.t_eval = t_eval\n",
        "        self.coord_type = coord_type\n",
        "        self.q1 = q1  # [num_trajectories, time_steps]\n",
        "        self.p1 = p1  # [num_trajectories, time_steps]\n",
        "        self.q2 = q2  # [num_trajectories, time_steps]\n",
        "        self.p2 = p2  # [num_trajectories, time_steps]\n",
        "        # self.u = u # [num_trajectories, time_steps]\n",
        "        # self.G = G # [num_trajectories, time_steps, (g1,g2,g3,g4)]\n",
        "        if len(derivatives.shape) == 3:\n",
        "            # [num_trajectories, time_steps, (dq1/dt,dp1/dt,dq2/dt,dp2/dt)]\n",
        "            self.dq1dt = derivatives[:, :, 0]\n",
        "            self.dq2dt = derivatives[:, :, 2]\n",
        "        else:\n",
        "            # [num_trajectories, time_steps, (dq1/dt,dp1/dt,dq2/dt,dp2/dt)]\n",
        "            self.dq1dt = derivatives[:, 0]\n",
        "            self.dq2dt = derivatives[:, 2]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.q1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if self.coord_type == 'hamiltonian':\n",
        "\n",
        "            q1 = self.q1[idx]\n",
        "            p1 = self.p1[idx]\n",
        "            q2 = self.q2[idx]\n",
        "            p2 = self.p2[idx]\n",
        "            # u = self.u[idx]\n",
        "            # G = self.G[idx]\n",
        "            x = torch.stack((q1, p1, q2, p2), dim=1)  # ,u\n",
        "            # x = torch.hstack((x,G))\n",
        "\n",
        "        if self.coord_type == 'newtonian':\n",
        "\n",
        "            q1 = self.q1[idx]\n",
        "            q2 = self.q2[idx]\n",
        "            dq1dt = self.dq1dt[idx]\n",
        "            dq2dt = self.dq2dt[idx]\n",
        "\n",
        "            x = torch.vstack((q1, dq1dt, q2, dq2dt))\n",
        "\n",
        "        t_eval = self.t_eval\n",
        "\n",
        "        return x, t_eval\n",
        "\n",
        "\n",
        "def data_loader_furuta(q1, p1, q2, p2, energy, derivatives, t_eval, batch_size,\n",
        "                       shuffle=True, proportion=0.5, coord_type='hamiltonian'):  # u, G,\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "    # split  into train and test\n",
        "    full_dataset = TrajectoryDataset_furuta(\n",
        "        q1, p1, q2, p2, t_eval, derivatives, coord_type=coord_type)  # u, G,\n",
        "    if proportion:\n",
        "\n",
        "        train_size = int(proportion * len(full_dataset))\n",
        "        test_size = len(full_dataset) - train_size\n",
        "\n",
        "        train_dataset, test_dataset = random_split(\n",
        "            full_dataset, [train_size, test_size])\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size,\n",
        "            shuffle\n",
        "        )\n",
        "    else:\n",
        "      # if proportion is set to None don't split the dataset\n",
        "        train_dataset = full_dataset\n",
        "        energy_train = energy\n",
        "        derivatives_train = derivatives\n",
        "        t_eval_train = t_eval\n",
        "        test_loader = None\n",
        "\n",
        "    # create the dataloader object from the custom dataset\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size,\n",
        "        shuffle\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp4nC5YW-r4x"
      },
      "source": [
        "## models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqdZxOkCEgPT"
      },
      "source": [
        "### base models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6esDXasrZIe"
      },
      "source": [
        "#### MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "id": "7JO7Pja0Egrj"
      },
      "outputs": [],
      "source": [
        "def choose_nonlinearity(name):\n",
        "    '''\n",
        "    From the SymODEN repository\n",
        "    returns an activation function that can be evaluated\n",
        "    '''\n",
        "    nl = None\n",
        "    if name == 'tanh':\n",
        "        nl = torch.tanh\n",
        "    elif name == 'x+sin(x)^2':\n",
        "        def nl(x): return x + torch.sin(x).pow(2)\n",
        "    else:\n",
        "        raise ValueError(\"nonlinearity not recognized\")\n",
        "    return nl\n",
        "\n",
        "\n",
        "class hidden_Layer(torch.nn.Module):\n",
        "    '''\n",
        "    Fully connected layer with activation function\n",
        "    '''\n",
        "\n",
        "    def __init__(self, hidden_dim, activation='tanh'):\n",
        "        super().__init__()\n",
        "        self.fc = torch.nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.activation = choose_nonlinearity(\n",
        "            activation)  # activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    '''\n",
        "    MLP with number of hidden layers as a parameter\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_dim=2, hidden_dim=90, nb_hidden_layers=4, output_dim=1, activation='x+sin(x)^2'):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
        "        self.hidden_layers = torch.nn.Sequential(\n",
        "            *(hidden_Layer(hidden_dim, activation)\n",
        "              for _ in range(nb_hidden_layers))\n",
        "        )  # trick from EE-559 to define hidden layers\n",
        "        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        self.activation = choose_nonlinearity(\n",
        "            activation)  # activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.activation(self.fc1(x))\n",
        "        h = self.hidden_layers(h)\n",
        "        return self.fc2(h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h9Hj0R4rZIf"
      },
      "source": [
        "#### ResNets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "id": "eM86drgerZIg"
      },
      "outputs": [],
      "source": [
        "class ResNet_config1(torch.nn.Module):\n",
        "    '''\n",
        "    Model compose of [ MLP - RESBLOCK1 - RESBLOCK2] used in the following way:\n",
        "    First we train the model with only the MLP, then we introduce RESBLOCK1 when we increase the horizon, \n",
        "    but initialise RESBLOCK1 with very small weights, \n",
        "    '''\n",
        "\n",
        "    def __init__(self, resblock_list, num_blocks=4, input_dim=4, hidden_dim=90, nb_hidden_layers=1, output_dim=1, activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2'):\n",
        "        super(ResNet_config1, self).__init__()\n",
        "\n",
        "        self.resblocks = [MLP(input_dim=output_dim, hidden_dim=hidden_dim, nb_hidden_layers=nb_hidden_layers,\n",
        "                              output_dim=output_dim, activation=activation_res) for _ in range(num_blocks)]\n",
        "\n",
        "        self.mlp = MLP(input_dim=input_dim, hidden_dim=hidden_dim, nb_hidden_layers=nb_hidden_layers,\n",
        "                       output_dim=output_dim, activation=activation_mlp)\n",
        "\n",
        "        self.resblock_list = resblock_list\n",
        "\n",
        "        self.make_params_small()  # make the resblock parameters small\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = self.mlp(x)\n",
        "\n",
        "        for i in self.resblock_list:\n",
        "            y = self.resblocks[i](y) + y\n",
        "\n",
        "        return y\n",
        "\n",
        "    def make_params_small(self):\n",
        "        with torch.no_grad():\n",
        "            for i in range(len(self.resblocks)):\n",
        "                for param in self.resblocks[i].parameters():\n",
        "                    param.copy_(param/1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {
        "id": "kKJPjw1lrZIi"
      },
      "outputs": [],
      "source": [
        "class ResNet_config2(torch.nn.Module):\n",
        "    '''\n",
        "    MLP with number of hidden layers as a parameter\n",
        "    '''\n",
        "\n",
        "    def __init__(self, resblock_list, num_blocks=4, input_dim=4, hidden_dim=25, nb_hidden_layers=2, output_dim=1, activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2'):\n",
        "        super(ResNet_config2, self).__init__()\n",
        "\n",
        "        self.resblocks = [MLP(input_dim=input_dim, hidden_dim=hidden_dim, nb_hidden_layers=nb_hidden_layers,\n",
        "                              output_dim=input_dim, activation=activation_res) for _ in range(num_blocks)]\n",
        "\n",
        "        self.mlp = MLP(input_dim=input_dim, hidden_dim=hidden_dim, nb_hidden_layers=nb_hidden_layers,\n",
        "                       output_dim=output_dim, activation=activation_mlp)\n",
        "\n",
        "        self.alpha = torch.tensor([1])\n",
        "\n",
        "        self.resblock_list = resblock_list\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "\n",
        "        for i in self.resblock_list:\n",
        "            y = self.resblocks[i](y)*self.alpha + y\n",
        "\n",
        "        y = self.mlp(y)\n",
        "        return y\n",
        "\n",
        "    def init_new_resblocks_two(self, i, j):\n",
        "        # i and j are the new resblocks to be initialised\n",
        "        # in our simple case we introduce reblocks 1 and 2 between resblocks 0 and 3\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for param1, param2, param3, param4 in zip(self.resblocks[i-1].parameters(), self.resblocks[i].parameters(), self.resblocks[j].parameters(), self.resblocks[j+1].parameters()):\n",
        "\n",
        "                param2.copy_((param1 + param2)/2)\n",
        "                param3.copy_((param3 + param4)/2)\n",
        "\n",
        "    def init_new_resblocks(self, i, j, k):\n",
        "        # i is the new resblocks to be initialised\n",
        "        # in our simple case we introduce reblocks 1 and 2 between resblocks 0 and 3\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for param1, param2, param3 in zip(self.resblocks[i].parameters(), self.resblocks[j].parameters(), self.resblocks[k].parameters()):\n",
        "                param2.copy_((param1 + param3)/2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "P1WASDsPxR0s"
      },
      "outputs": [],
      "source": [
        "class ResNet_config3(torch.nn.Module):\n",
        "    '''\n",
        "    Model compose of [RESBLOCK1 - RESBLOCK2 - MLP] used in the following way:\n",
        "    First we train the model with only the MLP, then we introduce RESBLOCK1 when we increase the horizon, \n",
        "    but initialise RESBLOCK2 with very small weights, \n",
        "    '''\n",
        "\n",
        "    def __init__(self, resblock_list, num_blocks=4, input_dim=4, hidden_dim=90, nb_hidden_layers=1, output_dim=1, activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2'):\n",
        "        super(ResNet_config3, self).__init__()\n",
        "\n",
        "        self.resblocks = [MLP(input_dim=input_dim, hidden_dim=hidden_dim, nb_hidden_layers=nb_hidden_layers,\n",
        "                              output_dim=input_dim, activation=activation_res) for _ in range(num_blocks)]\n",
        "\n",
        "        self.mlp = MLP(input_dim=input_dim, hidden_dim=hidden_dim, nb_hidden_layers=nb_hidden_layers,\n",
        "                       output_dim=output_dim, activation=activation_mlp)\n",
        "\n",
        "        self.resblock_list = resblock_list\n",
        "        self.make_params_small()  # make the resblock parameters small\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = x\n",
        "\n",
        "        for i in self.resblock_list:\n",
        "            y = self.resblocks[i](y) + y\n",
        "        y = self.mlp(y)\n",
        "        return y\n",
        "\n",
        "    def make_params_small(self):\n",
        "        with torch.no_grad():\n",
        "            for i in range(len(self.resblocks)):\n",
        "                for param in self.resblocks[i].parameters():\n",
        "                    param.copy_(param/1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi6LkasyEW9Z"
      },
      "source": [
        "### simple_HNN : simple mlp / Unconstrained HNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "id": "b7aGsR_REW4Z"
      },
      "outputs": [],
      "source": [
        "class U_HNN(torch.nn.Module):\n",
        "    '''\n",
        "    Modified version of the original SymODEN_R module from symoden repository\n",
        "    Similar to unconstrained ODE HNN from the report\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_dim, H_net=None, device=None):\n",
        "        super(U_HNN, self).__init__()\n",
        "        self.H_net = H_net\n",
        "\n",
        "        self.device = device\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        # add learnable dissipation coefficients\n",
        "        # torch.nn.Parameter(torch.randn(1)+1) # torch.nn.Parameter(torch.tensor([0.5]))\n",
        "        self.C1_dissip = torch.nn.Parameter(torch.tensor([0.02]).sqrt())\n",
        "        self.C1_dissip.requires_grad = True\n",
        "        # torch.nn.Parameter(torch.randn(1)+1) # torch.nn.Parameter(torch.tensor([0.5]))\n",
        "        self.C2_dissip = torch.nn.Parameter(torch.tensor([0.02]).sqrt())\n",
        "        self.C2_dissip.requires_grad = True\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        with torch.enable_grad():\n",
        "            q_p = x\n",
        "\n",
        "            # q1,p1,q2,p2 = torch.chunk(x,4,dim=-1)\n",
        "\n",
        "            q_p.requires_grad_(True)\n",
        "\n",
        "            H = self.H_net(q_p)\n",
        "\n",
        "            # .sum() to sum up the hamiltonian funcs of a batch\n",
        "            dH = torch.autograd.grad(H.sum(), q_p, create_graph=True)\n",
        "\n",
        "            dH = dH[0]\n",
        "\n",
        "            dHdq1, dHdp1, dHdq2, dHdp2 = torch.chunk(dH, 4, dim=-1)\n",
        "\n",
        "            dq1dt = dHdp1\n",
        "            dp1dt = -dHdq1 - self.C1_dissip.pow(2)*dHdp1\n",
        "            dq2dt = dHdp2\n",
        "            dp2dt = -dHdq2 - self.C2_dissip.pow(2)*dHdp2\n",
        "\n",
        "            # symplectic gradient\n",
        "            S_h = torch.cat((dq1dt, dp1dt, dq2dt, dp2dt),\n",
        "                            dim=-1)\n",
        "\n",
        "            return S_h\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj6TCrYnEWyg"
      },
      "source": [
        "### latent_HNN : autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {
        "id": "jz4e79BdEWtZ"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(torch.nn.Module):\n",
        "    '''\n",
        "    '''\n",
        "\n",
        "    def __init__(self, nb_hidden_layers=1,  hidden_dim=64, activation='tanh', config='latent'):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "        if self.config == 'latent':\n",
        "            enc_in_dim = 4\n",
        "            enc_out_dim = 2\n",
        "            dec_in_dim = 4\n",
        "            dec_out_dim = 4\n",
        "\n",
        "        elif self.config == 'encoded':\n",
        "            enc_in_dim = 4\n",
        "            enc_out_dim = 4\n",
        "            dec_in_dim = 4\n",
        "            dec_out_dim = 4\n",
        "\n",
        "        self.encoder = MLP(input_dim=enc_in_dim, hidden_dim=hidden_dim,\n",
        "                           nb_hidden_layers=nb_hidden_layers, output_dim=enc_out_dim, activation=activation)\n",
        "\n",
        "        self.decoder = MLP(input_dim=dec_in_dim, hidden_dim=hidden_dim,\n",
        "                           nb_hidden_layers=nb_hidden_layers, output_dim=dec_out_dim, activation=activation)\n",
        "\n",
        "    def forward(self, x):  # x is (q, q_dot)\n",
        "\n",
        "        if self.config == 'latent':\n",
        "            q1, p1, q2, p2 = torch.split(x, 1, dim=-1)\n",
        "\n",
        "            p_hat = self.encoder(x)  # coordinates in the latent space\n",
        "\n",
        "            # input known q and encoded z into decoder\n",
        "            z = torch.stack((q1[:, :, 0], p_hat[:, :, 0],\n",
        "                            q2[:, :, 0], p_hat[:, :, 1]), dim=2)\n",
        "\n",
        "            # coordinates back in the original space but using the decoder\n",
        "            x_hat = self.decoder(z)\n",
        "\n",
        "            # x_hat = torch.stack((q1[:,:,0],q_dot_hat[:,:,0],q2[:,:,0],q_dot_hat[:,:,1]),dim=2)\n",
        "\n",
        "            # x_hat = torch.stack((q1[:,:,0],q_dot_hat[:,:,0],q2[:,:,0],q_dot_hat[:,:,1]),dim=2)\n",
        "        if self.config == 'encoded':\n",
        "            z = self.encoder(x)\n",
        "            x_hat = self.decoder(z)\n",
        "\n",
        "        return z, x_hat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmrjnJ5xEWbh"
      },
      "source": [
        "### input_HNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 455,
      "metadata": {
        "id": "wR1UsX-_EWEm"
      },
      "outputs": [],
      "source": [
        "class Nes_HDNN(torch.nn.Module):\n",
        "    '''\n",
        "    Modified version of the original SymODEN_R module from symoden repository\n",
        "    Similar to unconstrained ODE HNN from the report\n",
        "    '''\n",
        "\n",
        "    def __init__(self, u_func=None, G_net=None, H_net=None, device=None, dissip=False):\n",
        "        super(Nes_HDNN, self).__init__()\n",
        "        self.H_net = H_net\n",
        "        self.G_net = G_net\n",
        "        self.u_func = u_func\n",
        "        self.device = device\n",
        "        self.dissip = dissip\n",
        "        # add learnable dissipation coefficients 0.000009, 0.00004\n",
        "        # torch.nn.Parameter(torch.randn(1)+1) # torch.nn.Parameter(torch.tensor([0.5]))\n",
        "        self.C1_dissip = torch.nn.Parameter(torch.tensor([0.000009]).sqrt())\n",
        "        self.C1_dissip.requires_grad = True\n",
        "        # torch.nn.Parameter(torch.randn(1)+1) # torch.nn.Parameter(torch.tensor([0.5]))\n",
        "        self.C2_dissip = torch.nn.Parameter(torch.tensor([0.00004]).sqrt())\n",
        "        self.C2_dissip.requires_grad = True\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        with torch.enable_grad():\n",
        "            q_p = x[:, :4]\n",
        "\n",
        "            # q1, p1, q2, p2 = torch.chunk(x,4,dim=-1)\n",
        "\n",
        "            q_p.requires_grad_(True)\n",
        "\n",
        "            H = self.H_net(q_p)\n",
        "\n",
        "            # .sum() to sum up the hamiltonian funcs of a batch\n",
        "            dH = torch.autograd.grad(H.sum(), q_p, create_graph=True)\n",
        "\n",
        "            dHdq1, dHdp1, dHdq2, dHdp2 = torch.chunk(dH[0], 4, dim=-1)\n",
        "\n",
        "            # if self.G_net:\n",
        "            G = self.G_net.forward(q_p)\n",
        "            # print(G.device)\n",
        "            # else:\n",
        "            #     G = x[:,5:]\n",
        "            # if self.u_func:\n",
        "            u = self.u_func.forward(t)\n",
        "            # print(u.device)\n",
        "            # else:\n",
        "            #     u = x[:,4]\n",
        "            # print('q_p',q_p.shape)\n",
        "            # print('G',G.shape)\n",
        "            # print('u',u.shape, u)\n",
        "            # print('dHdq1',dHdq1.shape)\n",
        "\n",
        "            dq1dt = dHdp1\n",
        "            dq2dt = dHdp2\n",
        "            if self.dissip:\n",
        "\n",
        "                dp1dt = -dHdq1 + (G[:, 1]*u).unsqueeze(dim=1) - self.C1_dissip.pow(2)*dHdp1\n",
        "                dp2dt = -dHdq2 + (G[:, 3]*u).unsqueeze(dim=1) - self.C2_dissip.pow(2)*dHdp2\n",
        "            else:\n",
        "                dp1dt = -dHdq1 + (G[:, 1]*u).unsqueeze(dim=1)\n",
        "                dp2dt = -dHdq2 + (G[:, 3]*u).unsqueeze(dim=1)\n",
        "            # symplectic gradient\n",
        "            # zeros = torch.zeros_like(dq1dt)\n",
        "            # , zeros, zeros, zeros, zeros, zeros\n",
        "            S_h = torch.cat((dq1dt, dp1dt, dq2dt, dp2dt), dim=-1)\n",
        "            return S_h\n",
        "\n",
        "    def freeze_G_net(self, freeze=True):\n",
        "        \"\"\"\n",
        "        Only freez the G_net parameters\n",
        "        Inputs\n",
        "            freeze(bool) : True = freeze the parameters; False = don't\n",
        "\n",
        "        outputs:\n",
        "            None\n",
        "\n",
        "        \"\"\"\n",
        "        for param in self.G_net.parameters():\n",
        "            param.requires_grad = (not freeze)\n",
        "\n",
        "    def freeze_H_net(self, freeze=True):\n",
        "        \"\"\"\n",
        "        Only freez the H_net parameters\n",
        "        Inputs\n",
        "            freeze(bool) : True = freeze the parameters; False = don't\n",
        "\n",
        "        outputs:\n",
        "            None\n",
        "        \"\"\"\n",
        "        for param in self.H_net.parameters():\n",
        "            param.requires_grad = (not freeze)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xLuM9kz-yLr"
      },
      "source": [
        "## plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUHxkWU5E6lm"
      },
      "source": [
        "### for data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "M-T8gGtbE6S8"
      },
      "outputs": [],
      "source": [
        "def plot_traj_furuta(t_eval, q1, p1, q2, p2, energy=torch.tensor(False),\n",
        "                     title='Trajectory of the generalized coordinates', coord_type='hamiltonian'):\n",
        "    '''\n",
        "    This function plots the generalised variables q1, p1, q2, p2, and the energy \n",
        "    at the time t_eval at which they were evaluated\n",
        "    Inputs:\n",
        "      t_eval (tensor) : vector containing evaluation times of the generalized coordinates\n",
        "      q1 (tensor) : generalized position q1\n",
        "      p1 (tensor) : generalized momentum p1\n",
        "      q2 (tensor) : generalized position q1\n",
        "      p2 (tensor) : generalized momentum p2\n",
        "      energy (tensor) : energy evaluated at the provided coordinates, if\n",
        "          not provided, it will not appear in the plot (default = torch.tensor(False))\n",
        "    Outputs:\n",
        "      None\n",
        "    '''\n",
        "    # TODO : make this work for two columns\n",
        "    if torch.any(energy):\n",
        "\n",
        "        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(\n",
        "            15, 4), constrained_layout=True, sharex=True)  # , sharey=True)\n",
        "        ax5.plot(t_eval, energy, label='energy')\n",
        "\n",
        "        # ax1.legend()\n",
        "        ax5.set_title('Energy', fontsize=10)\n",
        "        ax5.set_xlabel('time (s)')\n",
        "        ax5.set_ylabel('E')\n",
        "        ax5.set_ylim((0, torch.max(energy)*1.1))\n",
        "    else:\n",
        "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(12, 4),\n",
        "                                                 constrained_layout=True, sharex=True)  # , sharey=True)\n",
        "\n",
        "    ax1.plot(t_eval, q1, label='q1')\n",
        "    ax2.plot(t_eval, p1, label='p1')\n",
        "    ax3.plot(t_eval, q2, label='q2')\n",
        "    ax4.plot(t_eval, p2, label='p2')\n",
        "\n",
        "    # ax1.legend()\n",
        "    ax1.set_title('generalized position (q1)', fontsize=10)\n",
        "    ax1.set_xlabel('time[s]')\n",
        "    ax1.set_ylabel('q1[rad]')\n",
        "\n",
        "    # ax2.legend()\n",
        "    ax2.set_title('generalized momentum (p1)', fontsize=10)\n",
        "    ax2.set_xlabel('time [s]')\n",
        "    ax2.set_ylabel('p1')\n",
        "\n",
        "    ax3.set_title('generalized position (q2)', fontsize=10)\n",
        "    ax3.set_xlabel('time [s]')\n",
        "    ax3.set_ylabel('q2[rad]')\n",
        "\n",
        "    ax4.set_title('generalized momentum (p2)', fontsize=10)\n",
        "    ax4.set_xlabel('time [s]')\n",
        "    ax4.set_ylabel('p2')\n",
        "\n",
        "    if coord_type == 'newtonian':\n",
        "        ax2.set_title(r'$\\dot{q1}[rad/s]$', fontsize=10)\n",
        "        ax2.set_ylabel(r'$\\dot{q1}[rad/s]$')\n",
        "        ax4.set_title(r'$\\dot{q2}[rad/s]$', fontsize=10)\n",
        "        ax4.set_ylabel(r'$\\dot{q2}[rad/s]$')\n",
        "\n",
        "    fig.suptitle(title, fontsize=12)\n",
        "    plt.show()\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "fuNOJwpN0eaA"
      },
      "outputs": [],
      "source": [
        "def plot_traj_furuta_withinput(t_eval, q1, p1, q2, p2, energy=None, input=None,\n",
        "                               title='Trajectory of the generalized coordinates', coord_type='hamiltonian'):\n",
        "    '''\n",
        "    This function plots the generalised variables q1, p1, q2, p2, and the energy \n",
        "    at the time t_eval at which they were evaluated\n",
        "    Inputs:\n",
        "      t_eval (tensor) : vector containing evaluation times of the generalized coordinates\n",
        "      q1 (tensor) : generalized position q1\n",
        "      p1 (tensor) : generalized momentum p1\n",
        "      q2 (tensor) : generalized position q1\n",
        "      p2 (tensor) : generalized momentum p2\n",
        "      energy (tensor) : energy evaluated at the provided coordinates, if\n",
        "          not provided, it will not appear in the plot (default = torch.tensor(False))\n",
        "    Outputs:\n",
        "      None\n",
        "    '''\n",
        "    # TODO : make this work for two columns\n",
        "\n",
        "    fig, ax = plt.subplots(2, 3, figsize=(\n",
        "        15, 4), constrained_layout=True, sharex=True)  # , sharey=True)\n",
        "    if energy is not None:\n",
        "        ax[1, 2].plot(t_eval, energy, label='energy')\n",
        "        ax[1, 2].set_title('Energy', fontsize=10)\n",
        "        ax[1, 2].set_xlabel('time (s)')\n",
        "        ax[1, 2].set_ylabel('E')\n",
        "        ax[1, 2].set_ylim((0, torch.max(energy)*1.1))\n",
        "    else:\n",
        "        ax[1, 2].set_axis_off()\n",
        "\n",
        "    ax[0, 2].plot(t_eval, input)\n",
        "    ax[0, 2].set_title('Input', fontsize=10)\n",
        "    ax[0, 2].set_xlabel('time (s)')\n",
        "    ax[0, 2].set_ylabel('U')\n",
        "\n",
        "    ax[0, 0].plot(t_eval, q1, label='q1')\n",
        "    ax[0, 0].set_title('generalized position (q1)', fontsize=10)\n",
        "    ax[0, 0].set_xlabel('time[s]')\n",
        "    ax[0, 0].set_ylabel('q1[rad]')\n",
        "\n",
        "    ax[1, 0].plot(t_eval, p1, label='p1')\n",
        "    ax[1, 0].set_title('generalized momentum (p1)', fontsize=10)\n",
        "    ax[1, 0].set_xlabel('time [s]')\n",
        "    ax[1, 0].set_ylabel('p1')\n",
        "\n",
        "    ax[0, 1].plot(t_eval, q2, label='q2')\n",
        "    ax[0, 1].set_title('generalized position (q2)', fontsize=10)\n",
        "    ax[0, 1].set_xlabel('time [s]')\n",
        "    ax[0, 1].set_ylabel('q2[rad]')\n",
        "\n",
        "    ax[1, 1].plot(t_eval, p2, label='p2')\n",
        "    ax[1, 1].set_title('generalized momentum (p2)', fontsize=10)\n",
        "    ax[1, 1].set_xlabel('time [s]')\n",
        "    ax[1, 1].set_ylabel('p2')\n",
        "\n",
        "    if coord_type == 'newtonian':\n",
        "        ax[1, 0].set_title(r'$\\dot{q1}[rad/s]$', fontsize=10)\n",
        "        ax[1, 0].set_ylabel(r'$\\dot{q1}[rad/s]$')\n",
        "        ax[1, 1].set_title(r'$\\dot{q2}[rad/s]$', fontsize=10)\n",
        "        ax[1, 1].set_ylabel(r'$\\dot{q2}[rad/s]$')\n",
        "\n",
        "    fig.suptitle(title, fontsize=12)\n",
        "    plt.show()\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZhWzhFnE9cq"
      },
      "source": [
        "### for results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "id": "ptWmRSZYFMJ4"
      },
      "outputs": [],
      "source": [
        "def plot_furuta_hat_nom(device, model, u_func, g_func, utype, gtype, data_loader_t, n, t_max, C_q1, C_q2, g, Jr, Lr, Mp, Lp,\n",
        "                        t_plot=None, show_pred=True, only_pred=False, H_or_Input='input',\n",
        "                        title='Trajectory of the generalized coordinates'  # , coord_type='hamiltonian'\n",
        "                        , file_path=None):\n",
        "    '''\n",
        "    Description:\n",
        "      This function plots the generalised variables q p, the energy at the time\n",
        "      t_eval at which they were evaluated \n",
        "    Inputs: \n",
        "      t_eval () \n",
        "      q () \n",
        "      p () \n",
        "    Outputs: \n",
        "      None \n",
        "    '''\n",
        "\n",
        "    x_nom, t_eval = next(iter(data_loader_t))\n",
        "\n",
        "    t_eval = t_eval[0, :]  # otherwise it is by batch\n",
        "    time_steps = len(t_eval)\n",
        "\n",
        "    if t_plot:\n",
        "        time_steps = t_plot\n",
        "        t_eval = t_eval[:t_plot]\n",
        "    else:\n",
        "        t_plot = time_steps\n",
        "\n",
        "    Ts = t_eval[0]\n",
        "    print('Ts', Ts)\n",
        "    # predicted trajectory\n",
        "    x_hat = odeint(model, x_nom[:, 0, :], t_eval, method='rk4').detach()\n",
        "    x_hat = x_hat.detach()\n",
        "\n",
        "    # to do: make this concise with torch split or chunck\n",
        "    q1_hat = x_hat[:, n, 0].unsqueeze(dim=0)\n",
        "    p1_hat = x_hat[:, n, 1].unsqueeze(dim=0)\n",
        "    q2_hat = x_hat[:, n, 2].unsqueeze(dim=0)\n",
        "    p2_hat = x_hat[:, n, 3].unsqueeze(dim=0)\n",
        "\n",
        "    E_hat, _ = get_energy_furuta(device, time_steps, Ts, u_func, g_func, q1_hat /\n",
        "                                 w_rescale[0], p1_hat/w_rescale[1], q2_hat/w_rescale[2], p2_hat/w_rescale[3], C_q1, C_q2, g, Jr, Lr, Mp, Lp)\n",
        "    H_hat = furuta_H(q1_hat/w_rescale[0], p1_hat/w_rescale[1],\n",
        "                     q2_hat/w_rescale[2], p2_hat/w_rescale[3], g, Jr, Lr, Mp, Lp)\n",
        "\n",
        "    # H_hat = model.H_net(x_hat[:,0,:]).detach().squeeze()\n",
        "    E_hat = E_hat.detach().cpu().squeeze()\n",
        "    H_hat = H_hat.detach().cpu().squeeze()\n",
        "\n",
        "    # nominal trajectory\n",
        "    q1_hat, p1_hat, q2_hat, p2_hat = q1_hat.squeeze(\n",
        "    ), p1_hat.squeeze(), q2_hat.squeeze(), p2_hat.squeeze()\n",
        "    x_nom = x_nom.detach()\n",
        "\n",
        "    q1_nom = x_nom[n, :t_plot, 0].unsqueeze(dim=0)\n",
        "    p1_nom = x_nom[n, :t_plot, 1].unsqueeze(dim=0)\n",
        "    q2_nom = x_nom[n, :t_plot, 2].unsqueeze(dim=0)\n",
        "    p2_nom = x_nom[n, :t_plot, 3].unsqueeze(dim=0)\n",
        "    print('plot_furuta_hat_nom', 'q1_nom', q1_nom.shape)\n",
        "    E_nom, _ = get_energy_furuta(device, time_steps, Ts, u_func, g_func, q1_nom /\n",
        "                                 w_rescale[0], p1_nom/w_rescale[1], q2_nom/w_rescale[2], p2_nom/w_rescale[3], C_q1, C_q2, g, Jr, Lr, Mp, Lp, time_=t_eval)\n",
        "    H_nom = furuta_H(q1_nom/w_rescale[0], p1_nom/w_rescale[1],\n",
        "                     q2_nom/w_rescale[2], p2_nom/w_rescale[3], g, Jr, Lr, Mp, Lp)\n",
        "\n",
        "    E_nom = E_nom.detach().cpu().squeeze()\n",
        "    H_nom = H_nom.detach().cpu().squeeze()\n",
        "    q1_nom, p1_nom, q2_nom, p2_nom = q1_nom.squeeze().cpu(), p1_nom.squeeze(\n",
        "    ).cpu(), q2_nom.squeeze().cpu(), p2_nom.squeeze().cpu()\n",
        "    t_eval = t_eval.detach().cpu()\n",
        "    fig, ax = plt.subplots(2, 3, figsize=(\n",
        "        15, 4), constrained_layout=True, sharex=True)  # , sharey=True)\n",
        "\n",
        "    # to do : make a for loop to add multiple plots\n",
        "    # predicted\n",
        "    # plot nominal and predicted trajectory on same plot\n",
        "\n",
        "    # for x in [t_eval, q1_hat, p1_hat, q2_hat, p2_hat, E_hat, H_hat, q1_nom, p1_nom, q2_nom, p2_nom, E_nom, H_nom]:\n",
        "    #     x = x.detach().cpu() # transfering everything to cpu memory\n",
        "    #     print(x.device)\n",
        "    # t_eval = t_eval\n",
        "\n",
        "    if H_or_Input == 'input':\n",
        "        H_nom = u_func.forward(t_eval.to(device))\n",
        "        ax[1, 2].set_title('Input', fontsize=10)\n",
        "        ax[1, 2].set_xlabel('time (s)')\n",
        "        ax[1, 2].set_ylabel('u')\n",
        "        t_eval = t_eval = t_eval.detach().cpu()\n",
        "    else:\n",
        "        ax[1, 2].set_title('Hamiltonian', fontsize=10)\n",
        "        ax[1, 2].set_xlabel('time (s)')\n",
        "        ax[1, 2].set_ylabel('H')\n",
        "    for q1, p1, q2, p2, E, H, label in [[q1_nom, p1_nom, q2_nom, p2_nom, E_nom, H_nom, 'nominal']]:\n",
        "        # q1 = q1.cpu()\n",
        "        # p1 = p1.cpu()\n",
        "        # q2 = q2.cpu()\n",
        "        # p2 = p2.cpu()\n",
        "        # E = E.cpu()\n",
        "        # H = H.cpu()\n",
        "\n",
        "        ax[0, 0].plot(t_eval, q1, label=label)\n",
        "        ax[1, 0].plot(t_eval, p1, label=label)\n",
        "        ax[0, 1].plot(t_eval, q2, label=label)\n",
        "        ax[1, 1].plot(t_eval, p2, label=label)\n",
        "        ax[0, 2].plot(t_eval, E, label=label)\n",
        "        ax[1, 2].plot(t_eval, H, label=label)\n",
        "\n",
        "    for q1, p1, q2, p2, E, H, label in [[q1_hat, p1_hat, q2_hat, p2_hat, E_hat, H_hat, 'prediction']]:\n",
        "\n",
        "        q1 = q1.cpu()\n",
        "        p1 = p1.cpu()\n",
        "        q2 = q2.cpu()\n",
        "        p2 = p2.cpu()\n",
        "        E = E.cpu()\n",
        "        H = H.cpu()\n",
        "        label_train = 'train'\n",
        "        color = 'g'\n",
        "        if only_pred:\n",
        "            t_max = time_steps\n",
        "            color = 'r'\n",
        "            label_train = 'prediction'\n",
        "            show_pred = False\n",
        "\n",
        "        ax[0, 0].plot(t_eval[:t_max], q1[:t_max], label=label_train, c=color)\n",
        "        if show_pred:\n",
        "            ax[0, 0].plot(t_eval[t_max-1:], q1[t_max-1:], label=label, c='r')\n",
        "\n",
        "        ax[1, 0].plot(t_eval[:t_max], p1[:t_max], label=label_train, c=color)\n",
        "        if show_pred:\n",
        "            ax[1, 0].plot(t_eval[t_max-1:], p1[t_max-1:], label=label, c='r')\n",
        "\n",
        "        ax[0, 1].plot(t_eval[:t_max], q2[:t_max], label=label_train, c=color)\n",
        "        if show_pred:\n",
        "            ax[0, 1].plot(t_eval[t_max-1:], q2[t_max-1:], label=label, c='r')\n",
        "\n",
        "        ax[1, 1].plot(t_eval[:t_max], p2[:t_max], label=label_train, c=color)\n",
        "        if show_pred:\n",
        "            ax[1, 1].plot(t_eval[t_max-1:], p2[t_max-1:], label=label, c='r')\n",
        "\n",
        "        ax[0, 2].plot(t_eval[:t_max], E[:t_max], label=label_train, c=color)\n",
        "        if show_pred:\n",
        "            ax[0, 2].plot(t_eval[t_max-1:], E[t_max-1:], label=label, c='r')\n",
        "\n",
        "        if H_or_Input == 'H':\n",
        "            ax[1, 2].plot(t_eval[:t_max], H[:t_max],\n",
        "                          label=label_train, c=color)\n",
        "            if show_pred:\n",
        "                ax[1, 2].plot(t_eval[t_max-1:], H[t_max-1:],\n",
        "                              label=label, c='r')\n",
        "\n",
        "    # for j in range(3): # show all of the legends\n",
        "    #   for i in range(2):\n",
        "\n",
        "    ax[0, 0].legend()\n",
        "\n",
        "    # add labels and titles on every plot\n",
        "    ax[0, 0].set_title('generalized position (q1)', fontsize=10)\n",
        "    ax[0, 0].set_xlabel('time[s]')\n",
        "    ax[0, 0].set_ylabel('q1[rad]')\n",
        "\n",
        "    ax[1, 0].set_title('generalized momentum (p1)', fontsize=10)\n",
        "    ax[1, 0].set_xlabel('time [s]')\n",
        "    ax[1, 0].set_ylabel('p1')\n",
        "\n",
        "    ax[0, 1].set_title('generalized position (q2)', fontsize=10)\n",
        "    ax[0, 1].set_xlabel('time [s]')\n",
        "    ax[0, 1].set_ylabel('q2[rad]')\n",
        "\n",
        "    ax[1, 1].set_title('generalized momentum (p2)', fontsize=10)\n",
        "    ax[1, 1].set_xlabel('time [s]')\n",
        "    ax[1, 1].set_ylabel('p2')\n",
        "\n",
        "    ax[0, 2].set_title('Energy', fontsize=10)\n",
        "    ax[0, 2].set_xlabel('time (s)')\n",
        "    ax[0, 2].set_ylabel('E')\n",
        "    # ax[0,2].set_ylim(bottom=0)\n",
        "    # ax[0,2].set_ylim(0,torch.max(torch.cat((E_hat.cpu() ,E_nom.cpu())))*1.1) # because sometimes it won't appear on the plot\n",
        "\n",
        "    # add larger title on top\n",
        "    fig.suptitle(title, fontsize=12)\n",
        "\n",
        "    if file_path is not None:\n",
        "        # ,bbox_inches='tight') # dpi\n",
        "        plt.savefig(file_path, format=\"png\", dpi=400)\n",
        "        # plt.savefig(file_path, format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "id": "huq-qs2-Jybd"
      },
      "outputs": [],
      "source": [
        "def plot_longer_horizon_furuta(device, model, u_func, g_func, utype, gtype, test_loader, n, t1, t2, C_q1, C_q2, g, Jr, Lr, Mp, Lp, \n",
        "                               title = 'Trajectory after longer horizon', file_path=None,):\n",
        "    '''\n",
        "\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "      \n",
        "    '''\n",
        "    x_nom, t_eval = next(iter(test_loader))\n",
        "\n",
        "    t_eval = t_eval[0,:t2]\n",
        "\n",
        "    time_steps = len(t_eval)\n",
        "    Ts = t_eval[0]\n",
        "\n",
        "    # test trajectories\n",
        "    x_hat = odeint(model, x_nom[:, 0, :4], t_eval, method='rk4').detach()\n",
        "    \n",
        "\n",
        "    q1_hat = x_hat[:t2,n,0].unsqueeze(dim=0) # to do: make this concise with torch split or chunck\n",
        "    p1_hat = x_hat[:t2,n,1].unsqueeze(dim=0)\n",
        "    q2_hat = x_hat[:t2,n,2].unsqueeze(dim=0)\n",
        "    p2_hat = x_hat[:t2,n,3].unsqueeze(dim=0)\n",
        "\n",
        "    E_hat, _ = get_energy_furuta(device, time_steps, Ts, u_func, g_func, q1_hat, p1_hat, q2_hat, p2_hat, C_q1, C_q2, g, Jr, Lr, Mp, Lp) \n",
        "    H_hat = furuta_H(q1_hat, p1_hat, q2_hat, p2_hat, g, Jr, Lr, Mp, Lp)\n",
        "    # H_hat = model.H_net(x_hat[t1:t2,0,:]).detach().squeeze()\n",
        "    E_hat = E_hat[t1:t2].cpu().detach().squeeze()\n",
        "    H_hat = H_hat[t1:t2].cpu().detach().squeeze()\n",
        "\n",
        "    # nominal trajectories\n",
        "    q1_nom = x_nom[n,:t2,0].unsqueeze(dim=0)\n",
        "    p1_nom = x_nom[n,:t2,1].unsqueeze(dim=0)\n",
        "    q2_nom = x_nom[n,:t2,2].unsqueeze(dim=0)\n",
        "    p2_nom = x_nom[n,:t2,3].unsqueeze(dim=0)\n",
        "\n",
        "    E_nom, _ = get_energy_furuta(device, time_steps, Ts, u_func, g_func, q1_nom, p1_nom, q2_nom, p2_nom, C_q1, C_q2, g, Jr, Lr, Mp, Lp)\n",
        "    H_nom = furuta_H(q1_nom, p1_nom, q2_nom, p2_nom, g, Jr, Lr, Mp, Lp)\n",
        "    E_nom = E_nom[t1:t2].cpu().detach().squeeze()\n",
        "    H_nom = H_nom[t1:t2].cpu().detach().squeeze()\n",
        "    \n",
        "    x_hat = x_hat.cpu().detach()\n",
        "    x_nom = x_nom.cpu().detach()\n",
        "    \n",
        "    q1_hat = x_hat[t1:t2,n,0] # to do: make this concise with torch split or chunck\n",
        "    p1_hat = x_hat[t1:t2,n,1]\n",
        "    q2_hat = x_hat[t1:t2,n,2]\n",
        "    p2_hat = x_hat[t1:t2,n,3]\n",
        "    \n",
        "    q1_nom = x_nom[n,t1:t2,0]\n",
        "    p1_nom = x_nom[n,t1:t2,1]\n",
        "    q2_nom = x_nom[n,t1:t2,2]\n",
        "    p2_nom = x_nom[n,t1:t2,3]\n",
        "    t_eval = t_eval[t1:]\n",
        "    t_eval = t_eval.cpu().detach()\n",
        "    \n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(15, 6), constrained_layout=True, sharex=True)# , sharey=True)\n",
        "\n",
        "    # t_eval = t_eval.cpu()\n",
        "    for q1, p1, q2, p2, E, H, label in [[q1_nom, p1_nom, q2_nom, p2_nom, E_nom, H_nom,'nominal'],[q1_hat, p1_hat, q2_hat, p2_hat, E_hat, H_hat,'prediction']]:\n",
        "        \n",
        "        # q1 = q1.cpu() \n",
        "        # p1 = p1.cpu() \n",
        "        # q2 = q2.cpu() \n",
        "        # p2 = p2.cpu() \n",
        "        # E = E.cpu() \n",
        "        # H = H.cpu() \n",
        "        if label == 'prediction':\n",
        "            color = 'r'\n",
        "        elif label == 'nominal' : \n",
        "            color = 'C0'\n",
        "        ax[0,0].plot(t_eval, q1, label=label, color=color)\n",
        "        ax[0,1].plot(t_eval, q2, label=label, color=color)\n",
        "\n",
        "        ax[1,0].plot(t_eval, E, label=label, color=color) \n",
        "        ax[1,0].set_title('Energy', fontsize=10) \n",
        "        ax[1,0].set_xlabel('time (s)') \n",
        "        ax[1,0].set_ylabel('E') \n",
        "          \n",
        "        ax[1,1].plot(t_eval, H, label=label, color=color)\n",
        "        ax[1,1].set_title('Hamiltonian', fontsize=10)\n",
        "        ax[1,1].set_xlabel('time (s)')\n",
        "        ax[1,1].set_ylabel('H')\n",
        "\n",
        "    #ax[1,0].set_ylim(0,torch.max(torch.cat((E_hat.cpu() ,E_nom.cpu())))*1.1) # because sometimes it won't appear on the plot\n",
        "\n",
        "    # for j in range(2): # show all of the legends\n",
        "    #   for i in range(2):\n",
        "    #     ax[i,j].legend()\n",
        "    ax[0,1].legend()\n",
        "\n",
        "    # add labels and titles on every plot\n",
        "    ax[0,0].set_title('generalized position (q1)', fontsize=10)\n",
        "    ax[0,0].set_xlabel('time[s]')\n",
        "    ax[0,0].set_ylabel('q1[rad]')\n",
        "\n",
        "    ax[0,1].set_title('generalized position (q2)', fontsize=10)\n",
        "    ax[0,1].set_xlabel('time [s]')\n",
        "    ax[0,1].set_ylabel('q2[rad]')\n",
        "    fig.suptitle(title, fontsize=12)\n",
        "    if file_path is not None:\n",
        "        plt.savefig(file_path, format=\"png\",dpi=400)#,bbox_inches='tight') # dpi\n",
        "        # plt.savefig(file_path, format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    return \n",
        "\n",
        "def train_test_loss_plot(loss_train,loss_test, epochs, file_path=None,\n",
        "                            horizons = [100,150,200,250,300],\n",
        "                            switch_steps = [200,200,200,200,200],\n",
        "                            title='train and test loss per epoch' ):\n",
        "    ''' \n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "    # convert switch steps from : [200,200,200,200,200] to [200,400,600...]\n",
        "    horizon_steps = []\n",
        "    horizon_steps.append(0)\n",
        "    for i, number in enumerate(switch_steps) :\n",
        "        horizon_steps.append(horizon_steps[i] +number) \n",
        "    horizon_steps = horizon_steps[1:-1]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,4))\n",
        "    # ,constrained_layout=True)\n",
        "    # fig.tight_layout()\n",
        "\n",
        "    plt.plot(epochs, loss_train, label='train')\n",
        "\n",
        "    if not loss_test == []: # if loss_test exists\n",
        "        plt.plot(epochs[::10], loss_test, label='test')\n",
        "\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.yscale('log')\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "\n",
        "    if horizons:\n",
        "        for i, epoch_num in enumerate(horizon_steps[:-1]):\n",
        "            ax.annotate(\n",
        "            'horizon = %d'%horizons[i],\n",
        "            xy=(epochs[epoch_num], loss_train[epoch_num]), xycoords='data',\n",
        "            xytext=(-70, 100), textcoords='offset points',\n",
        "            arrowprops=dict(arrowstyle=\"->\",\n",
        "                            #connectionstyle=\"arc,angleA=0,armA=50,rad=10\"\n",
        "                            connectionstyle=\"angle,angleA=0,angleB=90,rad=10\"\n",
        "                            ))\n",
        "        ax.annotate(\n",
        "        'horizon = %d'%horizons[-1],\n",
        "        xy=(epochs[horizon_steps[-1]], loss_train[horizon_steps[-1]]), xycoords='data',\n",
        "        xytext=(+20, 100), textcoords='offset points',\n",
        "        arrowprops=dict(arrowstyle=\"->\",\n",
        "                        #connectionstyle=\"arc,angleA=0,armA=50,rad=10\"\n",
        "                        connectionstyle=\"angle,angleA=0,angleB=90,rad=10\"\n",
        "                        ))\n",
        "\n",
        "    if file_path is not None:\n",
        "        plt.savefig(file_path, format=\"png\",dpi=400)#,bbox_inches='tight') # dpi\n",
        "        # plt.savefig(file_path, format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "   \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTE_UuduFIlw"
      },
      "source": [
        "### for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "id": "DNn3OjHKFIXq"
      },
      "outputs": [],
      "source": [
        "def training_plot_old(t_eval, train_x, nominal_x):\n",
        "    # train_x is [batch_size,(q1,p1,q2,p1),time_steps]\n",
        "    # nominal_x is [time_steps, batch_size, (q1,p1,q2,p1)]\n",
        "\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(10, 5), constrained_layout=True, sharex=True)# , sharey=True)\n",
        "    t_eval_cpu = t_eval.detach().cpu() \n",
        "    ax[0,0].plot(t_eval_cpu, train_x[:,0,0].detach().cpu(), label='train', c='g')\n",
        "    ax[1,0].plot(t_eval_cpu, train_x[:,0,1].detach().cpu(), label='train', c='g')\n",
        "    ax[0,1].plot(t_eval_cpu, train_x[:,0,2].detach().cpu(), label='train', c='g')\n",
        "    ax[1,1].plot(t_eval_cpu, train_x[:,0,3].detach().cpu(), label='train', c='g')\n",
        "\n",
        "    ax[0,0].plot(t_eval_cpu, nominal_x[0,0,:].detach().cpu(), label='nominal')\n",
        "    ax[1,0].plot(t_eval_cpu, nominal_x[0,1,:].detach().cpu(), label='nominal')\n",
        "    ax[0,1].plot(t_eval_cpu, nominal_x[0,2,:].detach().cpu(), label='nominal')\n",
        "    ax[1,1].plot(t_eval_cpu, nominal_x[0,3,:].detach().cpu(), label='nominal')\n",
        "\n",
        "    ax[0,0].set_title('generalized position (q1)', fontsize=10)\n",
        "    ax[0,0].set_xlabel('time[s]')\n",
        "    ax[0,0].set_ylabel('q1[rad]')\n",
        "\n",
        "    ax[1,0].set_title('generalized momentum (p1)', fontsize=10)\n",
        "    ax[1,0].set_xlabel('time [s]')\n",
        "    ax[1,0].set_ylabel('p1')\n",
        "\n",
        "    ax[0,1].set_title('generalized position (q2)', fontsize=10)\n",
        "    ax[0,1].set_xlabel('time [s]')\n",
        "    ax[0,1].set_ylabel('q2[rad]')\n",
        "\n",
        "    ax[1,1].set_title('generalized momentum (p2)', fontsize=10)\n",
        "    ax[1,1].set_xlabel('time [s]')\n",
        "    ax[1,1].set_ylabel('p2')\n",
        "    ax[1,1].legend()\n",
        "    \n",
        "    # add larger title on top\n",
        "    fig.suptitle('intermediate plot of trajectories', fontsize=12)\n",
        "\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "DNlMB0vmrXkF"
      },
      "outputs": [],
      "source": [
        "def training_plot(t_eval, train_x, nominal_x):\n",
        "    # train_x is [batch_size,(q1,p1,q2,p1),time_steps]\n",
        "    # nominal_x is [time_steps, batch_size, (q1,p1,q2,p1)]\n",
        "\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(10, 5), constrained_layout=True, sharex=True)# , sharey=True)\n",
        "    t_eval_cpu = t_eval.detach().cpu()\n",
        "    # print('train_x',train_x.shape)#5 300 9\n",
        "    # print('t_eval_cpu',t_eval_cpu.shape)#5 300 9\n",
        "    # print('nominal_x',nominal_x.shape)#5 300 9\n",
        "\n",
        "    ax[0,0].plot(t_eval_cpu, train_x[:,0,0].detach().cpu(), label='train', c='g')\n",
        "    ax[1,0].plot(t_eval_cpu, train_x[:,0,1].detach().cpu(), label='train', c='g')\n",
        "    ax[0,1].plot(t_eval_cpu, train_x[:,0,2].detach().cpu(), label='train', c='g')\n",
        "    ax[1,1].plot(t_eval_cpu, train_x[:,0,3].detach().cpu(), label='train', c='g')\n",
        "    # print(nominal_x.shape)\n",
        "    ax[0,0].plot(t_eval_cpu, nominal_x[0,:,0].detach().cpu(), label='nominal')\n",
        "    ax[1,0].plot(t_eval_cpu, nominal_x[0,:,1].detach().cpu(), label='nominal')\n",
        "    ax[0,1].plot(t_eval_cpu, nominal_x[0,:,2].detach().cpu(), label='nominal')\n",
        "    ax[1,1].plot(t_eval_cpu, nominal_x[0,:,3].detach().cpu(), label='nominal')\n",
        "\n",
        "    ax[0,0].set_title('generalized position (q1)', fontsize=10)\n",
        "    ax[0,0].set_xlabel('time[s]')\n",
        "    ax[0,0].set_ylabel('q1[rad]')\n",
        "\n",
        "    ax[1,0].set_title('generalized momentum (p1)', fontsize=10)\n",
        "    ax[1,0].set_xlabel('time [s]')\n",
        "    ax[1,0].set_ylabel('p1')\n",
        "\n",
        "    ax[0,1].set_title('generalized position (q2)', fontsize=10)\n",
        "    ax[0,1].set_xlabel('time [s]')\n",
        "    ax[0,1].set_ylabel('q2[rad]')\n",
        "\n",
        "    ax[1,1].set_title('generalized momentum (p2)', fontsize=10)\n",
        "    ax[1,1].set_xlabel('time [s]')\n",
        "    ax[1,1].set_ylabel('p2')\n",
        "    ax[1,1].legend()\n",
        "    \n",
        "    # add larger title on top\n",
        "    fig.suptitle('intermediate plot of trajectories', fontsize=12)\n",
        "\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMpV0txb_WBQ"
      },
      "source": [
        "### gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "id": "yqp9ZkNu_WBR"
      },
      "outputs": [],
      "source": [
        "def plot_grads(stats):\n",
        "    '''\n",
        "    '''\n",
        "    grads_preclip_min = [ [] for _ in range(len(stats['layer_names'][0])) ]\n",
        "    grads_preclip_max = [ [] for _ in range(len(stats['layer_names'][0])) ]\n",
        "    grads_preclip_mean = [ [] for _ in range(len(stats['layer_names'][0])) ]\n",
        "    grads_postclip_min = [ [] for _ in range(len(stats['layer_names'][0])) ]\n",
        "    grads_postclip_max = [ [] for _ in range(len(stats['layer_names'][0])) ]\n",
        "    grads_postclip_mean = [ [] for _ in range(len(stats['layer_names'][0])) ]\n",
        "\n",
        "    for layer in range(len(stats['grads_preclip'][0])): \n",
        "        for iteration in range(len(stats['grads_preclip'])): \n",
        "            grads_preclip_min[layer].append(stats['grads_preclip'][iteration][layer].abs().min())\n",
        "            grads_preclip_max[layer].append(stats['grads_preclip'][iteration][layer].abs().max())\n",
        "            grads_preclip_mean[layer].append(stats['grads_preclip'][iteration][layer].abs().mean())\n",
        "            grads_postclip_min[layer].append(stats['grads_postclip'][iteration][layer].abs().min())\n",
        "            grads_postclip_max[layer].append(stats['grads_postclip'][iteration][layer].abs().max())\n",
        "            grads_postclip_mean[layer].append(stats['grads_postclip'][iteration][layer].abs().mean())\n",
        "    grads_preclip_min = torch.tensor(grads_preclip_min)\n",
        "    grads_preclip_max = torch.tensor(grads_preclip_max)\n",
        "    grads_preclip_mean = torch.tensor(grads_preclip_mean)\n",
        "    grads_postclip_min = torch.tensor(grads_postclip_min)\n",
        "    grads_postclip_max = torch.tensor(grads_postclip_max)\n",
        "    grads_postclip_mean = torch.tensor(grads_postclip_mean)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2,figsize=(10,4),sharex=True,sharey=True)\n",
        "    plt.yscale('log')\n",
        "    for i in range(2,grads_preclip_min.shape[0]):\n",
        "        ax[0].plot(grads_preclip_mean[i,:], label = stats['layer_names'][0][i])\n",
        "    for i in range(2,grads_preclip_min.shape[0]):\n",
        "        ax[1].plot(grads_postclip_mean[i,:])\n",
        "\n",
        "    # fig.subplots_adjust(right=0.6)\n",
        "    ax[0].set_title('before clipping')\n",
        "    ax[0].set_xlabel('iteration')\n",
        "    ax[0].set_ylabel('mean gradient value')\n",
        "    ax[0].set_yscale('log')\n",
        "\n",
        "    ax[1].set_title('after clipping')\n",
        "    ax[1].set_xlabel('iteration')\n",
        "    ax[1].set_yscale('log')\n",
        "\n",
        "    fig.suptitle('Mean gradient value in each layer') \n",
        "    fig.legend(loc=7)\n",
        "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    fig.subplots_adjust(right=0.70) \n",
        "    plt.show()             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO0OQeI7-bEs"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "id": "3ij33HcW-e5L"
      },
      "outputs": [],
      "source": [
        "def collect_gradients(named_parameters):\n",
        "    '''Plots the gradients flowing through different layers in the net during training.\n",
        "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "    \n",
        "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
        "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
        "\n",
        "    all_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            all_grads.append(p.grad.detach().clone())\n",
        "\n",
        "    return layers, all_grads\n",
        "\n",
        "\n",
        "def set_device():\n",
        "    # set device to GPU if available otherwise use CPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if device.type == 'cuda':\n",
        "        # if there is a GPU\n",
        "        print(f'Available device : {torch.cuda.get_device_name(0)}')\n",
        "    else:\n",
        "        print(device)\n",
        "    return device\n",
        "\n",
        "\n",
        "def set_furuta_params(which='fake'):\n",
        "\n",
        "    if which == 'fake':\n",
        "        # The \"fake\" set of furuta parameters to have similar magnitudes in q1 p1 q2 p2\n",
        "        Ts = 0.005\n",
        "        noise_std = 0.0\n",
        "        C_q1 = 0.0\n",
        "        C_q2 = 0.0\n",
        "        g = 9.81\n",
        "        Jr = 1*1e-5\n",
        "        Lr = 0.5\n",
        "        Mp = 5.0\n",
        "        Lp = 0.1\n",
        "\n",
        "    if which == 'real':\n",
        "        # The set of furuta parameters similar to the real furuta\n",
        "        Ts = 0.005\n",
        "        noise_std = 0.0\n",
        "        C_q1 = 0.0\n",
        "        C_q2 = 0.0\n",
        "        g = 9.81\n",
        "        Jr = 5.72*1e-5\n",
        "        Lr = 0.085\n",
        "        Mp = 0.024\n",
        "        Lp = 0.129\n",
        "\n",
        "    return Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    '''\n",
        "    from https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/9\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "\n",
        "    '''\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def load_model(device, hidden_dim=90, nb_hidden_layers=4):\n",
        "    H_net = MLP(input_dim=4, hidden_dim=hidden_dim,\n",
        "                nb_hidden_layers=nb_hidden_layers, output_dim=1, activation='x+sin(x)^2')\n",
        "    model = U_HNN(input_dim=4, H_net=H_net, device=None)\n",
        "    model.to(device)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_model_nes_hdnn(device, utype, u_func=None, hidden_dim=90, nb_hidden_layers=4):\n",
        "    G_net = MLP(input_dim=4, hidden_dim=64, nb_hidden_layers=1,\n",
        "                output_dim=2, activation='tanh')\n",
        "    H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4,\n",
        "                output_dim=1, activation='x+sin(x)^2')\n",
        "    model = Nes_HDNN(utype=utype, u_func=u_func,\n",
        "                     G_net=G_net, H_net=H_net, device=device)\n",
        "    model.to(device)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_data_device(device, init_method, w_rescale, u_func=None, g_func=None, time_steps=40, num_trajectories=10, shuffle=False,\n",
        "                     coord_type='hamiltonian', proportion=0.5, batch_size=1,\n",
        "                     Ts=0.005, noise_std=0.0, C_q1=0.0, C_q2=0.0,\n",
        "                     g=9.81, Jr=1*1e-5, Lr=0.5, Mp=5.0, Lp=0.5, min_max_rescale=False, rescale_dims=[1, 1, 1, 1]):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "    '''\n",
        "    # create trajectories\n",
        "    q1, p1, q2, p2, energy, derivatives, t_eval = multiple_trajectories_furuta('cpu', init_method, time_steps, num_trajectories, u_func, g_func,\n",
        "                                                                               None, Ts, noise_std, C_q1, C_q2, g, Jr,  Lr,  Mp, Lp)  # u, G,\n",
        "\n",
        "    q1 = (q1*w_rescale[0]).to(device)\n",
        "    p1 = (p1*w_rescale[1]).to(device)\n",
        "    q2 = (q2*w_rescale[2]).to(device)\n",
        "    p2 = (p2*w_rescale[3]).to(device)\n",
        "\n",
        "    if min_max_rescale:\n",
        "        if rescale_dims[0]:\n",
        "            q1 = (q1-q1.amin(dim=(1)).unsqueeze(dim=1)) / \\\n",
        "                ((q1.amax(dim=(1))-q1.amin(dim=(1))).abs().unsqueeze(dim=1))\n",
        "        if rescale_dims[1]:\n",
        "            q2 = (q2-q2.amin(dim=(1)).unsqueeze(dim=1)) / \\\n",
        "                ((q2.amax(dim=(1))-q2.amin(dim=(1))).abs().unsqueeze(dim=1))\n",
        "        if rescale_dims[2]:\n",
        "            p1 = (p1-p1.amin(dim=(1)).unsqueeze(dim=1)) / \\\n",
        "                ((p1.amax(dim=(1))-p1.amin(dim=(1))).abs().unsqueeze(dim=1))\n",
        "        if rescale_dims[3]:\n",
        "            p2 = (p2-p2.amin(dim=(1)).unsqueeze(dim=1)) / \\\n",
        "                ((p2.amax(dim=(1))-p2.amin(dim=(1))).abs().unsqueeze(dim=1))\n",
        "\n",
        "    energy = energy.to(device)\n",
        "    derivatives = derivatives.to(device)\n",
        "    t_eval = t_eval.to(device)\n",
        "    # u = u.to(device)\n",
        "    # G = G.to(device)\n",
        "    # if u_func is not None:\n",
        "    #     u = u_func(t_eval, utype).to(device)\n",
        "    # else:\n",
        "    #     u = torch.zeros_like(t_eval,device=device)\n",
        "    # stds = torch.tensor([q1.std(),p1.std(),q2.std(),p2.std()])\n",
        "\n",
        "    # dataloader to load data in batches\n",
        "    train_loader, test_loader = data_loader_furuta(q1, p1, q2, p2, energy, derivatives, t_eval, batch_size=batch_size,\n",
        "                                                   shuffle=shuffle, proportion=proportion, coord_type=coord_type)  # u, G,\n",
        "    return train_loader, test_loader  # , stds\n",
        "\n",
        "\n",
        "def save_stats(stats, stats_path):\n",
        "    with open(stats_path, 'w') as file:\n",
        "        file.write(json.dumps(stats))  # use `json.loads` to do the reverse\n",
        "    return\n",
        "\n",
        "\n",
        "def read_dict(stats_path):\n",
        "    # read the stats txt file\n",
        "    with open(stats_path) as f:\n",
        "        data = f.read()\n",
        "\n",
        "    data = json.loads(data)\n",
        "    return data\n",
        "    \n",
        "def get_maxmindenom(x, dim1, dim2, rescale_dims):\n",
        "    maximums = x.amax(dim=dim1).unsqueeze(dim=dim2)\n",
        "    minimums = x.amin(dim=dim1).unsqueeze(dim=dim2)\n",
        "    denom = (maximums - minimums).abs()\n",
        "    denom[:, :, ~(torch.Tensor(rescale_dims).bool())] = 1  #\n",
        "    print(\"min max values updated\")\n",
        "    return maximums, minimums, denom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5d-r_s2-ebg"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNjRgnNOFdPr"
      },
      "source": [
        "### loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "id": "iZEOIad5FdD9"
      },
      "outputs": [],
      "source": [
        "def L2_loss(u, v, w=False, dim=(0, 1), param=\"L2\", rescale_loss=False, denom=None):\n",
        "    # u nominal trajectory\n",
        "    # v predicted trajectory\n",
        "    # u and v expected with shape : [time_steps, batch_size , (q1,p1,q2,p1)]\n",
        "    diff = u - v\n",
        "    if rescale_loss:\n",
        "        # min max scaling of u and v using nominal statistics\n",
        "        # ((u-min)/denom)-((v-min)/denom) = (u-v)/denom\n",
        "        diff = (diff) / denom\n",
        "\n",
        "    if param == \"L2weighted\":\n",
        "        # mean only over time steps and batch_size\n",
        "        loss = (((diff).mul(w)).pow(2)).mean(dim=dim).sum()\n",
        "    elif param == \"L2\":\n",
        "        loss = (((diff)).pow(2)).mean(dim=dim).sum()\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T4cbLjJFg05"
      },
      "source": [
        "### horizon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "id": "wcwn_LQ0Fc-3"
      },
      "outputs": [],
      "source": [
        "def select_horizon_list(step, epoch_number, horizon_list = [50,100,150,200,250,300], switch_steps = [200,200,200,150,150,150]):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "      \n",
        "    '''\n",
        "    # throw error if horizon_list and switch_steps not of the same length\n",
        "    assert len(horizon_list)==len(switch_steps), ' horizon_list and switch_steps must have same length'\n",
        "    horizon_updated = 0\n",
        "    if step <switch_steps[0]:\n",
        "        horizon = horizon_list[0]\n",
        "        if step==0:\n",
        "            print('horizon length :', horizon)\n",
        "            horizon_updated = 1\n",
        "    elif step < sum(switch_steps):\n",
        "        for i in range(1,len(switch_steps)):\n",
        "            if (step >= sum(switch_steps[0:i]))&(step < sum(switch_steps[0:i+1])):\n",
        "                horizon = horizon_list[i]\n",
        "                if step==sum(switch_steps[0:i]):\n",
        "                    print('horizon length :', horizon)\n",
        "                    horizon_updated = 1\n",
        "    else:\n",
        "        horizon = horizon_list[-1]\n",
        "    return horizon_updated, horizon "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "clojGJaH77hO"
      },
      "outputs": [],
      "source": [
        "def update_loss_weights(step, w, w_list, switch_steps_weights=[300, 300, 300]):\n",
        "    '''\n",
        "    Description:\n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "    '''\n",
        "    assert len(w_list) == len(\n",
        "        switch_steps_weights), ' w_list and switch_steps must have same length'\n",
        "\n",
        "    if step < switch_steps_weights[0]:\n",
        "        w = w_list[0]\n",
        "        if step == 0:\n",
        "            print('loss weights :', w)\n",
        "    elif step < sum(switch_steps_weights):\n",
        "        for i in range(1, len(switch_steps_weights)):\n",
        "            if (step >= sum(switch_steps_weights[0:i])) & (step < sum(switch_steps_weights[0:i+1])):\n",
        "                w = w_list[i]\n",
        "                if step == sum(switch_steps_weights[0:i]):\n",
        "                    print('loss weights :', w)\n",
        "    else:\n",
        "        w = w_list[-1]\n",
        "    return w\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3ecn-rRNhap"
      },
      "source": [
        "### resnet depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "4WB_V-BMNhPA"
      },
      "outputs": [],
      "source": [
        "def multilevel_strategy_update(device, step, model, resnet_config):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    # resnet strategy 1 :\n",
        "    if resnet_config == 1 or resnet_config == 3:\n",
        "        if step < sum(switch_steps[:1]):\n",
        "            if step == 0:\n",
        "                print('Model size increased')\n",
        "            model.H_net.resblock_list = [0]\n",
        "        elif step == sum(switch_steps[:1]) and len(model.H_net.resblocks) >= 2:\n",
        "            print('Model size increased')\n",
        "            model.H_net.resblock_list = [0, 1]\n",
        "        elif step == sum(switch_steps[:2]) and len(model.H_net.resblocks) >= 3:\n",
        "            print('Model size increased')\n",
        "            model.H_net.resblock_list = [0, 1, 2]\n",
        "        elif step == sum(switch_steps[:3]) and len(model.H_net.resblocks) >= 4:\n",
        "            print('Model size increased')\n",
        "            model.H_net.resblock_list = [0, 1, 2, 3]\n",
        "        elif step == sum(switch_steps[:4]) and len(model.H_net.resblocks) >= 5:\n",
        "            print('Model size increased')\n",
        "            model.H_net.resblock_list = [0, 1, 2, 3, 4]\n",
        "        elif step == sum(switch_steps[:5]) and len(model.H_net.resblocks) >= 6:\n",
        "            print('Model size increased')\n",
        "            model.H_net.resblock_list = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "    # resnet strategy 2 :\n",
        "    if resnet_config == 2:\n",
        "        if step < sum(switch_steps[:1]):  # init : [0,1,2,3,4,5,6,7,8,9,10,11]\n",
        "            if step == 0:\n",
        "                print('Model size increased')\n",
        "            model.H_net.resblock_list = [0, 16]\n",
        "            model.H_net.alpha = torch.tensor(\n",
        "                [1/len(model.H_net.resblock_list)], device=device)\n",
        "        elif step == sum(switch_steps[:1]) and len(model.H_net.resblocks) >= 4:\n",
        "            print('Model size increased')\n",
        "            model.H_net.init_new_resblocks(0, 8, 16)\n",
        "            model.H_net.resblock_list = [0, 8, 16]\n",
        "            model.H_net.alpha = torch.tensor(\n",
        "                [1/len(model.H_net.resblock_list)], device=device)\n",
        "        elif step == sum(switch_steps[:2]) and len(model.H_net.resblocks) >= 6:\n",
        "            print('Model size increased')\n",
        "            model.H_net.init_new_resblocks(0, 4, 8)\n",
        "            model.H_net.init_new_resblocks(8, 12, 16)\n",
        "            model.H_net.resblock_list = [0, 4, 8, 12, 16]\n",
        "            model.H_net.alpha = torch.tensor(\n",
        "                [1/len(model.H_net.resblock_list)], device=device)\n",
        "        elif step == sum(switch_steps[:3]) and len(model.H_net.resblocks) >= 8:\n",
        "            print('Model size increased')\n",
        "            model.H_net.init_new_resblocks(0, 2, 4)\n",
        "            model.H_net.init_new_resblocks(4, 6, 8)\n",
        "            model.H_net.init_new_resblocks(8, 10, 12)\n",
        "            model.H_net.init_new_resblocks(12, 14, 16)\n",
        "            model.H_net.resblock_list = [0, 2, 4, 6, 8, 10, 12, 14, 16]\n",
        "            model.H_net.alpha = torch.tensor(\n",
        "                [1/len(model.H_net.resblock_list)], device=device)\n",
        "        elif step == sum(switch_steps[:4]) and len(model.H_net.resblocks) >= 10:\n",
        "            print('Model size increased')\n",
        "            model.H_net.init_new_resblocks(0, 1, 2)\n",
        "            model.H_net.init_new_resblocks(2, 3, 4)\n",
        "            model.H_net.init_new_resblocks(4, 5, 6)\n",
        "            model.H_net.init_new_resblocks(8, 9, 10)\n",
        "            model.H_net.init_new_resblocks(10, 11, 12)\n",
        "            model.H_net.init_new_resblocks(11, 12, 13)\n",
        "            model.H_net.init_new_resblocks(12, 13, 14)\n",
        "            model.H_net.init_new_resblocks(14, 15, 16)\n",
        "            model.H_net.resblock_list = [\n",
        "                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
        "            model.H_net.alpha = torch.tensor(\n",
        "                [1/len(model.H_net.resblock_list)], device=device)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n",
              " [0, 2, 4, 6, 8, 10, 12, 14, 16],\n",
              " [0, 4, 8, 12, 16],\n",
              " [0, 8, 16],\n",
              " [0, 16]]"
            ]
          },
          "execution_count": 433,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_multi_level_list_conf2(length=17, num_lists=4):\n",
        "    \n",
        "    largest_list =list(range(length))\n",
        "    all_lists = [largest_list]\n",
        "    # print(largest_list)\n",
        "    prev_list = largest_list\n",
        "    for j in range(num_lists):\n",
        "        new_list = []\n",
        "        for i, elem in enumerate(prev_list):\n",
        "            # print(i)\n",
        "            if not i%2 and i<len(prev_list):\n",
        "                new_list.append(elem)\n",
        "            if i == len(prev_list)-1:\n",
        "                # print(new_list)\n",
        "                all_lists.append(new_list)\n",
        "                prev_list = new_list\n",
        "    return all_lists\n",
        "all_lists = generate_multi_level_list_conf2(length=17, num_lists=4)\n",
        "all_lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "UDGAQoLIQVRN"
      },
      "outputs": [],
      "source": [
        "# switch_steps = [200, 100, 100, 100, 100, 100]\n",
        "# H_net = ResNet_config1(resblock_list=[0], num_blocks = 3, input_dim=4, hidden_dim=70, \n",
        "#                 nb_hidden_layers=2, output_dim=1, activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2')\n",
        "# for block in H_net.resblocks:\n",
        "#     block.to(device)\n",
        "# model = Nes_HDNN(u_func=u_func, G_net=g_func, H_net=H_net, device=device)\n",
        "# model.to(device)\n",
        "# multilevel_strategy_update(300, model,resnet_config=1)\n",
        "# print(model.H_net.resblock_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "-quT749nQVND"
      },
      "outputs": [],
      "source": [
        "# H_net = ResNet_config2(resblock_list = [0,7], num_blocks = 12, input_dim=4, \n",
        "#                        hidden_dim=40, nb_hidden_layers=2, output_dim=1, \n",
        "#                        activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2')\n",
        "# num_params = 0\n",
        "# for block in H_net.resblocks:\n",
        "#     block.to(device)\n",
        "#     num_params += count_parameters(block)\n",
        "\n",
        "# model = Nes_HDNN(u_func=u_func, G_net=g_func, H_net=H_net, device=device)\n",
        "# model.to(device)\n",
        "\n",
        "# multilevel_strategy_update(300, model,resnet_config=2)\n",
        "# print(model.H_net.resblock_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZiNuDeAFiUc"
      },
      "source": [
        "### train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "id": "RcxlyTUurZI5"
      },
      "outputs": [],
      "source": [
        "def train(model, Ts, train_loader, test_loader, w, grad_clip, lr_schedule, begin_decay, epoch_number, resnet_config = False,\n",
        "        alternating=False, horizon=False, horizon_type=False,\n",
        "        horizon_list = [50,100,150,200,250,300], \n",
        "        switch_steps = [200,200,200,150,150,150],\n",
        "        epochs = 20, \n",
        "        loss_type = 'L2', collect_grads = False,\n",
        "        rescale_loss = False,\n",
        "        rescale_dims = [1,1,1,1]\n",
        "        ):\n",
        "    '''\n",
        "    Description: \n",
        "\n",
        "    Inputs:\n",
        "\n",
        "    Outpus:\n",
        "    '''\n",
        "    ## TODO : make a function for one epoch\n",
        "    ## first training steps on smaller amount of time_steps\n",
        "\n",
        "    lr = 1e-3\n",
        "    \n",
        "    optim = torch.optim.AdamW(model.parameters(), lr, weight_decay=1e-4) # Adam\n",
        "    if lr_schedule:\n",
        "        scheduler = LinearLR(optim, start_factor=1.0, end_factor=0.5, total_iters=epochs-begin_decay)\n",
        "\n",
        "    logs = {'train_loss': [], 'test_loss': [], 'grads_preclip': [], 'grads_postclip': [], 'layer_names': []}\n",
        "\n",
        "    denom = torch.tensor([1],device=device)\n",
        "    horizon_updated = 1\n",
        "\n",
        "    for step in range(epochs):\n",
        "        \n",
        "        train_loss = 0\n",
        "        test_loss = 0\n",
        "        t1 = time.time()\n",
        "\n",
        "        if horizon_type == 'schedule':\n",
        "            pass\n",
        "        #     horizon, num_steps= select_horizon_wschedule(step,optim,\n",
        "        #                                                   epoch_number,\n",
        "        #                                                   switch_steps)\n",
        "        #     if num_steps :\n",
        "        #         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, num_steps)\n",
        "        elif horizon_type == 'auto': \n",
        "            horizon_updated, horizon = select_horizon_list(step, epoch_number, horizon_list, switch_steps)\n",
        "        elif horizon_type == 'constant': \n",
        "            horizon = horizon\n",
        "\n",
        "        # increase the model size and initialie the new parameters\n",
        "        if resnet_config:\n",
        "            model = multilevel_strategy_update(device, step, model, resnet_config)\n",
        "\n",
        "        model.train()\n",
        "        \n",
        "        for i_batch, (x, t_eval) in enumerate(train_loader): \n",
        "            # x is [batch_size, time_steps, (q1,p1,q2,p1,u,g1,g2,g3,g4)]\n",
        "            # print('xshape',x.shape)\n",
        "            # print('tshape',t_eval.shape)\n",
        "            t_eval = t_eval[0,:horizon]\n",
        "\n",
        "            # calculate (max-min) to rescale the loss function\n",
        "            if rescale_loss:\n",
        "                if horizon_updated:\n",
        "                    _, _, denom =  get_maxmindenom(x=x[:, :horizon, :4].permute(1,0,2),dim1=(0),dim2=(0), rescale_dims=rescale_dims)\n",
        "\n",
        "            for i in range(2 if alternating else 1): # only runs once if alternating = False\n",
        "                if i==0 and alternating: # train only the model approximating G\n",
        "                    model.freeze_H_net(freeze=True)\n",
        "                    model.freeze_G_net(freeze=False)\n",
        "                elif i==1 and alternating: # train only the model approximating H\n",
        "                    model.freeze_H_net(freeze=False)\n",
        "                    model.freeze_G_net(freeze=True)\n",
        "\n",
        "                train_x_hat = odeint(model, x[:, 0, :4], t_eval, method='rk4', options=dict(step_size=Ts))     \n",
        "                # print('train_x_hat',train_x_hat.shape)       \n",
        "                # train_x_hat is [time_steps, batch_size, (q1,p1,q2,p1)] \n",
        "\n",
        "                train_loss_mini = L2_loss(x[:, :horizon, :4].permute(1,0,2) , \n",
        "                                            train_x_hat[:,:,:4], w, param = loss_type, \n",
        "                                            rescale_loss=rescale_loss, denom=denom)\n",
        "                # after permute x is [time_steps, batch_size, (q1,p1,q2,p1)]\n",
        "\n",
        "                # loss(u, v, w = False, dim = (0,1), param = loss_type)\n",
        "                if (not step%10) and (i_batch ==0):\n",
        "                    t_plot = time.time()\n",
        "                    training_plot(t_eval, train_x_hat[:,:,:4], x[:, :horizon, :4])\n",
        "                    print('plot time :' , time.time()-t_plot)\n",
        "\n",
        "                train_loss = train_loss + train_loss_mini.item()\n",
        "                \n",
        "                train_loss_mini.backward() \n",
        "                if collect_grads: \n",
        "                    layer_names, all_grads_preclip = collect_gradients(model.named_parameters())\n",
        "                    # print(all_grads_preclip)\n",
        "                if grad_clip : # gradient clipping to a norm of 1\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                if collect_grads: \n",
        "                    layer_names, all_grads_postclip = collect_gradients(model.named_parameters())\n",
        "                    logs['layer_names'].append(layer_names)\n",
        "                    logs['grads_preclip'].append(all_grads_preclip)\n",
        "                    logs['grads_postclip'].append(all_grads_postclip)\n",
        "\n",
        "                optim.step() \n",
        "                optim.zero_grad() \n",
        "\n",
        "                if step>begin_decay and lr_schedule:\n",
        "                    scheduler.step()\n",
        "                \n",
        "                # if (horizon == 'schedule') and do_step:\n",
        "                #   scheduler.step()                                                                                                                       \n",
        "        \n",
        "        t2 = time.time()\n",
        "        train_time = t2-t1\n",
        "\n",
        "        model.eval()\n",
        "        if test_loader: \n",
        "                if not (step%10): # run validation every 10 steps\n",
        "                    for x, t_eval in iter(test_loader):\n",
        "                        with torch.no_grad(): # we won't need gradients for testing\n",
        "                            # run test data\n",
        "                            t_eval = t_eval[0,:horizon]\n",
        "          \n",
        "                            test_x_hat = odeint(model, x[:, 0, :4], t_eval, method='rk4', \n",
        "                                                options=dict(step_size=Ts))\n",
        "\n",
        "                            #test_loss_mini = L2_loss(torch.permute(x[:, :, :horizon], (2,0,1)) , test_x_hat[:horizon,:,:],w)\n",
        "                            \n",
        "                            test_loss_mini = L2_loss(x[:, :horizon, :4].permute(1,0,2) , \n",
        "                                                    test_x_hat[:horizon,:,:4], w, param = loss_type,\n",
        "                                                    rescale_loss=rescale_loss, denom=denom)\n",
        "                            test_loss = test_loss + test_loss_mini.item()\n",
        "                    test_time = time.time()-t2\n",
        "                    print('epoch {:4d} | train time {:.2f} | train loss {:8e} | test loss {:8e} | test time {:.2f}  '\n",
        "                          .format(step, train_time, train_loss, test_loss,test_time))\n",
        "                    logs['test_loss'].append(test_loss)\n",
        "                    \n",
        "                else:\n",
        "                    print('epoch {:4d} | train time {:.2f} | train loss {:8e} '\n",
        "                          .format(step, train_time, train_loss))\n",
        "        else:\n",
        "            print('epoch {:4d} | train time {:.2f} | train loss {:8e} '\n",
        "                  .format(step, train_time, train_loss))\n",
        "        \n",
        "        # logging\n",
        "        logs['train_loss'].append(train_loss)\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b6B9xeLWPfT"
      },
      "source": [
        "# Sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "7WRVPbDTl7hF",
        "outputId": "cc6d6b97-90a4-44ac-d990-9ebdd4a25f84"
      },
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real' # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) \n",
        "# C_q1, C_q2 = 0.000009, 0.00004\n",
        "utype = 'sine' #  'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 2 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.0001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = 'simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_closetopi' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 800\n",
        "num_trajectories = 100\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 10000, 1, 100000] # [1, 9000, 1, 10000] # [1,1,1,1]#\n",
        "\n",
        "# train_loader, test_loader = load_data_device(device, init_method, w_rescale, \n",
        "#                                             u_func, g_func, time_steps, \n",
        "#                                             shuffle = False, \n",
        "#                                             num_trajectories = num_trajectories, \n",
        "#                                             coord_type = 'hamiltonian', \n",
        "#                                             proportion = proportion, batch_size = batch_size, \n",
        "#                                             Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
        "#                                             g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp) \n",
        "\n",
        "\n",
        "# q1, p1, q2, p2, t_eval = get_trajectory_furuta(device, init_method, num_trajectories, u_func, g_func, time_steps, None, noise_std, Ts, C_q1, \n",
        "#                           C_q2, g, Jr, Lr, Mp, Lp)\n",
        "# energy, derivatives = get_energy_furuta(device, time_steps, Ts, u_func, g_func, q1, p1, q2, p2, C_q1, C_q2, g, Jr, Lr, Mp, Lp)\n",
        "\n",
        "q1, p1, q2, p2, energy, derivatives, t_eval = multiple_trajectories_furuta('cpu', init_method, time_steps, num_trajectories, u_func, g_func, \n",
        "                          None, Ts,\n",
        "                          noise_std, C_q1, C_q2, g, \n",
        "                          Jr, Lr, Mp, Lp, energ_deriv=True)\n",
        "\n",
        "# print(u.shape)\n",
        "# print(G.shape)\n",
        "print(q1.shape)\n",
        "print(p1.shape)\n",
        "print(q2.shape)\n",
        "print(p2.shape)\n",
        "print(t_eval.shape)\n",
        "print(energy.shape)\n",
        "print(derivatives.shape)\n",
        "print(1/q1.std(), 1/p1.std(), 1/q2.std(), 1/p2.std())\n",
        "\n",
        "# w1, w2, w3, w4 = q1.std(), p1.std(), q2.std(), p2.std()\n",
        "# w_rescale = [1, 10000, 1, 10000]\n",
        "w1 = w_rescale[0]\n",
        "w2 = w_rescale[1]\n",
        "w3 = w_rescale[2]\n",
        "w4 = w_rescale[3]\n",
        "\n",
        "fix, ax = plt.subplots(1,4,figsize = (10,3))\n",
        "\n",
        "sns.histplot(q1.ravel(), ax=ax[0])\n",
        "sns.histplot(p1.ravel()*w2, ax=ax[1])\n",
        "sns.histplot(q2.ravel()*w3, ax=ax[2])\n",
        "sns.histplot(p2.ravel()*w4, ax=ax[3])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fix, ax = plt.subplots(1,4,figsize = (10,3))\n",
        "sns.histplot(q1.ravel(), ax=ax[0])\n",
        "sns.histplot(p1.ravel(), ax=ax[1])\n",
        "sns.histplot(q2.ravel(), ax=ax[2])\n",
        "sns.histplot(p2.ravel(), ax=ax[3])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_nominal_normalised.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in [q1, p1, q2, p2]:\n",
        "    x_nominal = x\n",
        "    maximums = x_nominal.amax(dim=(1))\n",
        "    minimums = x_nominal.amin(dim=(1))\n",
        "    denom = (maximums-minimums).abs().unsqueeze(dim=1)\n",
        "\n",
        "    x_nominal_normalised = (x_nominal-minimums.unsqueeze(dim=1))/denom\n",
        "    x = x_nominal_normalised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q1 = (q1-q1.amin(dim=(1)).unsqueeze(dim=1))/((q1.amax(dim=(1))-q1.amin(dim=(1))).abs().unsqueeze(dim=1))\n",
        "q2 = (q2-q2.amin(dim=(1)).unsqueeze(dim=1))/((q2.amax(dim=(1))-q2.amin(dim=(1))).abs().unsqueeze(dim=1))\n",
        "p1 = (p1-p1.amin(dim=(1)).unsqueeze(dim=1))/((p1.amax(dim=(1))-p1.amin(dim=(1))).abs().unsqueeze(dim=1))\n",
        "p2 = (p2-p2.amin(dim=(1)).unsqueeze(dim=1))/((p2.amax(dim=(1))-p2.amin(dim=(1))).abs().unsqueeze(dim=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix, ax = plt.subplots(1,4,figsize = (10,3))\n",
        "\n",
        "sns.histplot(q1.ravel(), ax=ax[0])\n",
        "sns.histplot(p1.ravel(), ax=ax[1])\n",
        "sns.histplot(q2.ravel(), ax=ax[2])\n",
        "sns.histplot(p2.ravel(), ax=ax[3])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sMbBj-RLOnGX",
        "outputId": "39c17809-892d-4374-ef58-6bc7c04fdf4b"
      },
      "outputs": [],
      "source": [
        "u=u_func.forward(t_eval).cpu().detach() \n",
        "for n in range(10): \n",
        "   plot_traj_furuta_withinput(t_eval.cpu().detach(), \n",
        "   q1[n,:].cpu().detach(), \n",
        "   p1[n,:].cpu().detach()/w2, \n",
        "   q2[n,:].cpu().detach()/w3, \n",
        "   p2[n,:].cpu().detach()/w4, \n",
        "   energy = energy[n,:].cpu().detach(), input=u, \n",
        "                      title = 'Trajectory of the generalized coordinates', coord_type='hamiltonian') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgHj8NUxL-5p"
      },
      "outputs": [],
      "source": [
        "batch_size=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw6Cpm0bL6ox"
      },
      "outputs": [],
      "source": [
        "train_loader, test_loader = data_loader_furuta(q1, p1, q2, p2, energy, derivatives, t_eval, batch_size,\n",
        "                       shuffle = True, proportion = 0.0, coord_type='hamiltonian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnB5k1UPVI3c"
      },
      "outputs": [],
      "source": [
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale, u_func, g_func, time_steps, num_trajectories, shuffle=False,\n",
        "                     coord_type='hamiltonian', proportion=proportion, batch_size=batch_size, \n",
        "                     Ts = Ts , noise_std = noise_std, C_q1 = C_q1, C_q2 = C_q2, \n",
        "                     g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp,min_max_rescale = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "b1J_Yq40XIsk",
        "outputId": "a7798792-fa90-47a2-cbeb-1485d6a9773d"
      },
      "outputs": [],
      "source": [
        "x,t = next(iter(train_loader))\n",
        "for n in range(10):\n",
        "  t_eval = t[0,:].cpu().detach()\n",
        "  q1 = x[n,:,0].cpu().detach()\n",
        "  p1 = x[n,:,1].cpu().detach()\n",
        "  q2 = x[n,:,2].cpu().detach()\n",
        "  p2 = x[n,:,3].cpu().detach()\n",
        "  u = u_func.forward(t_eval).cpu().detach()\n",
        "  G = g_func.forward(x[n,:,:4]).cpu().detach()\n",
        "  plot_traj_furuta_withinput(t_eval, q1, p1, q2, p2,input=u,\n",
        "                      title = 'Trajectory of the generalized coordinates', coord_type='hamiltonian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "m_hbUTe4jTqn",
        "outputId": "160752fb-689a-4443-bf3d-5412dccae28b"
      },
      "outputs": [],
      "source": [
        "model = torch.nn.Linear(2,1)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-4, weight_decay=1e-4)\n",
        "torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.3333333333333333, end_factor=1.0, total_iters=5, last_epoch=- 1, verbose=False)\n",
        "max_epochs = 100\n",
        "begin_decay=80\n",
        "scheduler = LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=max_epochs-begin_decay)\n",
        "lrs = []\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    if epoch>begin_decay:\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    lrs.append(scheduler.get_last_lr())\n",
        "plt.plot(lrs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# min max normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real' # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) \n",
        "# C_q1, C_q2 = 0.000009, 0.00004\n",
        "utype = 'sine' #  'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 4 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.0001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = 'simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_closetopi' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 800\n",
        "num_trajectories = 125\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 10000, 1, 100000] # [1, 9000, 1, 10000] # [1,1,1,1]#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale, \n",
        "                                            u_func, g_func, time_steps, \n",
        "                                            shuffle = False, \n",
        "                                            num_trajectories = num_trajectories, \n",
        "                                            coord_type = 'hamiltonian', \n",
        "                                            proportion = proportion, batch_size = batch_size, \n",
        "                                            Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
        "                                            g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "horizon_list = [20, 100, 150,300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x,t = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for n in range(10):\n",
        "  t_eval = t[0,:].cpu().detach()\n",
        "  q1 = x[n,:,0].cpu().detach()\n",
        "  p1 = x[n,:,1].cpu().detach()\n",
        "  q2 = x[n,:,2].cpu().detach()\n",
        "  p2 = x[n,:,3].cpu().detach()\n",
        "  u = u_func.forward(t_eval).cpu().detach()\n",
        "  G = g_func.forward(x[n,:,:4]).cpu().detach()\n",
        "  plot_traj_furuta_withinput(t_eval, q1, p1, q2, p2,input=u,\n",
        "                      title = 'Trajectory of the generalized coordinates', coord_type='hamiltonian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix, ax = plt.subplots(1,4,figsize = (10,3))\n",
        "print(x.shape)\n",
        "sns.histplot(x[:,:,0].ravel(), ax=ax[0])\n",
        "sns.histplot(x[:,:,1].ravel(), ax=ax[1])\n",
        "sns.histplot(x[:,:,2].ravel(), ax=ax[2])\n",
        "sns.histplot(x[:,:,3].ravel(), ax=ax[3])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i=3\n",
        "x_nominal = x[:,:,:]\n",
        "\n",
        "rescale_dims=[1,1,1,1]\n",
        "dim1, dim2 = (1),(1)\n",
        "maximums, minimums, denom = get_maxmindenom(x_nominal, dim1, dim2, rescale_dims)\n",
        "\n",
        "def min_max_rescale_(x, maximums, minimums, denom):\n",
        "    x_nominal_normalised = (x-minimums)/denom\n",
        "    return x_nominal_normalised\n",
        "\n",
        "x_pred_normalised = (x_nominal-minimums)/denom\n",
        "print(minimums.shape)\n",
        "print(maximums.shape)\n",
        "print(denom.shape)\n",
        "print(x_nominal.shape)\n",
        "print(x_pred_normalised.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fix, ax = plt.subplots(1,4,figsize = (10,3))\n",
        "\n",
        "sns.histplot(x_pred_normalised[:,:,0].ravel(), ax=ax[0])\n",
        "sns.histplot(x_pred_normalised[:,:,1].ravel(), ax=ax[1])\n",
        "sns.histplot(x_pred_normalised[:,:,2].ravel(), ax=ax[2])\n",
        "sns.histplot(x_pred_normalised[:,:,3].ravel(), ax=ax[3])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for n in range(10):\n",
        "  t_eval = t[0,:horizon_list[i]].cpu().detach()\n",
        "  q1 = x_pred_normalised[n,:,0].cpu().detach()\n",
        "  p1 = x_pred_normalised[n,:,1].cpu().detach()\n",
        "  q2 = x_pred_normalised[n,:,2].cpu().detach()\n",
        "  p2 = x_pred_normalised[n,:,3].cpu().detach()\n",
        "  u = u_func.forward(t_eval).cpu().detach()\n",
        "  G = g_func.forward(x[n,:,:4]).cpu().detach()\n",
        "  plot_traj_furuta_withinput(t_eval, q1, p1, q2, p2,input=u,\n",
        "                      title = 'Trajectory of the generalized coordinates', coord_type='hamiltonian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print((b).shape)\n",
        "\n",
        "# plt.subplots(sns.histplot((b[:,:,0]).ravel(),ax=ax[0]))\n",
        "# plt.subplots(sns.histplot((b[:,:,1]).ravel(),ax=ax[1]))\n",
        "# plt.subplots(sns.histplot((b[:,:,2]).ravel(),ax=ax[2]))\n",
        "# plt.subplots(sns.histplot((b[:,:,3]).ravel(),ax=ax[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2azdHB9irsbo"
      },
      "source": [
        "# Generate, load and save the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dir-6ePzw2dC"
      },
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real' # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) \n",
        "\n",
        "utype = None #  'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 4 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype='simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_nozero' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 300\n",
        "num_trajectories = 10\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 1000, 1, 10000] # [1, 9000, 1, 10000]\n",
        "\n",
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale, \n",
        "                                            u_func, g_func, time_steps, \n",
        "                                            shuffle = False, \n",
        "                                            num_trajectories = num_trajectories, \n",
        "                                            coord_type = 'hamiltonian', \n",
        "                                            proportion = proportion, batch_size = batch_size, \n",
        "                                            Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
        "                                            g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQoA6EWtJycA"
      },
      "outputs": [],
      "source": [
        "x,t = next(iter(train_loader))\n",
        "print(x.shape)\n",
        "for n in range(1):\n",
        "  t_eval = t[0,:].cpu().detach()\n",
        "  q1 = x[n,:,0].cpu().detach()\n",
        "  p1 = x[n,:,1].cpu().detach()\n",
        "  q2 = x[n,:,2].cpu().detach()\n",
        "  p2 = x[n,:,3].cpu().detach()\n",
        "  \n",
        "  u = u_func.forward(t_eval).cpu().detach()\n",
        "  G = g_func.forward(x[n,:,:4]).cpu().detach()\n",
        "  energy, derivatives = get_energy_furuta(device, time_steps, Ts, u_func, g_func, \n",
        "  q1, p1, q2, p2, C_q1, C_q2, g, Jr, Lr, Mp, Lp)\n",
        "  print('q1',q1.shape)\n",
        "  print('energy',energy.shape)\n",
        "  energy = energy.detach().squeeze()\n",
        "\n",
        "  plot_traj_furuta_withinput(t_eval, q1, p1, q2, p2, energy=energy, input=u,\n",
        "                      title = 'Trajectory of the generalized coordinates', coord_type='hamiltonian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivE30zYOrsbq"
      },
      "outputs": [],
      "source": [
        "# suffix = 'Ts_{:.3f}_Jr_{:.2f}_Lr_{:.2f}_Mp_{:.2f}_Lp_{:.2f}'.format(Ts, Jr, Lr, Mp, Lp)\n",
        "# suffix = suffix + '_'+ utype\n",
        "# print(suffix)\n",
        "# train_loader_path = PATH + 'data/datasets/train_loader_' + suffix + '.pt'\n",
        "# test_loader_path = PATH + 'data/datasets/test_loader_' + suffix + '.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90oeaYmmrsbs"
      },
      "outputs": [],
      "source": [
        "# torch.save(train_loader, train_loader_path)\n",
        "# if test_loader is not None:\n",
        "#     torch.save(test_loader, test_loader_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5rw1BVwrsbt"
      },
      "outputs": [],
      "source": [
        "# train_loader = torch.load(train_loader_path)\n",
        "# test_loader = torch.load(test_loader_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK-tFX-vrsbt"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WBPS5kWJycC"
      },
      "source": [
        "#### U_HNN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SebIxog3JycC",
        "outputId": "11493996-f673-4be6-d649-ae404ea07a2d"
      },
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real' # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) \n",
        "\n",
        "utype = None #  'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "gtype = None\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_nozero' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 300\n",
        "num_trajectories = 100\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "# w_rescale = [1, 1000, 1, 10000] # [1, 9000, 1, 10000]\n",
        "shuffle = False\n",
        "coord_type = 'hamiltonian'\n",
        "rescale_dims = [1,1,1,0]\n",
        "min_max_rescale = True\n",
        "\n",
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale, \n",
        "                                            u_func, g_func, time_steps, \n",
        "                                            shuffle = shuffle, \n",
        "                                            num_trajectories = num_trajectories, \n",
        "                                            coord_type = coord_type, \n",
        "                                            proportion = proportion, batch_size = batch_size, \n",
        "                                            Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
        "                                            g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp,\n",
        "                                            min_max_rescale = min_max_rescale, rescale_dims = rescale_dims) \n",
        "                                            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFeWFdOtJycC",
        "outputId": "4fa3ad70-dd42-4e9e-c4dc-d06d88005c62"
      },
      "outputs": [],
      "source": [
        "horizon_list = [50,100,150,200,250,300]\n",
        "switch_steps = [200,100,100,100,100,100]\n",
        "# horizon_list = [50,100]\n",
        "# switch_steps = [5,5]\n",
        "epoch_number = sum(switch_steps)\n",
        "grad_clip = True # activate gradient clipping\n",
        "lr_schedule = True # activate lr schedule\n",
        "begin_decay = 2250 # epoch at which lr starts decaying\n",
        "\n",
        "model_name = 'UODEHNN_mlp'\n",
        "\n",
        "H_net = MLP(input_dim=4, hidden_dim=70, nb_hidden_layers=2, output_dim=1, activation='x+sin(x)^2')\n",
        "model = U_HNN(input_dim=4, H_net=H_net, device=device) \n",
        "model.to(device) \n",
        "num_params = count_parameters(model) \n",
        "\n",
        "weights = [1.0, 1.0, 1.0, 1.0] # weights for the loss functions\n",
        "weights_title = ' | weights = ' + str(weights) \n",
        "\n",
        "save_prefix = '{:d}e_w{:05.1f}_{:05.1f}_{:05.1f}_{:05.1f}_p{:d}k_Ts{:1.3f}_'.format(epoch_number,weights[0],weights[1],weights[2],weights[3],int((num_params-num_params%1000)/1000),Ts)\n",
        "if utype is None:\n",
        "    input = 'noinput'\n",
        "else :\n",
        "    input = utype\n",
        "save_prefix = model_name +'_'+ input + '_' + str(num_trajectories)+'traj'+'_' + furuta_type + '_' + 'noise'+str(noise_std)+'_'+  save_prefix \n",
        "if grad_clip:\n",
        "    save_prefix = save_prefix + 'gradcl_'\n",
        "if lr_schedule: \n",
        "    save_prefix = save_prefix + 'lrsched_'\n",
        "if C_q1==0 and C_q2==0:\n",
        "    save_prefix = save_prefix + 'nodissip'\n",
        "else:\n",
        "    save_prefix = save_prefix + 'wdissip'\n",
        "\n",
        "print('Total number of epochs:',epoch_number)\n",
        "print('H_net number of parameters :', num_params)\n",
        "print('Save file prefix : ', save_prefix)\n",
        "\n",
        "if len(horizon_list) == len(switch_steps) :\n",
        "    print('horizon_list and switch_steps have the same size')\n",
        "else:\n",
        "    raise ValueError('horizon_list and switch_steps do NOT have the same size')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0p7VJblfYUws",
        "outputId": "46075fbd-0f71-4b46-dda2-860f7d652f9e"
      },
      "outputs": [],
      "source": [
        "stats = train(model = model, \n",
        "            Ts = Ts, \n",
        "            train_loader = train_loader, \n",
        "            test_loader = test_loader, \n",
        "            w=torch.tensor(weights, device=device),\n",
        "            grad_clip = grad_clip,\n",
        "            lr_schedule = lr_schedule,\n",
        "            begin_decay = begin_decay, \n",
        "            resnet_config = None,\n",
        "            epoch_number = epoch_number, \n",
        "            alternating = False,\n",
        "            horizon = False, \n",
        "            horizon_type = 'auto', \n",
        "            horizon_list = horizon_list, \n",
        "            switch_steps = switch_steps, \n",
        "            epochs = epoch_number, \n",
        "            loss_type = 'L2weighted', \n",
        "            collect_grads = False,\n",
        "            rescale_loss = True,\n",
        "            rescale_dims = [1,1,1,0]\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "TJVkivwBD-F1",
        "outputId": "7b7c1124-8542-4e37-d9d8-d9d882e785dd"
      },
      "outputs": [],
      "source": [
        "plot_grads(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKc9x8kW_WBa"
      },
      "outputs": [],
      "source": [
        "# save model to disk\n",
        "model_path = 'data/models/'+save_prefix+'model_test'\n",
        "torch.save(model.state_dict(), PATH+model_path)\n",
        "\n",
        "# save the stats\n",
        "stats_path = PATH+'data/stats/'+save_prefix+'stats.txt'\n",
        "save_stats(stats, stats_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F18LW49JJycE"
      },
      "source": [
        "#### NESHDNN + mlp + input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 456,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ9MdLpvJycF",
        "outputId": "284c0edd-0486-451d-8d83-ac6df2c080b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real'  # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(\n",
        "    which=furuta_type)\n",
        "# C_q1, C_q2 = 0.000009, 0.00004\n",
        "utype = 'chirp'  # 'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 2  # 4 # 1.4\n",
        "u_func.params['scale'] = 0.0001  # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = 'simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_nozero'  # 'random_nozero' # 'random_closetopi'\n",
        "time_steps = 800\n",
        "num_trajectories = 100\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 1000, 1, 100000]  # [1, 9000, 1, 10000]\n",
        "coord_type = 'hamiltonian'\n",
        "min_max_rescale = True\n",
        "rescale_dims = [1, 1, 1, 1]\n",
        "shuffle = False\n",
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale,\n",
        "                                             u_func, g_func, time_steps,\n",
        "                                             shuffle=shuffle,\n",
        "                                             num_trajectories=num_trajectories,\n",
        "                                             coord_type=coord_type,\n",
        "                                             proportion=proportion, batch_size=batch_size,\n",
        "                                             Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2,\n",
        "                                             g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
        "                                             min_max_rescale=min_max_rescale, rescale_dims = rescale_dims)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QOhfGdQJycF",
        "outputId": "e07b21cc-962d-41df-e15f-1166e59fa1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of epochs: 1000\n",
            "H_net number of parameters : 33303\n",
            "Save file prefix :  NESHDNN_mlp_chirp_100traj_real_noise0.0_1000e_w001.0_001.0_001.0_001.0_p33k_Ts0.005_gradcl_lrsched_nodissip\n",
            "horizon_list and switch_steps have the same size \n"
          ]
        }
      ],
      "source": [
        "# horizon_list = [40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, 260, 280, 300]\n",
        "# switch_steps = [500, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
        "\n",
        "horizon_list = [50, 100, 150, 200, 250, 300]\n",
        "switch_steps = [300, 200, 200, 100, 100, 100]\n",
        "epoch_number = sum(switch_steps)\n",
        "grad_clip = True  # activate gradient clipping\n",
        "lr_schedule = True  # activate lr schedule\n",
        "begin_decay = 2250  # epoch at which lr starts decaying\n",
        "\n",
        "model_name = 'NESHDNN_mlp'\n",
        "\n",
        "H_net = MLP(input_dim=4, hidden_dim=90, nb_hidden_layers=4,\n",
        "            output_dim=1, activation='x+sin(x)^2')\n",
        "model = Nes_HDNN(u_func=u_func, G_net=g_func,\n",
        "                 H_net=H_net, device=device, dissip=False)\n",
        "model.to(device)\n",
        "num_params = count_parameters(model)\n",
        "\n",
        "weights = [1.0, 1.0, 1.0, 1.0]\n",
        "weights_title = ' | weights = ' + str(weights)\n",
        "\n",
        "save_prefix = '{:d}e_w{:05.1f}_{:05.1f}_{:05.1f}_{:05.1f}_p{:d}k_Ts{:1.3f}_'.format(\n",
        "    epoch_number, weights[0], weights[1], weights[2], weights[3], int((num_params-num_params % 1000)/1000), Ts)\n",
        "if utype is None:\n",
        "    input = 'noinput'\n",
        "else:\n",
        "    input = utype\n",
        "save_prefix = model_name + '_' + input + '_' + \\\n",
        "    str(num_trajectories)+'traj'+'_' + furuta_type + \\\n",
        "    '_' + 'noise'+str(noise_std)+'_' + save_prefix\n",
        "if grad_clip:\n",
        "    save_prefix = save_prefix + 'gradcl_'\n",
        "if lr_schedule:\n",
        "    save_prefix = save_prefix + 'lrsched_'\n",
        "if C_q1 == 0 and C_q2 == 0:\n",
        "    save_prefix = save_prefix + 'nodissip'\n",
        "else:\n",
        "    save_prefix = save_prefix + 'wdissip'\n",
        "\n",
        "print('Total number of epochs:', epoch_number)\n",
        "print('H_net number of parameters :', num_params)\n",
        "print('Save file prefix : ', save_prefix)\n",
        "\n",
        "if len(horizon_list) == len(switch_steps):\n",
        "    print('horizon_list and switch_steps have the same size ')\n",
        "else:\n",
        "    raise ValueError('horizon_list and switch_steps do NOT have the same size ', len(\n",
        "        horizon_list), len(switch_steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {
        "id": "DyiVnpXrgowB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "horizon length : 50\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot time : 0.6356368064880371\n",
            "epoch    0 | train time 3.28 | train loss 4.043246e-01 \n",
            "epoch    1 | train time 2.67 | train loss 3.990547e-01 \n",
            "epoch    2 | train time 2.46 | train loss 3.927431e-01 \n",
            "epoch    3 | train time 2.57 | train loss 3.844723e-01 \n",
            "epoch    4 | train time 2.63 | train loss 3.734621e-01 \n",
            "epoch    5 | train time 2.66 | train loss 3.590482e-01 \n",
            "epoch    6 | train time 2.36 | train loss 3.408076e-01 \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7308/1936013803.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m stats = train(model=model,\n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[0mTs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mtest_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7308/3869133303.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, Ts, train_loader, test_loader, w, grad_clip, lr_schedule, begin_decay, epoch_number, resnet_config, alternating, horizon, horizon_type, horizon_list, switch_steps, epochs, loss_type, collect_grads, rescale_loss, rescale_dims)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain_loss_mini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                 \u001b[0mtrain_loss_mini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcollect_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                     \u001b[0mlayer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_grads_preclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollect_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "stats = train(model=model,\n",
        "              Ts=Ts,\n",
        "              train_loader=train_loader,\n",
        "              test_loader=test_loader,\n",
        "              w=torch.tensor(weights, device=device),\n",
        "              grad_clip=grad_clip,\n",
        "              lr_schedule=lr_schedule,\n",
        "              begin_decay=begin_decay,\n",
        "              resnet_config=None,\n",
        "              epoch_number=epoch_number,\n",
        "              alternating=False,\n",
        "              horizon=False,\n",
        "              horizon_type='auto',\n",
        "              horizon_list=horizon_list,\n",
        "              switch_steps=switch_steps,\n",
        "              epochs=epoch_number,\n",
        "              loss_type='L2',\n",
        "              collect_grads=False,\n",
        "              rescale_loss=True,\n",
        "              rescale_dims=[1, 1, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCmjjdsXJycG"
      },
      "outputs": [],
      "source": [
        "# save model to disk\n",
        "model_path = 'data/models/'+save_prefix+'model_test'\n",
        "torch.save(model.state_dict(), PATH+model_path)\n",
        "\n",
        "# save the stats\n",
        "stats_path = PATH+'data/stats/'+save_prefix+'stats.txt'\n",
        "save_stats(stats, stats_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a83Sjv31rZJA"
      },
      "source": [
        "#### Resnet config 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS8xMRbvgvnx",
        "outputId": "2f588552-5097-4bf2-e241-e73781cc6ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real'  # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(\n",
        "    which=furuta_type)\n",
        "# C_q1, C_q2 = 0.000009, 0.00004\n",
        "utype = 'sine'  # 'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 5  # 4 # 1.4\n",
        "u_func.params['scale'] = 0.0001  # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = 'simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_closetopi'  # 'random_nozero' # 'random_closetopi'\n",
        "time_steps = 800\n",
        "num_trajectories = 1\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 10000, 1, 100000]  # [1, 9000, 1, 10000] # [1,1,1,1]#\n",
        "coord_type = 'hamiltonian'\n",
        "min_max_rescale = False\n",
        "rescale_dims = [1, 1, 1, 1]\n",
        "shuffle = False\n",
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale,\n",
        "                                             u_func, g_func, time_steps,\n",
        "                                             shuffle=shuffle,\n",
        "                                             num_trajectories=num_trajectories,\n",
        "                                             coord_type=coord_type,\n",
        "                                             proportion=proportion, batch_size=batch_size,\n",
        "                                             Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2,\n",
        "                                             g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
        "                                             min_max_rescale=min_max_rescale, rescale_dims = rescale_dims)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GToXlt2Cgvnz",
        "outputId": "e5e32d49-a3f5-4acd-bcf4-9185d30adab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of epochs: 310\n",
            "mlp number of parameters : 3523\n",
            "resblock number of parameters : 3401\n",
            "Total number of H_net parameters : 23929\n",
            "Save file prefix :  NESHDNN_resnet_conf1_sine_1traj_real_noise0.0_310e_w001.0_001.0_001.0_001.0_p23k_Ts0.005_gradcl_nodissip\n",
            "horizon_list and switch_steps have the same size \n"
          ]
        }
      ],
      "source": [
        "# horizon_list = [20,40,60]\n",
        "# switch_steps = [200,200,200]\n",
        "horizon_list = [50,100,150]\n",
        "switch_steps = [300,300,300]\n",
        "epoch_number = sum(switch_steps)\n",
        "grad_clip = True # activate gradient clipping\n",
        "lr_schedule = False # activate lr schedule\n",
        "begin_decay = 2250 # epoch at which lr starts decaying\n",
        "\n",
        "model_name = 'NESHDNN_resnet_conf1'\n",
        "\n",
        "H_net = ResNet_config1(resblock_list=[0], num_blocks = 6, input_dim=4, hidden_dim=40, \n",
        "                nb_hidden_layers=2, output_dim=1, activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2')\n",
        "num_params = 0\n",
        "for block in H_net.resblocks:\n",
        "    block.to(device)\n",
        "    num_params += count_parameters(block)\n",
        "\n",
        "model = Nes_HDNN(u_func=u_func, G_net=g_func, H_net=H_net, device=device, dissip=False)\n",
        "model.to(device)\n",
        "num_params1 = count_parameters(model)\n",
        "num_params2 = count_parameters(model.H_net.resblocks[0])\n",
        "num_params += num_params1\n",
        "\n",
        "weights = [1.0, 1.0, 1.0, 1.0] \n",
        "weights_title = ' | weights = ' + str(weights)\n",
        "\n",
        "save_prefix = '{:d}e_w{:05.1f}_{:05.1f}_{:05.1f}_{:05.1f}_p{:d}k_Ts{:1.3f}_'.format(epoch_number,weights[0],weights[1],weights[2],weights[3],int((num_params-num_params%1000)/1000),Ts)\n",
        "if utype is None:\n",
        "    input = 'noinput'\n",
        "else :\n",
        "    input = utype\n",
        "save_prefix = model_name +'_'+ input + '_' + str(num_trajectories)+'traj'+'_' + furuta_type + '_' + 'noise'+str(noise_std)+'_'+  save_prefix \n",
        "if grad_clip:\n",
        "    save_prefix = save_prefix + 'gradcl_'\n",
        "if lr_schedule: \n",
        "    save_prefix = save_prefix + 'lrsched_'\n",
        "if C_q1==0 and C_q2==0:\n",
        "    save_prefix = save_prefix + 'nodissip'\n",
        "else:\n",
        "    save_prefix = save_prefix + 'wdissip'\n",
        "\n",
        "print('Total number of epochs:', epoch_number)\n",
        "print('mlp number of parameters :', num_params1)\n",
        "print('resblock number of parameters :', num_params2)\n",
        "print('Total number of H_net parameters :', num_params)\n",
        "print('Save file prefix : ', save_prefix)\n",
        "\n",
        "if len(horizon_list) == len(switch_steps) :\n",
        "    print('horizon_list and switch_steps have the same size ')\n",
        "else:\n",
        "    raise ValueError('horizon_list and switch_steps do NOT have the same size ',len(horizon_list),len(switch_steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzIlPKWHrZJD",
        "outputId": "b1bcd643-474c-4757-bd31-14ccc481d867"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "execution_count": 365,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.H_net.resblock_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "UYe6wlakrZJE",
        "outputId": "608785e6-3bbd-4dd8-c679-9d36860d08ff"
      },
      "outputs": [],
      "source": [
        "stats = train(model=model,\n",
        "            Ts=Ts,\n",
        "            train_loader=train_loader,\n",
        "            test_loader=test_loader,\n",
        "            w=torch.tensor(weights, device=device),\n",
        "            grad_clip=grad_clip,\n",
        "            lr_schedule=lr_schedule,\n",
        "            begin_decay=begin_decay,\n",
        "            resnet_config=1,\n",
        "            epoch_number=epoch_number,\n",
        "            alternating=False,\n",
        "            horizon=False,\n",
        "            horizon_type='auto',\n",
        "            horizon_list=horizon_list,\n",
        "            switch_steps=switch_steps,\n",
        "            epochs=epoch_number,\n",
        "            loss_type='L2weighted',\n",
        "            collect_grads=False,\n",
        "            rescale_loss = True,\n",
        "            rescale_dims = [1, 1, 1, 1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z1f22FlkPcB"
      },
      "outputs": [],
      "source": [
        "# save model to disk\n",
        "model_path = 'data/models/'+save_prefix+'model_test'\n",
        "torch.save(model.state_dict(), PATH+model_path)\n",
        "\n",
        "# save the stats\n",
        "stats_path = PATH+'data/stats/'+save_prefix+'stats.txt'\n",
        "save_stats(stats, stats_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeWufKhKrZJF"
      },
      "source": [
        "#### Resnet config 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muzDe0lMjX4w",
        "outputId": "3284c998-8a39-4c90-a696-add9fcc31b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real' # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) \n",
        "\n",
        "utype = 'chirp' #  'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 4 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype='simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_nozero' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 800\n",
        "num_trajectories = 1\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 1000, 1, 10000] # [1, 9000, 1, 10000]\n",
        "coord_type = 'hamiltonian'\n",
        "min_max_rescale = False\n",
        "rescale_dims = [1, 1, 1, 1]\n",
        "shuffle = False\n",
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale,\n",
        "                                             u_func, g_func, time_steps,\n",
        "                                             shuffle=shuffle,\n",
        "                                             num_trajectories=num_trajectories,\n",
        "                                             coord_type=coord_type,\n",
        "                                             proportion=proportion, batch_size=batch_size,\n",
        "                                             Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2,\n",
        "                                             g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
        "                                             min_max_rescale=min_max_rescale, rescale_dims = rescale_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 396,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6MYPp6QwnGX",
        "outputId": "72a8a644-bd7c-441e-8ce9-7dc85f6ed12e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=4, out_features=70, bias=True)\n",
              "  (hidden_layers): Sequential(\n",
              "    (0): hidden_Layer(\n",
              "      (fc): Linear(in_features=70, out_features=70, bias=True)\n",
              "    )\n",
              "    (1): hidden_Layer(\n",
              "      (fc): Linear(in_features=70, out_features=70, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (fc2): Linear(in_features=70, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 396,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.H_net.resblocks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0ItHdz2jX4x",
        "outputId": "ca11af98-088b-406a-a969-94150ac554da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of epochs: 30\n",
            "mlp number of parameters : 2343\n",
            "resblock number of parameters : 2479\n",
            "Total number of parameters : 44486\n",
            "Save file prefix :  NESHDNN_resnet_conf2_chirp_1traj_real_noise0.0_30e_w001.0_001.0_001.0_001.0_p44k_Ts0.005_gradcl_nodissip\n",
            "horizon_list and switch_steps have the same size \n"
          ]
        }
      ],
      "source": [
        "# horizon_list = [50,100,150,200]\n",
        "# switch_steps = [200,200,100,100]\n",
        "horizon_list = [50,100,150,200,250,300]\n",
        "switch_steps = [5,5,5,5,5,5]\n",
        "epoch_number = sum(switch_steps)\n",
        "grad_clip = True # activate gradient clipping\n",
        "lr_schedule = False # activate lr schedule\n",
        "begin_decay = 2250 # epoch at which lr starts decaying\n",
        "\n",
        "model_name = 'NESHDNN_resnet_conf2'\n",
        "\n",
        "H_net = ResNet_config2(resblock_list = [0,16], num_blocks = 17, input_dim=4, \n",
        "                       hidden_dim=45, nb_hidden_layers=1, output_dim=1, \n",
        "                       activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2')\n",
        "num_params = 0\n",
        "for block in H_net.resblocks:\n",
        "    block.to(device)\n",
        "    num_params += count_parameters(block)\n",
        "\n",
        "model = Nes_HDNN(u_func=u_func, G_net=g_func, H_net=H_net, device=device, dissip=False)\n",
        "model.to(device)\n",
        "num_params1 = count_parameters(model)\n",
        "num_params2 = count_parameters(model.H_net.resblocks[0])\n",
        "num_params += num_params1\n",
        "weights = [1.0, 1.0, 1.0, 1.0] \n",
        "weights_title = ' | weights = ' + str(weights)\n",
        "\n",
        "save_prefix = '{:d}e_w{:05.1f}_{:05.1f}_{:05.1f}_{:05.1f}_p{:d}k_Ts{:1.3f}_'.format(epoch_number,weights[0],weights[1],weights[2],weights[3],int((num_params-num_params%1000)/1000),Ts)\n",
        "if utype is None:\n",
        "    input = 'noinput'\n",
        "else :\n",
        "    input = utype \n",
        "save_prefix = model_name +'_'+ input + '_' + str(num_trajectories)+'traj'+'_' + furuta_type + '_' + 'noise'+str(noise_std)+'_'+  save_prefix \n",
        "if grad_clip: \n",
        "    save_prefix = save_prefix + 'gradcl_'\n",
        "if lr_schedule: \n",
        "    save_prefix = save_prefix + 'lrsched_'\n",
        "if C_q1==0 and C_q2==0:\n",
        "    save_prefix = save_prefix + 'nodissip'\n",
        "else:\n",
        "    save_prefix = save_prefix + 'wdissip'\n",
        "\n",
        "print('Total number of epochs:',epoch_number)\n",
        "print('mlp number of parameters :', num_params1)\n",
        "print('resblock number of parameters :', num_params2)\n",
        "print('Total number of parameters :', num_params)\n",
        "\n",
        "print('Save file prefix : ', save_prefix)\n",
        "\n",
        "if len(horizon_list) == len(switch_steps) :\n",
        "    print('horizon_list and switch_steps have the same size ')\n",
        "else:\n",
        "    raise ValueError('horizon_list and switch_steps do NOT have the same size ',len(horizon_list),len(switch_steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9H-T7GDjX4y",
        "outputId": "5ae101c5-6fe4-4e5a-ef38-9120a6e0186a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 16]"
            ]
          },
          "execution_count": 382,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.H_net.resblock_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9eri-gUc2bt_",
        "outputId": "106e9cb4-6c5b-4658-f3cf-0da1587e6ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "horizon length : 50\n",
            "Model size increased\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "number of dims don't match in permute",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7308/1113745901.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m stats = train(model = model, \n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mTs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7308/3869133303.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, Ts, train_loader, test_loader, w, grad_clip, lr_schedule, begin_decay, epoch_number, resnet_config, alternating, horizon, horizon_type, horizon_list, switch_steps, epochs, loss_type, collect_grads, rescale_loss, rescale_dims)\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreeze_G_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m                 \u001b[0mtrain_x_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rk4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m                 \u001b[1;31m# print('train_x_hat',train_x_hat.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[1;31m# train_x_hat is [time_steps, batch_size, (q1,p1,q2,p1)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torchdiffeq\\_impl\\odeint.py\u001b[0m in \u001b[0;36modeint\u001b[1;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0msolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torchdiffeq\\_impl\\solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mdy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torchdiffeq\\_impl\\fixed_grid.py\u001b[0m in \u001b[0;36m_step_func\u001b[1;34m(self, func, t0, dt, t1, y0)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_step_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mf0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperturb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPerturb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNEXT\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperturb\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrk4_alt_step_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperturb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torchdiffeq\\_impl\\misc.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, t, y, perturb)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;31m# Do nothing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7308/1364334383.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, t, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC2_dissip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdHdp2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0mdp1dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mdHdq1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                 \u001b[0mdp2dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mdHdq2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# symplectic gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: number of dims don't match in permute"
          ]
        }
      ],
      "source": [
        "stats = train(model = model, \n",
        "            Ts = Ts, \n",
        "            train_loader = train_loader, \n",
        "            test_loader = test_loader, \n",
        "            w=torch.tensor(weights, device=device),\n",
        "            grad_clip = grad_clip,\n",
        "            lr_schedule = lr_schedule,\n",
        "            begin_decay = begin_decay, \n",
        "            resnet_config = 2,\n",
        "            epoch_number = epoch_number, \n",
        "            alternating = False,\n",
        "            horizon = False, \n",
        "            horizon_type = 'auto', \n",
        "            horizon_list = horizon_list, \n",
        "            switch_steps = switch_steps, \n",
        "            epochs = epoch_number, \n",
        "            loss_type = 'L2weighted',\n",
        "            collect_grads=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrd75QTdkVdh"
      },
      "outputs": [],
      "source": [
        "# save model to disk\n",
        "model_path = 'data/models/'+save_prefix+'model_test'\n",
        "torch.save(model.state_dict(), PATH+model_path)\n",
        "\n",
        "# save the stats\n",
        "stats_path = PATH+'data/stats/'+save_prefix+'stats.txt'\n",
        "save_stats(stats, stats_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvH00uYvxr-7"
      },
      "source": [
        "## Resnet config 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21LnlWhg_2p8",
        "outputId": "a4cbc761-c6e3-41df-bb2c-7584c25a67c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real' # 'real' or 'fake'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) \n",
        "# C_q1, C_q2 = 0.000009, 0.00004\n",
        "utype = 'sine' #  'chirp' or None or '' or ''\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 5 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.0001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = 'simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_closetopi' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 800\n",
        "num_trajectories = 5\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 10000, 1, 100000] # [1, 9000, 1, 10000] # [1,1,1,1]#\n",
        "coord_type = 'hamiltonian'\n",
        "min_max_rescale = False\n",
        "rescale_dims = [1, 1, 1, 1]\n",
        "shuffle = False\n",
        "train_loader, test_loader = load_data_device(device, init_method, w_rescale,\n",
        "                                             u_func, g_func, time_steps,\n",
        "                                             shuffle=shuffle,\n",
        "                                             num_trajectories=num_trajectories,\n",
        "                                             coord_type=coord_type,\n",
        "                                             proportion=proportion, batch_size=batch_size,\n",
        "                                             Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2,\n",
        "                                             g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
        "                                             min_max_rescale=min_max_rescale, rescale_dims = rescale_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TVsfSKZ_2p9",
        "outputId": "5cf8e4da-3560-41a7-d66d-1005e64b4375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of epochs: 310\n",
            "mlp number of parameters : 10363\n",
            "resblock number of parameters : 10574\n",
            "Total number of H_net parameters : 73807\n",
            "Save file prefix :  NESHDNN_resnet_conf3_sine_5traj_real_noise0.0_310e_w001.0_001.0_001.0_001.0_p73k_Ts0.005_gradcl_nodissip_\n",
            "horizon_list and switch_steps have the same size \n"
          ]
        }
      ],
      "source": [
        "# horizon_list = [20,40,60]\n",
        "# switch_steps = [200,200,200]\n",
        "horizon_list = [50,100,150]\n",
        "switch_steps = [5,5,300]\n",
        "epoch_number = sum(switch_steps)\n",
        "grad_clip = True # activate gradient clipping\n",
        "lr_schedule = False # activate lr schedule\n",
        "begin_decay = 2250 # epoch at which lr starts decaying\n",
        "\n",
        "model_name = 'NESHDNN_resnet_conf3'\n",
        "\n",
        "H_net = ResNet_config3(resblock_list=[0], num_blocks = 6, input_dim=4, hidden_dim=70, \n",
        "                nb_hidden_layers=2, output_dim=1, activation_res='x+sin(x)^2', activation_mlp='x+sin(x)^2')\n",
        "num_params = 0\n",
        "for block in H_net.resblocks:\n",
        "    block.to(device)\n",
        "    num_params += count_parameters(block)\n",
        "\n",
        "model = Nes_HDNN(u_func=u_func, G_net=g_func, H_net=H_net, device=device, dissip=False)\n",
        "model.to(device)\n",
        "num_params1 = count_parameters(model)\n",
        "num_params2 = count_parameters(model.H_net.resblocks[0])\n",
        "num_params += num_params1\n",
        "\n",
        "weights = [1.0, 1.0, 1.0, 1.0] \n",
        "weights_title = ' | weights = ' + str(weights)\n",
        "\n",
        "save_prefix = '{:d}e_w{:05.1f}_{:05.1f}_{:05.1f}_{:05.1f}_p{:d}k_Ts{:1.3f}_'.format(epoch_number,weights[0],weights[1],weights[2],weights[3],int((num_params-num_params%1000)/1000),Ts)\n",
        "if utype is None:\n",
        "    input = 'noinput'\n",
        "else :\n",
        "    input = utype\n",
        "save_prefix = model_name +'_'+ input + '_' + str(num_trajectories)+'traj'+'_' + furuta_type + '_' + 'noise'+str(noise_std)+'_'+  save_prefix \n",
        "if grad_clip:\n",
        "    save_prefix = save_prefix + 'gradcl_'\n",
        "if lr_schedule: \n",
        "    save_prefix = save_prefix + 'lrsched_'\n",
        "if C_q1==0 and C_q2==0:\n",
        "    save_prefix = save_prefix + 'nodissip_'\n",
        "else:\n",
        "    save_prefix = save_prefix + 'wdissip'\n",
        "\n",
        "print('Total number of epochs:', epoch_number)\n",
        "print('mlp number of parameters :', num_params1)\n",
        "print('resblock number of parameters :', num_params2)\n",
        "print('Total number of H_net parameters :', num_params)\n",
        "print('Save file prefix : ', save_prefix)\n",
        "\n",
        "if len(horizon_list) == len(switch_steps) :\n",
        "    print('horizon_list and switch_steps have the same size ')\n",
        "else:\n",
        "    raise ValueError('horizon_list and switch_steps do NOT have the same size ',len(horizon_list),len(switch_steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "gFVLnISBunJt"
      },
      "outputs": [],
      "source": [
        "# model_path = 'data/models/'+save_prefix+'model_test'\n",
        "# model.load_state_dict(torch.load(PATH+model_path))\n",
        "# model.eval()\n",
        "# model.to(device)\n",
        "# model.H_net.resblock_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qByp-mwG_2p9",
        "outputId": "8d989a2d-991a-4a00-b5d4-93d5ea338790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "horizon length : 50\n",
            "Model size increased\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plot time : 0.5966579914093018\n",
            "epoch    0 | train time 1.22 | train loss 1.351382e+00 \n",
            "epoch    1 | train time 0.58 | train loss 1.329894e+00 \n",
            "epoch    2 | train time 0.75 | train loss 1.311581e+00 \n",
            "epoch    3 | train time 0.62 | train loss 1.294755e+00 \n",
            "epoch    4 | train time 0.57 | train loss 1.278269e+00 \n",
            "horizon length : 100\n",
            "Model size increased\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7308/3655167129.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m stats = train(model = model, \n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mTs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7308/3869133303.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, Ts, train_loader, test_loader, w, grad_clip, lr_schedule, begin_decay, epoch_number, resnet_config, alternating, horizon, horizon_type, horizon_list, switch_steps, epochs, loss_type, collect_grads, rescale_loss, rescale_dims)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain_loss_mini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                 \u001b[0mtrain_loss_mini\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcollect_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                     \u001b[0mlayer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_grads_preclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollect_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pds\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "stats = train(model = model, \n",
        "            Ts = Ts, \n",
        "            train_loader = train_loader, \n",
        "            test_loader = test_loader, \n",
        "            w=torch.tensor(weights, device=device),\n",
        "            grad_clip = grad_clip,\n",
        "            lr_schedule = lr_schedule,\n",
        "            begin_decay = begin_decay, \n",
        "            resnet_config = 1,\n",
        "            epoch_number = epoch_number, \n",
        "            alternating = False,\n",
        "            horizon = False, \n",
        "            horizon_type = 'auto', \n",
        "            horizon_list = horizon_list, \n",
        "            switch_steps = switch_steps, \n",
        "            epochs = epoch_number, \n",
        "            loss_type = 'L2weighted',\n",
        "            collect_grads = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO8nbKo5Aj5B"
      },
      "outputs": [],
      "source": [
        "# save model to disk\n",
        "model_path = 'data/models/'+save_prefix+'model_test'\n",
        "torch.save(model.state_dict(), PATH+model_path)\n",
        "\n",
        "# save the stats\n",
        "stats_path = PATH+'data/stats/'+save_prefix+'stats.txt'\n",
        "save_stats(stats, stats_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiPNpCp9rsbw"
      },
      "source": [
        "# Loading models and stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yykcEKBUVTAv"
      },
      "outputs": [],
      "source": [
        "save_prefix = save_prefix +'multitrajwinput'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSZNGbFzsxTO"
      },
      "outputs": [],
      "source": [
        "stats_path = PATH+'data/stats/'+save_prefix+'stats.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLO7OoGFrsbw"
      },
      "outputs": [],
      "source": [
        "# # save the stats\n",
        "# save_stats(PATH, stats, stats_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNu3f80Frsbw"
      },
      "outputs": [],
      "source": [
        "# loads the stats \n",
        "stats = read_dict(PATH, stats_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg3tz41frsbx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D56Rtj5Srsbx"
      },
      "outputs": [],
      "source": [
        "# # save model to disk\n",
        "# model_path = 'data/models/'+save_prefix+'model_test'\n",
        "# torch.save(model.state_dict(), PATH+model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZw3t4M1rsbx"
      },
      "outputs": [],
      "source": [
        "model_path = 'models/'+save_prefix+'model_test_latest'\n",
        "# load the model from disk\n",
        "model = load_model_nes_hdnn(device,utype=utype, u_func=u_func, hidden_dim=90, nb_hidden_layers=4) # load_model(hidden_dim=90, nb_hidden_layers=4)\n",
        "#load_model(device, hidden_dim=90, nb_hidden_layers=4)\n",
        "model.load_state_dict(torch.load(PATH+model_path))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuH3yVHArsby"
      },
      "outputs": [],
      "source": [
        "print(model.C2_dissip)\n",
        "print(model.C1_dissip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FTm0Slrsby"
      },
      "source": [
        "# Plots of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "bpcjbU2h_bk-",
        "outputId": "9d733f30-78fc-4fe7-b69c-605c9005aab7"
      },
      "outputs": [],
      "source": [
        "loss_train = stats['train_loss']\n",
        "loss_test = stats['test_loss']\n",
        "epochs = np.arange(len(loss_train))\n",
        "train_test_loss_plot(loss_train, loss_test, epochs, file_path=PATH+'data/img/'+save_prefix+'LOSS_train_test.png', \n",
        "                     title='train and test loss per epoch', horizons = False )\n",
        "\n",
        "train_test_loss_plot(loss_train, loss_test, epochs, file_path=PATH+'data/img/'+save_prefix+'LOSS_train_test_warrows.png', \n",
        "                     title='train and test loss per epoch', horizons = horizon_list[:-1], horizon_steps = horizon_steps )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmcsaPav41JO"
      },
      "outputs": [],
      "source": [
        "model.u_func = u_func\n",
        "model.G_net = g_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ujCIcwEyJycS",
        "outputId": "c0f9afb7-1c44-4dba-b04c-12e424fd3267"
      },
      "outputs": [],
      "source": [
        "# show train and prediction\n",
        "title = 'Train set trajectories ' # | Nes_HDNN with chirp input and multi-level strategy 3\n",
        "for n in [0,5,10,19]:\n",
        "    plot_furuta_hat_nom(device, model, u_func, g_func, utype, gtype, data_loader_t=train_loader, \n",
        "                        t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
        "                        t_plot=300, show_pred=True, H_or_Input = 'input',\n",
        "                        title = title, file_path=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WcR1iZg4ha5"
      },
      "outputs": [],
      "source": [
        "# show train and prediction\n",
        "for n in [0,5,10,19]:\n",
        "    plot_furuta_hat_nom(device, model, u_func, g_func, utype, gtype, data_loader_t=train_loader, \n",
        "                        t_max=200, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp,\n",
        "                        t_plot=300, show_pred=True, H_or_Input = 'input',\n",
        "                        title = 'Train set trajectories', file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_train_set'+str(n)+'_nopred.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71072h6uvdVo"
      },
      "outputs": [],
      "source": [
        "# show only training portion\n",
        "for n in [0,50,70,80]:\n",
        "    plot_furuta_hat_nom(device, model, u_func, g_func, utype, gtype, data_loader_t=train_loader, t_max=300, \n",
        "    n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp, t_plot=300, show_pred=False,\n",
        "    title = 'Train set trajectories', file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_train_set'+str(n)+'.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj3zg89vHpdC"
      },
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = 'fake') # 'fake'\n",
        "utype = None\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 10 #4 # 1.4\n",
        "u_func.params['scale'] = 1.0 # 0.1\n",
        "gtype=None\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_closetopi' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 800\n",
        "num_trajectories = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thtw9a84HWfJ",
        "outputId": "7b0d2f88-a7a0-4834-da2d-c961112ca1a2"
      },
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) # 'fake'\n",
        "utype = None\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 4 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype=None\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_nozero' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 1000\n",
        "num_trajectories = 5\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 1000, 1, 10000] # [1, 9000, 1, 10000]\n",
        "\n",
        "train_loader_2, test_loader_2 = load_data_device(device, init_method, w_rescale,\n",
        "                                            u_func, g_func, time_steps, \n",
        "                                            shuffle = False, \n",
        "                                            num_trajectories = num_trajectories, \n",
        "                                            coord_type = 'hamiltonian', \n",
        "                                            proportion = proportion, batch_size = batch_size, \n",
        "                                            Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
        "                                            g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp,)\n",
        "model.u_func = u_func\n",
        "model.G_net = g_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MFcgNHdMIvI1",
        "outputId": "303e5f65-3a38-44d7-f8a0-e5a5692c9561"
      },
      "outputs": [],
      "source": [
        "for n in [0,1,2,3,4]:\n",
        "    plot_furuta_hat_nom(device, model, u_func, g_func, utype, gtype, data_loader_t=train_loader_2, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp, only_pred = True,\n",
        "                        title = 'Train set trajectories | no input', \n",
        "                        file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_train_set'+str(n)+'_noinput.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XeaJYIA292j"
      },
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) # 'fake'\n",
        "utype = 'chirp'\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 10 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = 'simple'\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_nozero' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 1000\n",
        "num_trajectories = 1\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 1000, 1, 10000] # [1, 9000, 1, 10000]\n",
        "\n",
        "train_loader_3, test_loader_3 = load_data_device(device, init_method, w_rescale,\n",
        "                                            u_func, g_func, time_steps, \n",
        "                                            shuffle = False, \n",
        "                                            num_trajectories = num_trajectories, \n",
        "                                            coord_type = 'hamiltonian', \n",
        "                                            proportion = proportion, batch_size = batch_size, \n",
        "                                            Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
        "                                            g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp)\n",
        "model.u_func = u_func\n",
        "model.G_net = g_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNITdm9KCsvo"
      },
      "outputs": [],
      "source": [
        "for n in [0,5,9]:\n",
        "    plot_furuta_hat_nom(device, model, u_func, g_func, utype, gtype, data_loader_t=train_loader_3, t_max=300, n=n, C_q1=C_q1, C_q2=C_q2, g=g, Jr=Jr, Lr=Lr, Mp=Mp, Lp=Lp, only_pred = True,\n",
        "                        title = 'Test set trajectories | sine input (1hz)', file_path=PATH+'data/img/'+save_prefix+'TRAJECTORIES_train_set'+str(n)+'_sineinput.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5twG3nIxJycY"
      },
      "outputs": [],
      "source": [
        "device = set_device()\n",
        "furuta_type = 'real'\n",
        "Ts, noise_std, C_q1, C_q2, g, Jr, Lr, Mp, Lp = set_furuta_params(which = furuta_type) # 'fake'\n",
        "utype = None\n",
        "u_func = U_FUNC(utype=utype)\n",
        "u_func.params['T'] = 1.5\n",
        "u_func.params['f0'] = 0\n",
        "u_func.params['f1'] = 4 # 4 # 1.4\n",
        "u_func.params['scale'] = 0.001 # for fake : 0.5 or 0.1 for real : 0.0001\n",
        "gtype = None\n",
        "g_func = G_FUNC(gtype=gtype)\n",
        "init_method = 'random_nozero' # 'random_nozero' # 'random_closetopi'\n",
        "time_steps= 1000\n",
        "num_trajectories = 1\n",
        "proportion = 0.0\n",
        "batch_size = 100\n",
        "w_rescale = [1, 1000, 1, 10000] # [1, 9000, 1, 10000]\n",
        "\n",
        "train_loader_4, test_loader_4 = load_data_device(device, init_method, w_rescale,\n",
        "                                            u_func, g_func, time_steps, \n",
        "                                            shuffle = False, \n",
        "                                            num_trajectories = num_trajectories, \n",
        "                                            coord_type = 'hamiltonian', \n",
        "                                            proportion = proportion, batch_size = batch_size, \n",
        "                                            Ts=Ts, noise_std=noise_std, C_q1=C_q1, C_q2=C_q2, \n",
        "                                            g = g, Jr = Jr, Lr = Lr, Mp = Mp, Lp = Lp)\n",
        "model.u_func = u_func \n",
        "model.G_net = g_func "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMrpQCCRJycY"
      },
      "outputs": [],
      "source": [
        "for n in [0]:\n",
        "    plot_longer_horizon_furuta(device, model, u_func, g_func, utype, gtype, test_loader=train_loader_4,n=n,\n",
        "                                t1=0,t2=600, C_q1= C_q1, C_q2= C_q2, g= g, Jr= Jr, Lr= Lr, Mp= Mp, Lp= Lp, \n",
        "                                title = 'Trajectory after longer horizon',\n",
        "                                file_path = PATH+'img/'+save_prefix+'TRAJ_longer_horizon1.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "w13_Furuta_NES_HDNN_ResNets__with_profiling_and_quicker_2_withgradplots.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "52b0f3b5fff4e2d99607e23e4ce3f8b9e3a664acf6541783ed53f1bd22095b69"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('pds')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
